import{_ as l,c as i,o as n,aA as t,j as s,a}from"./chunks/framework.DjA5121Y.js";const r="/d2l-julia/previews/PR1/assets/filters.DLjnf6TJ.png",o="/d2l-julia/previews/PR1/assets/alexnet.CzA4xxyI.svg",B=JSON.parse('{"title":"Deep Convolutional Neural Networks (AlexNet)","description":"","frontmatter":{},"headers":[],"relativePath":"CH7.ModernConvolutionalNeuralNetworks/MCNN_1.md","filePath":"CH7.ModernConvolutionalNeuralNetworks/MCNN_1.md","lastUpdated":null}'),h={name:"CH7.ModernConvolutionalNeuralNetworks/MCNN_1.md"},p={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},d={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.05ex"},xmlns:"http://www.w3.org/2000/svg",width:"7.291ex",height:"1.557ex",role:"img",focusable:"false",viewBox:"0 -666 3222.4 688","aria-hidden":"true"},k={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},g={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"0"},xmlns:"http://www.w3.org/2000/svg",width:"9.553ex",height:"1.532ex",role:"img",focusable:"false",viewBox:"0 -677 4222.4 677","aria-hidden":"true"},m={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},u={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.05ex"},xmlns:"http://www.w3.org/2000/svg",width:"7.291ex",height:"1.557ex",role:"img",focusable:"false",viewBox:"0 -666 3222.4 688","aria-hidden":"true"},T={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},c={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"0"},xmlns:"http://www.w3.org/2000/svg",width:"5.028ex",height:"1.532ex",role:"img",focusable:"false",viewBox:"0 -677 2222.4 677","aria-hidden":"true"},Q={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},y={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.781ex"},xmlns:"http://www.w3.org/2000/svg",width:"1.795ex",height:"2.737ex",role:"img",focusable:"false",viewBox:"0 -864.9 793.6 1209.9","aria-hidden":"true"},f={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},w={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.781ex"},xmlns:"http://www.w3.org/2000/svg",width:"10.972ex",height:"2.737ex",role:"img",focusable:"false",viewBox:"0 -864.9 4849.6 1209.9","aria-hidden":"true"},E={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},v={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"0"},xmlns:"http://www.w3.org/2000/svg",width:"7.291ex",height:"1.507ex",role:"img",focusable:"false",viewBox:"0 -666 3222.4 666","aria-hidden":"true"},x={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},C={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.05ex"},xmlns:"http://www.w3.org/2000/svg",width:"5.028ex",height:"1.557ex",role:"img",focusable:"false",viewBox:"0 -666 2222.4 688","aria-hidden":"true"},b={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},F={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.05ex"},xmlns:"http://www.w3.org/2000/svg",width:"5.028ex",height:"1.554ex",role:"img",focusable:"false",viewBox:"0 -665 2222.4 687","aria-hidden":"true"},L={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},V={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.05ex"},xmlns:"http://www.w3.org/2000/svg",width:"5.028ex",height:"1.554ex",role:"img",focusable:"false",viewBox:"0 -665 2222.4 687","aria-hidden":"true"};function _(A,e,H,M,N,P){return n(),i("div",null,[e[62]||(e[62]=t("",3)),s("p",null,[e[2]||(e[2]=a("Although some neural network accelerators were available in the 1990s, they were not yet sufficiently powerful to make deep multichannel, multilayer CNNs with a large number of parameters. For instance, NVIDIA's GeForce 256 from 1999 was able to process at most 480 million floating-point operations, such as additions and multiplications, per second (MFLOPS), without any meaningful programming framework for operations beyond games. Today's accelerators are able to perform in excess of 1000 TFLOPs per device. Moreover, datasets were still relatively small: OCR on 60,000 low-resolution ")),s("mjx-container",p,[(n(),i("svg",d,e[0]||(e[0]=[t("",1)]))),e[1]||(e[1]=s("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("mn",null,"28"),s("mo",null,"×"),s("mn",null,"28")])],-1))]),e[3]||(e[3]=a(" pixel images was considered a highly challenging task. Added to these obstacles, key tricks for training neural networks including parameter initialization heuristics [")),e[4]||(e[4]=s("a",{href:"/d2l-julia/previews/PR1/references#Glorot_Bengio_2010"},"105",-1)),e[5]||(e[5]=a("], clever variants of stochastic gradient descent [")),e[6]||(e[6]=s("a",{href:"/d2l-julia/previews/PR1/references#Kingma_Ba_2014"},"106",-1)),e[7]||(e[7]=a("], non-squashing activation functions [")),e[8]||(e[8]=s("a",{href:"/d2l-julia/previews/PR1/references#Nair_Hinton_2010"},"107",-1)),e[9]||(e[9]=a("], and effective regularization techniques [")),e[10]||(e[10]=s("a",{href:"/d2l-julia/previews/PR1/references#Srivastava_Hinton_Krizhevsky_ea_2014"},"70",-1)),e[11]||(e[11]=a("] were still missing."))]),e[63]||(e[63]=t("",14)),s("p",null,[e[16]||(e[16]=a("In 2009, the ImageNet dataset was released [")),e[17]||(e[17]=s("a",{href:"/d2l-julia/previews/PR1/references#Deng_Dong_Socher_ea_2009"},"22",-1)),e[18]||(e[18]=a("], challenging researchers to learn models from 1 million examples, 1000 each from 1000 distinct categories of objects. The categories themselves were based on the most popular noun nodes in WordNet [")),e[19]||(e[19]=s("a",{href:"/d2l-julia/previews/PR1/references#Miller_1995"},"113",-1)),e[20]||(e[20]=a("]. The ImageNet team used Google Image Search to prefilter large candidate sets for each category and employed the Amazon Mechanical Turk crowdsourcing pipeline to confirm for each image whether it belonged to the associated category. This scale was unprecedented, exceeding others by over an order of magnitude (e.g., CIFAR-100 has 60,000 images). Another aspect was that the images were at relatively high resolution of ")),s("mjx-container",k,[(n(),i("svg",g,e[12]||(e[12]=[t("",1)]))),e[13]||(e[13]=s("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("mn",null,"224"),s("mo",null,"×"),s("mn",null,"224")])],-1))]),e[21]||(e[21]=a(" pixels, unlike the 80 million-sized TinyImages dataset [")),e[22]||(e[22]=s("a",{href:"/d2l-julia/previews/PR1/references#Torralba_Fergus_Freeman_2008"},"114",-1)),e[23]||(e[23]=a("], consisting of ")),s("mjx-container",m,[(n(),i("svg",u,e[14]||(e[14]=[t("",1)]))),e[15]||(e[15]=s("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("mn",null,"32"),s("mo",null,"×"),s("mn",null,"32")])],-1))]),e[24]||(e[24]=a(" pixel thumbnails. This allowed for the formation of higher-level features. The associated competition, dubbed the ImageNet Large Scale Visual Recognition Challenge [")),e[25]||(e[25]=s("a",{href:"/d2l-julia/previews/PR1/references#russakovsky2015imagenet"},"115",-1)),e[26]||(e[26]=a("], pushed computer vision and machine learning research forward, challenging researchers to identify which models performed best at a greater scale than academics had previously considered. The largest vision datasets, such as LAION-5B [")),e[27]||(e[27]=s("a",{href:"/d2l-julia/previews/PR1/references#schuhmann2022laion"},"116",-1)),e[28]||(e[28]=a("] contain billions of images with additional metadata."))]),e[64]||(e[64]=s("h3",{id:"Missing-Ingredient:-Hardware",tabindex:"-1"},[a("Missing Ingredient: Hardware "),s("a",{class:"header-anchor",href:"#Missing-Ingredient:-Hardware","aria-label":'Permalink to "Missing Ingredient: Hardware {#Missing-Ingredient:-Hardware}"'},"​")],-1)),e[65]||(e[65]=s("p",null,"Deep learning models are voracious consumers of compute cycles. Training can take hundreds of epochs, and each iteration requires passing data through many layers of computationally expensive linear algebra operations. This is one of the main reasons why in the 1990s and early 2000s, simple algorithms based on the more-efficiently optimized convex objectives were preferred.",-1)),s("p",null,[e[31]||(e[31]=s("em",null,"Graphical processing units",-1)),e[32]||(e[32]=a(" (GPUs) proved to be a game changer in making deep learning feasible. These chips had earlier been developed for accelerating graphics processing to benefit computer games. In particular, they were optimized for high throughput ")),s("mjx-container",T,[(n(),i("svg",c,e[29]||(e[29]=[t("",1)]))),e[30]||(e[30]=s("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("mn",null,"4"),s("mo",null,"×"),s("mn",null,"4")])],-1))]),e[33]||(e[33]=a(" matrix–vector products, which are needed for many computer graphics tasks. Fortunately, the math is strikingly similar to that required for calculating convolutional layers. Around that time, NVIDIA and ATI had begun optimizing GPUs for general computing operations [")),e[34]||(e[34]=s("a",{href:"/d2l-julia/previews/PR1/references#Fernando_2004"},"117",-1)),e[35]||(e[35]=a("], going as far as to market them as ")),e[36]||(e[36]=s("em",null,"general-purpose GPUs",-1)),e[37]||(e[37]=a(" (GPGPUs)."))]),e[66]||(e[66]=s("p",null,"To provide some intuition, consider the cores of a modern microprocessor (CPU). Each of the cores is fairly powerful running at a high clock frequency and sporting large caches (up to several megabytes of L3). Each core is well-suited to executing a wide range of instructions, with branch predictors, a deep pipeline, specialized execution units, speculative execution, and many other bells and whistles that enable it to run a large variety of programs with sophisticated control flow. This apparent strength, however, is also its Achilles heel: general-purpose cores are very expensive to build. They excel at general-purpose code with lots of control flow. This requires lots of chip area, not just for the actual ALU (arithmetic logical unit) where computation happens, but also for all the aforementioned bells and whistles, plus memory interfaces, caching logic between cores, high-speed interconnects, and so on. CPUs are comparatively bad at any single task when compared with dedicated hardware. Modern laptops have 4–8 cores, and even high-end servers rarely exceed 64 cores per socket, simply because it is not cost-effective.",-1)),e[67]||(e[67]=s("p",null,"By comparison, GPUs can consist of thousands of small processing elements (NIVIDA's latest Ampere chips have up to 6912 CUDA cores), often grouped into larger groups (NVIDIA calls them warps). The details differ somewhat between NVIDIA, AMD, ARM and other chip vendors. While each core is relatively weak, running at about 1GHz clock frequency, it is the total number of such cores that makes GPUs orders of magnitude faster than CPUs. For instance, NVIDIA's recent Ampere A100 GPU offers over 300 TFLOPs per chip for specialized 16-bit precision (BFLOAT16) matrix-matrix multiplications, and up to 20 TFLOPs for more general-purpose floating point operations (FP32). At the same time, floating point performance of CPUs rarely exceeds 1 TFLOPs. For instance, Amazon's Graviton 3 reaches 2 TFLOPs peak performance for 16-bit precision operations, a number similar to the GPU performance of Apple's M1 processor.",-1)),s("p",null,[e[42]||(e[42]=a("There are many reasons why GPUs are much faster than CPUs in terms of FLOPs. First, power consumption tends to grow ")),e[43]||(e[43]=s("em",null,"quadratically",-1)),e[44]||(e[44]=a(" with clock frequency. Hence, for the power budget of a CPU core that runs four times faster (a typical number), you can use 16 GPU cores at ")),s("mjx-container",Q,[(n(),i("svg",y,e[38]||(e[38]=[t("",1)]))),e[39]||(e[39]=s("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("mfrac",null,[s("mn",null,"1"),s("mn",null,"4")])])],-1))]),e[45]||(e[45]=a(" the speed, which yields ")),s("mjx-container",f,[(n(),i("svg",w,e[40]||(e[40]=[t("",1)]))),e[41]||(e[41]=s("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("mn",null,"16"),s("mo",null,"×"),s("mfrac",null,[s("mn",null,"1"),s("mn",null,"4")]),s("mo",null,"="),s("mn",null,"4")])],-1))]),e[46]||(e[46]=a(" times the performance. Second, GPU cores are much simpler (in fact, for a long time they were not even ")),e[47]||(e[47]=s("em",null,"able",-1)),e[48]||(e[48]=a(" to execute general-purpose code), which makes them more energy efficient. For instance, (i) they tend not to support speculative evaluation, (ii) it typically is not possible to program each processing element individually, and (iii) the caches per core tend to be much smaller. Last, many operations in deep learning require high memory bandwidth. Again, GPUs shine here with buses that are at least 10 times as wide as many CPUs."))]),e[68]||(e[68]=t("",7)),s("p",null,[e[57]||(e[57]=a("In AlexNet's first layer, the convolution window shape is ")),s("mjx-container",E,[(n(),i("svg",v,e[49]||(e[49]=[t("",1)]))),e[50]||(e[50]=s("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("mn",null,"11"),s("mo",null,"×"),s("mn",null,"11")])],-1))]),e[58]||(e[58]=a(". Since the images in ImageNet are eight times taller and wider than the MNIST images, objects in ImageNet data tend to occupy more pixels with more visual detail. Consequently, a larger convolution window is needed to capture the object. The convolution window shape in the second layer is reduced to ")),s("mjx-container",x,[(n(),i("svg",C,e[51]||(e[51]=[t("",1)]))),e[52]||(e[52]=s("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("mn",null,"5"),s("mo",null,"×"),s("mn",null,"5")])],-1))]),e[59]||(e[59]=a(", followed by ")),s("mjx-container",b,[(n(),i("svg",F,e[53]||(e[53]=[t("",1)]))),e[54]||(e[54]=s("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("mn",null,"3"),s("mo",null,"×"),s("mn",null,"3")])],-1))]),e[60]||(e[60]=a(". In addition, after the first, second, and fifth convolutional layers, the network adds max-pooling layers with a window shape of ")),s("mjx-container",L,[(n(),i("svg",V,e[55]||(e[55]=[t("",1)]))),e[56]||(e[56]=s("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("mn",null,"3"),s("mo",null,"×"),s("mn",null,"3")])],-1))]),e[61]||(e[61]=a(" and a stride of 2. Moreover, AlexNet has ten times more convolution channels than LeNet."))]),e[69]||(e[69]=t("",12))])}const j=l(h,[["render",_]]);export{B as __pageData,j as default};
