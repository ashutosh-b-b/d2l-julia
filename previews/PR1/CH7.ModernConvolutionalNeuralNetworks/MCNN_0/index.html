<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Modern Convolutional Neural Networks · d2l Julia</title><meta name="title" content="Modern Convolutional Neural Networks · d2l Julia"/><meta property="og:title" content="Modern Convolutional Neural Networks · d2l Julia"/><meta property="twitter:title" content="Modern Convolutional Neural Networks · d2l Julia"/><meta name="description" content="Documentation for d2l Julia."/><meta property="og:description" content="Documentation for d2l Julia."/><meta property="twitter:description" content="Documentation for d2l Julia."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../CH3.Linear_Regression/LNN_1/">d2l Julia</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><span class="tocitem">Linear Neural Networks for Regression</span><ul><li><a class="tocitem" href="../../CH3.Linear_Regression/LNN_1/">Linear Regression</a></li><li><a class="tocitem" href="../../CH3.Linear_Regression/LNN_2/">Multiple Dispatch Design for Implementation</a></li><li><a class="tocitem" href="../../CH3.Linear_Regression/LNN_3/">Synthetic Regression Data</a></li><li><a class="tocitem" href="../../CH3.Linear_Regression/LNN_4/">Linear Regression Implementation from Scratch</a></li><li><a class="tocitem" href="../../CH3.Linear_Regression/LNN_5/">Concise Implementation of Linear Regression</a></li><li><a class="tocitem" href="../../CH3.Linear_Regression/LNN_6/">Generalization</a></li><li><a class="tocitem" href="../../CH3.Linear_Regression/LNN_7/">Weight Decay</a></li></ul></li><li><span class="tocitem">Linear Neural Networks for Classification</span><ul><li><a class="tocitem" href="../../CH4.Linear_Classification/LCN_1/">Softmax Regression</a></li><li><a class="tocitem" href="../../CH4.Linear_Classification/LCN_2/">The Image Classification Dataset</a></li><li><a class="tocitem" href="../../CH4.Linear_Classification/LCN_3/">Softmax Regression Implementation from Scratch</a></li><li><a class="tocitem" href="../../CH4.Linear_Classification/LCN_4/">Concise Implementation of Softmax Regression</a></li><li><a class="tocitem" href="../../CH4.Linear_Classification/LCN_5/">Generalization in Classification</a></li><li><a class="tocitem" href="../../CH4.Linear_Classification/LCN_6/">Environment and Distribution Shift</a></li></ul></li><li><span class="tocitem">Multilayer Perceptron</span><ul><li><a class="tocitem" href="../../CH5.MLP/MLP_1/">Multilayer Perceptrons</a></li><li><a class="tocitem" href="../../CH5.MLP/MLP_2/">Implementation of Multilayer Perceptrons</a></li><li><a class="tocitem" href="../../CH5.MLP/MLP_3/">Forward Propagation, Backward Propagation, and Computational Graphs</a></li><li><a class="tocitem" href="../../CH5.MLP/MLP_4/">Numerical Stability and Initialization</a></li><li><a class="tocitem" href="../../CH5.MLP/MLP_5/">Generalization in Deep Learning</a></li><li><a class="tocitem" href="../../CH5.MLP/MLP_6/">Dropout</a></li></ul></li><li><span class="tocitem">Convolutional Neural Networks</span><ul><li><a class="tocitem" href="../../CH6.Convolutional_Neural_Networks/CNN_2/">Convolutions for Images</a></li><li><a class="tocitem" href="../../CH6.Convolutional_Neural_Networks/CNN_3/">Padding and Stride</a></li><li><a class="tocitem" href="../../CH6.Convolutional_Neural_Networks/CNN_4/">Multiple Input and Multiple Output Channels</a></li><li><a class="tocitem" href="../../CH6.Convolutional_Neural_Networks/CNN_5/">Pooling</a></li><li><a class="tocitem" href="../../CH6.Convolutional_Neural_Networks/CNN_6/">Convolutional Neural Networks (LeNet)</a></li></ul></li><li><span class="tocitem">Modern Convolutional Neural Networks</span><ul><li class="is-active"><a class="tocitem" href>Modern Convolutional Neural Networks</a></li><li><a class="tocitem" href="../MCNN_1/">Deep Convolutional Neural Networks (AlexNet)</a></li><li><a class="tocitem" href="../MCNN_2/">Networks Using Blocks (VGG)</a></li><li><a class="tocitem" href="../MCNN_3/">-</a></li><li><a class="tocitem" href="../MCNN_4/">Multi-Branch Networks  (GoogLeNet)</a></li><li><a class="tocitem" href="../MCNN_5/">-</a></li><li><a class="tocitem" href="../MCNN_6/">Residual Networks (ResNet) and ResNeXt</a></li><li><a class="tocitem" href="../MCNN_7/">Densely Connected Networks (DenseNet)</a></li><li><a class="tocitem" href="../MCNN_8/">Designing Convolution Network Architectures</a></li></ul></li><li><span class="tocitem">Recurrent Neural Networks</span><ul><li><a class="tocitem" href="../../CH8.Recurrent_Neural_Networks/RNN_0/">Recurrent Neural Networks</a></li><li><a class="tocitem" href="../../CH8.Recurrent_Neural_Networks/RNN_1/">Working with Sequences</a></li><li><a class="tocitem" href="../../CH8.Recurrent_Neural_Networks/RNN_2/">Converting Raw Text into Sequence Data</a></li><li><a class="tocitem" href="../../CH8.Recurrent_Neural_Networks/RNN_3/">Language Models</a></li><li><a class="tocitem" href="../../CH8.Recurrent_Neural_Networks/RNN_4/">Recurrent Neural Networks</a></li><li><a class="tocitem" href="../../CH8.Recurrent_Neural_Networks/RNN_5/">Recurrent Neural Network Implementation from Scratch</a></li><li><a class="tocitem" href="../../CH8.Recurrent_Neural_Networks/RNN_6/">Concise Implementation of Recurrent Neural Networks</a></li><li><a class="tocitem" href="../../CH8.Recurrent_Neural_Networks/RNN_7/">Backpropagation Through Time</a></li></ul></li><li><span class="tocitem">Modern Recurrent Neural Networks</span><ul><li><a class="tocitem" href="../../CH9.Modern_Recurrent_Neural_Networks/MRNN7/">Sequence-to-Sequence Learning for Machine Translation</a></li><li><a class="tocitem" href="../../CH9.Modern_Recurrent_Neural_Networks/MRNN_1/">Long Short-Term Memory (LSTM)</a></li><li><a class="tocitem" href="../../CH9.Modern_Recurrent_Neural_Networks/MRNN_2/">Gated Recurrent Units (GRU)</a></li><li><a class="tocitem" href="../../CH9.Modern_Recurrent_Neural_Networks/MRNN_3/">-</a></li><li><a class="tocitem" href="../../CH9.Modern_Recurrent_Neural_Networks/MRNN_4/">Bidirectional Recurrent Neural Networks</a></li><li><a class="tocitem" href="../../CH9.Modern_Recurrent_Neural_Networks/MRNN_5/">Machine Translation and the Dataset</a></li><li><a class="tocitem" href="../../CH9.Modern_Recurrent_Neural_Networks/MRNN_6/">The Encoder–Decoder Architecture</a></li></ul></li><li><span class="tocitem">Attention Mechanisms and Transformers</span><ul><li><a class="tocitem" href="../../CH10.Attention_Mechanisms_and_Transformers/ATTN_1/">Queries, Keys, and Values</a></li><li><a class="tocitem" href="../../CH10.Attention_Mechanisms_and_Transformers/ATTN_2/">Attention Pooling by Similarity</a></li><li><a class="tocitem" href="../../CH10.Attention_Mechanisms_and_Transformers/ATTN_3/">Attention Scoring Functions</a></li><li><a class="tocitem" href="../../CH10.Attention_Mechanisms_and_Transformers/ATTN_4/">The Bahdanau Attention Mechanism</a></li><li><a class="tocitem" href="../../CH10.Attention_Mechanisms_and_Transformers/ATTN_5/">Multi-Head Attention</a></li><li><a class="tocitem" href="../../CH10.Attention_Mechanisms_and_Transformers/ATTN_6/">Self-Attention and Positional Encoding</a></li><li><a class="tocitem" href="../../CH10.Attention_Mechanisms_and_Transformers/Untitled/">-</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Modern Convolutional Neural Networks</a></li><li class="is-active"><a href>Modern Convolutional Neural Networks</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Modern Convolutional Neural Networks</a></li></ul></nav><div class="docs-right"><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Modern-Convolutional-Neural-Networks"><a class="docs-heading-anchor" href="#Modern-Convolutional-Neural-Networks">Modern Convolutional Neural Networks</a><a id="Modern-Convolutional-Neural-Networks-1"></a><a class="docs-heading-anchor-permalink" href="#Modern-Convolutional-Neural-Networks" title="Permalink"></a></h1><p>:label:<code>chap_modern_cnn</code></p><p>Now that we understand the basics of wiring together CNNs, let&#39;s take a tour of modern CNN architectures. This tour is, by necessity, incomplete, thanks to the plethora of exciting new designs being added. Their importance derives from the fact that not only can they be used directly for vision tasks, but they also serve as basic feature generators for more advanced tasks such as tracking :cite:<code>Zhang.Sun.Jiang.ea.2021</code>, segmentation :cite:<code>Long.Shelhamer.Darrell.2015</code>, object detection :cite:<code>Redmon.Farhadi.2018</code>, or style transformation :cite:<code>Gatys.Ecker.Bethge.2016</code>.  In this chapter, most sections correspond to a significant CNN architecture that was at some point (or currently) the base model upon which many research projects and deployed systems were built.  Each of these networks was briefly a dominant architecture and many were winners or runners-up in the <a href="https://www.image-net.org/challenges/LSVRC/">ImageNet competition</a> which has served as a barometer of progress on supervised learning in computer vision since 2010. It is only recently that Transformers have begun to displace CNNs, starting with :citet:<code>Dosovitskiy.Beyer.Kolesnikov.ea.2021</code> and  followed by the Swin Transformer :cite:<code>liu2021swin</code>. We will cover this development later  in :numref:<code>chap_attention-and-transformers</code>. </p><p>While the idea of <em>deep</em> neural networks is quite simple (stack together a bunch of layers), performance can vary wildly across architectures and hyperparameter choices.  The neural networks described in this chapter are the product of intuition, a few mathematical insights, and a lot of trial and error.  We present these models in chronological order, partly to convey a sense of the history so that you can form your own intuitions about where the field is heading and perhaps develop your own architectures.  For instance, batch normalization and residual connections described in this chapter have offered two popular ideas for training and designing deep models, both of which have since also been applied to architectures beyond computer vision.</p><p>We begin our tour of modern CNNs with AlexNet :cite:<code>Krizhevsky.Sutskever.Hinton.2012</code>, the first large-scale network deployed to beat conventional computer vision methods on a large-scale vision challenge; the VGG network :cite:<code>Simonyan.Zisserman.2014</code>, which makes use of a number of repeating blocks of elements; the network in network (NiN) that convolves whole neural networks patch-wise over inputs :cite:<code>Lin.Chen.Yan.2013</code>; GoogLeNet that uses networks with multi-branch convolutions :cite:<code>Szegedy.Liu.Jia.ea.2015</code>; the residual network (ResNet) :cite:<code>He.Zhang.Ren.ea.2016</code>, which remains one of the most popular off-the-shelf architectures in computer vision; ResNeXt blocks :cite:<code>Xie.Girshick.Dollar.ea.2017</code> for sparser connections; and DenseNet :cite:<code>Huang.Liu.Van-Der-Maaten.ea.2017</code> for a generalization of the residual architecture. Over time many special optimizations for efficient  networks have been developed, such as coordinate shifts (ShiftNet) :cite:<code>wu2018shift</code>. This  culminated in the automatic search for efficient architectures such as  MobileNet v3 :cite:<code>Howard.Sandler.Chu.ea.2019</code>. It also includes the  semi-automatic design exploration of :citet:<code>Radosavovic.Kosaraju.Girshick.ea.2020</code> that led to the RegNetX/Y which we will discuss later in this chapter.  The work is instructive insofar as it offers a path for marrying brute force computation with  the ingenuity of an experimenter in the search for efficient design spaces. Of note is also the work of :citet:<code>liu2022convnet</code> as it shows that training techniques (e.g., optimizers, data augmentation, and regularization) play a pivotal role in improving accuracy. It also shows that long-held assumptions, such as  the size of a convolution window, may need to be revisited, given the increase in  computation and data. We will cover this and many more questions in due course throughout this chapter.</p><pre><code class="language-toc hljs">:maxdepth: 2

alexnet
vgg
nin
googlenet
batch-norm
resnet
densenet
cnn-design</code></pre><pre><code class="language-julia hljs"></code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../CH6.Convolutional_Neural_Networks/CNN_6/">« Convolutional Neural Networks (LeNet)</a><a class="docs-footer-nextpage" href="../MCNN_1/">Deep Convolutional Neural Networks (AlexNet) »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.12.0 on <span class="colophon-date" title="Sunday 15 June 2025 19:32">Sunday 15 June 2025</span>. Using Julia version 1.11.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
