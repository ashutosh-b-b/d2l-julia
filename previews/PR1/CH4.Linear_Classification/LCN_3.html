<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Softmax Regression Implementation from Scratch | d2l Julia</title>
    <meta name="description" content="Documentation for d2l-julia">
    <meta name="generator" content="VitePress v1.6.3">
    <link rel="preload stylesheet" href="/d2l-julia/previews/PR1/assets/style.BUOi7SFr.css" as="style">
    <link rel="preload stylesheet" href="/d2l-julia/previews/PR1/vp-icons.css" as="style">
    
    <script type="module" src="/d2l-julia/previews/PR1/assets/app.DyCk50An.js"></script>
    <link rel="preload" href="/d2l-julia/previews/PR1/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/d2l-julia/previews/PR1/assets/chunks/theme.CszcN3qP.js">
    <link rel="modulepreload" href="/d2l-julia/previews/PR1/assets/chunks/framework.DjA5121Y.js">
    <link rel="modulepreload" href="/d2l-julia/previews/PR1/assets/CH4.Linear_Classification_LCN_3.md.V-0rtib8.lean.js">
    <script src="/d2l-julia/versions.js"></script>
    <script src="/d2l-julia/previews/PR1/siteinfo.js"></script>
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-a9a9e638><!--[--><!--]--><!--[--><span tabindex="-1" data-v-492508fc></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-492508fc>Skip to content</a><!--]--><!----><header class="VPNav" data-v-a9a9e638 data-v-f1e365da><div class="VPNavBar" data-v-f1e365da data-v-822684d1><div class="wrapper" data-v-822684d1><div class="container" data-v-822684d1><div class="title" data-v-822684d1><div class="VPNavBarTitle has-sidebar" data-v-822684d1 data-v-0f4f798b><a class="title" href="/d2l-julia/previews/PR1/" data-v-0f4f798b><!--[--><!--]--><!--[--><img class="VPImage logo" src="/d2l-julia/previews/PR1/logo.png" width="24" height="24" alt data-v-35a7d0b8><!--]--><span data-v-0f4f798b>d2l Julia</span><!--[--><!--]--></a></div></div><div class="content" data-v-822684d1><div class="content-body" data-v-822684d1><!--[--><!--]--><div class="VPNavBarSearch search" data-v-822684d1><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-822684d1 data-v-e6d46098><span id="main-nav-aria-label" class="visually-hidden" data-v-e6d46098> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/d2l-julia/previews/PR1/index" tabindex="0" data-v-e6d46098 data-v-956ec74c><!--[--><span data-v-956ec74c>Home</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup active" data-v-e6d46098 data-v-04f5c5e9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-04f5c5e9><span class="text" data-v-04f5c5e9><!----><span data-v-04f5c5e9>Chapters</span><span class="vpi-chevron-down text-icon" data-v-04f5c5e9></span></span></button><div class="menu" data-v-04f5c5e9><div class="VPMenu" data-v-04f5c5e9 data-v-7dd3104a><div class="items" data-v-7dd3104a><!--[--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/chapters" data-v-acbfed09><!--[--><span data-v-acbfed09>📘 Chapters Overview</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuGroup" data-v-7dd3104a data-v-48c802d0><p class="title" data-v-48c802d0>Linear Neural Networks for Regression</p><!--[--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH3.Linear_Regression/LNN_1" data-v-acbfed09><!--[--><span data-v-acbfed09>Linear Regression</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH3.Linear_Regression/LNN_2" data-v-acbfed09><!--[--><span data-v-acbfed09>Multiple Dispatch Design for Implementation</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH3.Linear_Regression/LNN_3" data-v-acbfed09><!--[--><span data-v-acbfed09>Synthetic Regression Data</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH3.Linear_Regression/LNN_4" data-v-acbfed09><!--[--><span data-v-acbfed09>Linear Regression Implementation from Scratch</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH3.Linear_Regression/LNN_5" data-v-acbfed09><!--[--><span data-v-acbfed09>Concise Implementation of Linear Regression</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH3.Linear_Regression/LNN_6" data-v-acbfed09><!--[--><span data-v-acbfed09>Generalization</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH3.Linear_Regression/LNN_7" data-v-acbfed09><!--[--><span data-v-acbfed09>Weight Decay</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-7dd3104a data-v-48c802d0><p class="title" data-v-48c802d0>Linear Neural Networks for Classification</p><!--[--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH4.Linear_Classification/LCN_1" data-v-acbfed09><!--[--><span data-v-acbfed09>Softmax Regression</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH4.Linear_Classification/LCN_2" data-v-acbfed09><!--[--><span data-v-acbfed09>The Image Classification Dataset</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link active" href="/d2l-julia/previews/PR1/CH4.Linear_Classification/LCN_3" data-v-acbfed09><!--[--><span data-v-acbfed09>Softmax Regression Implementation from Scratch</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH4.Linear_Classification/LCN_4" data-v-acbfed09><!--[--><span data-v-acbfed09>Concise Implementation of Softmax Regression</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH4.Linear_Classification/LCN_5" data-v-acbfed09><!--[--><span data-v-acbfed09>Generalization in Classification</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH4.Linear_Classification/LCN_6" data-v-acbfed09><!--[--><span data-v-acbfed09>Environment and Distribution Shift</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-7dd3104a data-v-48c802d0><p class="title" data-v-48c802d0>Multilayer Perceptron</p><!--[--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH5.MLP/MLP_1" data-v-acbfed09><!--[--><span data-v-acbfed09>Multilayer Perceptrons</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH5.MLP/MLP_2" data-v-acbfed09><!--[--><span data-v-acbfed09>Implementation of Multilayer Perceptrons</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH5.MLP/MLP_3" data-v-acbfed09><!--[--><span data-v-acbfed09>Forward Propagation, Backward Propagation, and Computational Graphs</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH5.MLP/MLP_4" data-v-acbfed09><!--[--><span data-v-acbfed09>Numerical Stability and Initialization</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH5.MLP/MLP_5" data-v-acbfed09><!--[--><span data-v-acbfed09>Generalization in Deep Learning</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH5.MLP/MLP_6" data-v-acbfed09><!--[--><span data-v-acbfed09>Dropout</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-7dd3104a data-v-48c802d0><p class="title" data-v-48c802d0>Convolutional Neural Networks</p><!--[--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH6.Convolutional_Neural_Networks/CNN_2" data-v-acbfed09><!--[--><span data-v-acbfed09>Convolutions for Images</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH6.Convolutional_Neural_Networks/CNN_3" data-v-acbfed09><!--[--><span data-v-acbfed09>Padding and Stride</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH6.Convolutional_Neural_Networks/CNN_4" data-v-acbfed09><!--[--><span data-v-acbfed09>Multiple Input and Multiple Output Channels</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH6.Convolutional_Neural_Networks/CNN_5" data-v-acbfed09><!--[--><span data-v-acbfed09>Pooling</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH6.Convolutional_Neural_Networks/CNN_6" data-v-acbfed09><!--[--><span data-v-acbfed09>Convolutional Neural Networks (LeNet)</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-7dd3104a data-v-48c802d0><p class="title" data-v-48c802d0>Modern Convolutional Neural Networks</p><!--[--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_0" data-v-acbfed09><!--[--><span data-v-acbfed09>Modern Convolutional Neural Networks</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_1" data-v-acbfed09><!--[--><span data-v-acbfed09>Deep Convolutional Neural Networks (AlexNet)</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_2" data-v-acbfed09><!--[--><span data-v-acbfed09>Networks Using Blocks (VGG)</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_3" data-v-acbfed09><!--[--><span data-v-acbfed09>Network in Network (NiN)</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_4" data-v-acbfed09><!--[--><span data-v-acbfed09>Multi-Branch Networks  (GoogLeNet)</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_5" data-v-acbfed09><!--[--><span data-v-acbfed09>Batch Normalization</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_6" data-v-acbfed09><!--[--><span data-v-acbfed09>Residual Networks (ResNet) and ResNeXt</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_7" data-v-acbfed09><!--[--><span data-v-acbfed09>Densely Connected Networks (DenseNet)</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_8" data-v-acbfed09><!--[--><span data-v-acbfed09>Designing Convolution Network Architectures</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-7dd3104a data-v-48c802d0><p class="title" data-v-48c802d0>Recurrent Neural Networks</p><!--[--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_0" data-v-acbfed09><!--[--><span data-v-acbfed09>Recurrent Neural Networks</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_1" data-v-acbfed09><!--[--><span data-v-acbfed09>Working with Sequences</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_2" data-v-acbfed09><!--[--><span data-v-acbfed09>Converting Raw Text into Sequence Data</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_3" data-v-acbfed09><!--[--><span data-v-acbfed09>Language Models</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_4" data-v-acbfed09><!--[--><span data-v-acbfed09>Recurrent Neural Networks</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_5" data-v-acbfed09><!--[--><span data-v-acbfed09>Recurrent Neural Network Implementation from Scratch</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_6" data-v-acbfed09><!--[--><span data-v-acbfed09>Concise Implementation of Recurrent Neural Networks</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_7" data-v-acbfed09><!--[--><span data-v-acbfed09>Backpropagation Through Time</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-7dd3104a data-v-48c802d0><p class="title" data-v-48c802d0>Modern Recurrent Neural Networks</p><!--[--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH9.Modern_Recurrent_Neural_Networks/MRNN_1" data-v-acbfed09><!--[--><span data-v-acbfed09>Long Short-Term Memory (LSTM)</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH9.Modern_Recurrent_Neural_Networks/MRNN_2" data-v-acbfed09><!--[--><span data-v-acbfed09>Gated Recurrent Units (GRU)</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH9.Modern_Recurrent_Neural_Networks/MRNN_3" data-v-acbfed09><!--[--><span data-v-acbfed09>Deep Recurrent Neural Networks</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH9.Modern_Recurrent_Neural_Networks/MRNN_4" data-v-acbfed09><!--[--><span data-v-acbfed09>Bidirectional Recurrent Neural Networks</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH9.Modern_Recurrent_Neural_Networks/MRNN_5" data-v-acbfed09><!--[--><span data-v-acbfed09>Machine Translation and the Dataset</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH9.Modern_Recurrent_Neural_Networks/MRNN_6" data-v-acbfed09><!--[--><span data-v-acbfed09>The Encoder–Decoder Architecture</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH9.Modern_Recurrent_Neural_Networks/MRNN_7" data-v-acbfed09><!--[--><span data-v-acbfed09>Sequence-to-Sequence Learning for Machine Translation</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-7dd3104a data-v-48c802d0><p class="title" data-v-48c802d0>Attention Mechanisms and Transformers</p><!--[--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH10.Attention_Mechanisms_and_Transformers/ATTN_1" data-v-acbfed09><!--[--><span data-v-acbfed09>Queries, Keys, and Values</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH10.Attention_Mechanisms_and_Transformers/ATTN_2" data-v-acbfed09><!--[--><span data-v-acbfed09>Attention Pooling by Similarity</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH10.Attention_Mechanisms_and_Transformers/ATTN_3" data-v-acbfed09><!--[--><span data-v-acbfed09>Attention Scoring Functions</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH10.Attention_Mechanisms_and_Transformers/ATTN_4" data-v-acbfed09><!--[--><span data-v-acbfed09>The Bahdanau Attention Mechanism</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH10.Attention_Mechanisms_and_Transformers/ATTN_5" data-v-acbfed09><!--[--><span data-v-acbfed09>Multi-Head Attention</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH10.Attention_Mechanisms_and_Transformers/ATTN_6" data-v-acbfed09><!--[--><span data-v-acbfed09>Self-Attention and Positional Encoding</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH10.Attention_Mechanisms_and_Transformers/Untitled" data-v-acbfed09><!--[--><span data-v-acbfed09>CH10.Attention_Mechanisms_and_Transformers/Untitled</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/d2l-julia/previews/PR1/references" tabindex="0" data-v-e6d46098 data-v-956ec74c><!--[--><span data-v-956ec74c>References</span><!--]--></a><!--]--><!--[--><!----><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-822684d1 data-v-af096f4a><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-af096f4a data-v-e40a8bb6 data-v-4a1c76db><span class="check" data-v-4a1c76db><span class="icon" data-v-4a1c76db><!--[--><span class="vpi-sun sun" data-v-e40a8bb6></span><span class="vpi-moon moon" data-v-e40a8bb6></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-822684d1 data-v-164c457f data-v-ee7a9424><!--[--><a class="VPSocialLink no-icon" href="https://github.com/ashutosh-b-b/d2l-julia" aria-label="github" target="_blank" rel="noopener" data-v-ee7a9424 data-v-d26d30cb><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-822684d1 data-v-925effce data-v-04f5c5e9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-04f5c5e9><span class="vpi-more-horizontal icon" data-v-04f5c5e9></span></button><div class="menu" data-v-04f5c5e9><div class="VPMenu" data-v-04f5c5e9 data-v-7dd3104a><!----><!--[--><!--[--><!----><div class="group" data-v-925effce><div class="item appearance" data-v-925effce><p class="label" data-v-925effce>Appearance</p><div class="appearance-action" data-v-925effce><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-925effce data-v-e40a8bb6 data-v-4a1c76db><span class="check" data-v-4a1c76db><span class="icon" data-v-4a1c76db><!--[--><span class="vpi-sun sun" data-v-e40a8bb6></span><span class="vpi-moon moon" data-v-e40a8bb6></span><!--]--></span></span></button></div></div></div><div class="group" data-v-925effce><div class="item social-links" data-v-925effce><div class="VPSocialLinks social-links-list" data-v-925effce data-v-ee7a9424><!--[--><a class="VPSocialLink no-icon" href="https://github.com/ashutosh-b-b/d2l-julia" aria-label="github" target="_blank" rel="noopener" data-v-ee7a9424 data-v-d26d30cb><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--[--><!--[--><div class="VPFlyout VPNolebaseEnhancedReadabilitiesMenu VPNolebaseEnhancedReadabilitiesMenuFlyout" aria-label="Enhanced Readability" role="menuitem" data-v-04f5c5e9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-04f5c5e9><span class="text" data-v-04f5c5e9><span class="i-icon-park-outline:book-open option-icon" data-v-04f5c5e9></span><!----><span class="vpi-chevron-down text-icon" data-v-04f5c5e9></span></span></button><div class="menu" data-v-04f5c5e9><div class="VPMenu" data-v-04f5c5e9 data-v-7dd3104a><!----><!--[--><!--]--></div></div></div><!--]--><!--]--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-822684d1 data-v-5dea55bf><span class="container" data-v-5dea55bf><span class="top" data-v-5dea55bf></span><span class="middle" data-v-5dea55bf></span><span class="bottom" data-v-5dea55bf></span></span></button></div></div></div></div><div class="divider" data-v-822684d1><div class="divider-line" data-v-822684d1></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-a9a9e638 data-v-070ab83d><div class="container" data-v-070ab83d><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-070ab83d><span class="vpi-align-left menu-icon" data-v-070ab83d></span><span class="menu-text" data-v-070ab83d>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-070ab83d data-v-168ddf5d><button data-v-168ddf5d>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-a9a9e638 data-v-18756405><div class="curtain" data-v-18756405></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-18756405><span class="visually-hidden" id="sidebar-aria-label" data-v-18756405> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-9e426adc><section class="VPSidebarItem level-0" data-v-9e426adc data-v-a4b0d9bf><!----><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/index" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Home</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-9e426adc><section class="VPSidebarItem level-0 collapsible has-active" data-v-9e426adc data-v-a4b0d9bf><div class="item" role="button" tabindex="0" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><h2 class="text" data-v-a4b0d9bf>Chapters</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-a4b0d9bf><span class="vpi-chevron-right caret-icon" data-v-a4b0d9bf></span></div></div><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/chapters" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>📘 Chapters Overview</p><!--]--></a><!----></div><!----></div><section class="VPSidebarItem level-1 collapsible" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" role="button" tabindex="0" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><h3 class="text" data-v-a4b0d9bf>Linear Neural Networks for Regression</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-a4b0d9bf><span class="vpi-chevron-right caret-icon" data-v-a4b0d9bf></span></div></div><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH3.Linear_Regression/LNN_1" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Linear Regression</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH3.Linear_Regression/LNN_2" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Multiple Dispatch Design for Implementation</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH3.Linear_Regression/LNN_3" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Synthetic Regression Data</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH3.Linear_Regression/LNN_4" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Linear Regression Implementation from Scratch</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH3.Linear_Regression/LNN_5" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Concise Implementation of Linear Regression</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH3.Linear_Regression/LNN_6" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Generalization</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH3.Linear_Regression/LNN_7" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Weight Decay</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible has-active" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" role="button" tabindex="0" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><h3 class="text" data-v-a4b0d9bf>Linear Neural Networks for Classification</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-a4b0d9bf><span class="vpi-chevron-right caret-icon" data-v-a4b0d9bf></span></div></div><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH4.Linear_Classification/LCN_1" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Softmax Regression</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH4.Linear_Classification/LCN_2" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>The Image Classification Dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH4.Linear_Classification/LCN_3" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Softmax Regression Implementation from Scratch</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH4.Linear_Classification/LCN_4" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Concise Implementation of Softmax Regression</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH4.Linear_Classification/LCN_5" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Generalization in Classification</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH4.Linear_Classification/LCN_6" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Environment and Distribution Shift</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" role="button" tabindex="0" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><h3 class="text" data-v-a4b0d9bf>Multilayer Perceptron</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-a4b0d9bf><span class="vpi-chevron-right caret-icon" data-v-a4b0d9bf></span></div></div><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH5.MLP/MLP_1" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Multilayer Perceptrons</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH5.MLP/MLP_2" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Implementation of Multilayer Perceptrons</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH5.MLP/MLP_3" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Forward Propagation, Backward Propagation, and Computational Graphs</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH5.MLP/MLP_4" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Numerical Stability and Initialization</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH5.MLP/MLP_5" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Generalization in Deep Learning</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH5.MLP/MLP_6" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Dropout</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" role="button" tabindex="0" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><h3 class="text" data-v-a4b0d9bf>Convolutional Neural Networks</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-a4b0d9bf><span class="vpi-chevron-right caret-icon" data-v-a4b0d9bf></span></div></div><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH6.Convolutional_Neural_Networks/CNN_2" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Convolutions for Images</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH6.Convolutional_Neural_Networks/CNN_3" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Padding and Stride</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH6.Convolutional_Neural_Networks/CNN_4" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Multiple Input and Multiple Output Channels</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH6.Convolutional_Neural_Networks/CNN_5" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Pooling</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH6.Convolutional_Neural_Networks/CNN_6" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Convolutional Neural Networks (LeNet)</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" role="button" tabindex="0" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><h3 class="text" data-v-a4b0d9bf>Modern Convolutional Neural Networks</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-a4b0d9bf><span class="vpi-chevron-right caret-icon" data-v-a4b0d9bf></span></div></div><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_0" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Modern Convolutional Neural Networks</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_1" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Deep Convolutional Neural Networks (AlexNet)</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_2" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Networks Using Blocks (VGG)</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_3" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Network in Network (NiN)</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_4" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Multi-Branch Networks  (GoogLeNet)</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_5" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Batch Normalization</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_6" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Residual Networks (ResNet) and ResNeXt</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_7" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Densely Connected Networks (DenseNet)</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_8" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Designing Convolution Network Architectures</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" role="button" tabindex="0" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><h3 class="text" data-v-a4b0d9bf>Recurrent Neural Networks</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-a4b0d9bf><span class="vpi-chevron-right caret-icon" data-v-a4b0d9bf></span></div></div><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_0" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Recurrent Neural Networks</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_1" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Working with Sequences</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_2" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Converting Raw Text into Sequence Data</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_3" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Language Models</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_4" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Recurrent Neural Networks</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_5" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Recurrent Neural Network Implementation from Scratch</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_6" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Concise Implementation of Recurrent Neural Networks</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_7" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Backpropagation Through Time</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" role="button" tabindex="0" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><h3 class="text" data-v-a4b0d9bf>Modern Recurrent Neural Networks</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-a4b0d9bf><span class="vpi-chevron-right caret-icon" data-v-a4b0d9bf></span></div></div><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH9.Modern_Recurrent_Neural_Networks/MRNN_1" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Long Short-Term Memory (LSTM)</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH9.Modern_Recurrent_Neural_Networks/MRNN_2" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Gated Recurrent Units (GRU)</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH9.Modern_Recurrent_Neural_Networks/MRNN_3" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Deep Recurrent Neural Networks</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH9.Modern_Recurrent_Neural_Networks/MRNN_4" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Bidirectional Recurrent Neural Networks</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH9.Modern_Recurrent_Neural_Networks/MRNN_5" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Machine Translation and the Dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH9.Modern_Recurrent_Neural_Networks/MRNN_6" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>The Encoder–Decoder Architecture</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH9.Modern_Recurrent_Neural_Networks/MRNN_7" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Sequence-to-Sequence Learning for Machine Translation</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" role="button" tabindex="0" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><h3 class="text" data-v-a4b0d9bf>Attention Mechanisms and Transformers</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-a4b0d9bf><span class="vpi-chevron-right caret-icon" data-v-a4b0d9bf></span></div></div><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH10.Attention_Mechanisms_and_Transformers/ATTN_1" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Queries, Keys, and Values</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH10.Attention_Mechanisms_and_Transformers/ATTN_2" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Attention Pooling by Similarity</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH10.Attention_Mechanisms_and_Transformers/ATTN_3" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Attention Scoring Functions</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH10.Attention_Mechanisms_and_Transformers/ATTN_4" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>The Bahdanau Attention Mechanism</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH10.Attention_Mechanisms_and_Transformers/ATTN_5" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Multi-Head Attention</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH10.Attention_Mechanisms_and_Transformers/ATTN_6" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Self-Attention and Positional Encoding</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH10.Attention_Mechanisms_and_Transformers/Untitled" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>CH10.Attention_Mechanisms_and_Transformers/Untitled</p><!--]--></a><!----></div><!----></div><!--]--></div></section><!--]--></div></section></div><div class="no-transition group" data-v-9e426adc><section class="VPSidebarItem level-0" data-v-9e426adc data-v-a4b0d9bf><!----><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/references" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>References</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-a9a9e638 data-v-91765379><div class="VPDoc has-sidebar has-aside" data-v-91765379 data-v-83890dd9><!--[--><!--]--><div class="container" data-v-83890dd9><div class="aside" data-v-83890dd9><div class="aside-curtain" data-v-83890dd9></div><div class="aside-container" data-v-83890dd9><div class="aside-content" data-v-83890dd9><div class="VPDocAside" data-v-83890dd9 data-v-6d7b3c46><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-6d7b3c46 data-v-b38bf2ff><div class="content" data-v-b38bf2ff><div class="outline-marker" data-v-b38bf2ff></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-b38bf2ff>On this page</div><ul class="VPDocOutlineItem root" data-v-b38bf2ff data-v-3f927ebe><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-6d7b3c46></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-83890dd9><div class="content-container" data-v-83890dd9><!--[--><!--]--><main class="main" data-v-83890dd9><div style="position:relative;" class="vp-doc _d2l-julia_previews_PR1_CH4_Linear_Classification_LCN_3" data-v-83890dd9><div><h1 id="sec_softmax_scratch" tabindex="-1">Softmax Regression Implementation from Scratch <a class="header-anchor" href="#sec_softmax_scratch" aria-label="Permalink to &quot;Softmax Regression Implementation from Scratch {#sec_softmax_scratch}&quot;">​</a></h1><p>Because softmax regression is so fundamental, we believe that you ought to know how to implement it yourself. Here, we limit ourselves to defining the softmax-specific aspects of the model and reuse the other components from our linear regression section, including the training loop.</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">using</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Pkg;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Pkg</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">activate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;../../d2lai&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">using</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> d2lai, Flux, Plots, Statistics</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">using</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Distributions</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>  Activating project at `/workspace/workspace/d2l-julia/d2lai`</span></span></code></pre></div><h2 id="The-Softmax" tabindex="-1">The Softmax <a class="header-anchor" href="#The-Softmax" aria-label="Permalink to &quot;The Softmax {#The-Softmax}&quot;">​</a></h2><p>Let&#39;s begin with the most important part: the mapping from scalars to probabilities. For a refresher, recall the operation of the sum operator along specific dimensions in a tensor, as discussed in :numref:<code>subsec_lin-alg-reduction</code> and :numref:<code>subsec_lin-alg-non-reduction</code>. Given a matrix <code>X</code> we can sum over all elements (by default) or only over elements in the same axis. The <code>axis</code> variable lets us compute row and column sums:</p><p>Computing the softmax requires three steps: (i) exponentiation of each term; (ii) a sum over each row to compute the normalization constant for each example; (iii) division of each row by its normalization constant, ensuring that the result sums to 1:</p><mjx-container class="MathJax" jax="SVG" display="true" style="direction:ltr;display:block;text-align:center;margin:1em 0;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-2.27ex;" xmlns="http://www.w3.org/2000/svg" width="30.116ex" height="5.673ex" role="img" focusable="false" viewBox="0 -1504.2 13311.3 2507.4" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" style="stroke-width:3;"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(394,0)" style="stroke-width:3;"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(894,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1200,0)" style="stroke-width:3;"></path><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1589,0)" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2422,0)" style="stroke-width:3;"></path><path data-c="78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z" transform="translate(2922,0)" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(3450,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(3839,0)"><g data-mml-node="mi"><path data-c="1D417" d="M327 0Q306 3 174 3Q52 3 43 0H33V62H98L162 63L360 333L157 624H48V686H59Q80 683 217 683Q368 683 395 686H408V624H335L393 540L452 458L573 623Q573 624 528 624H483V686H494Q515 683 646 683Q769 683 778 686H787V624H658L575 511Q493 398 493 397L508 376Q522 356 553 312T611 229L727 62H835V0H824Q803 3 667 3Q516 3 489 0H476V62H513L549 63L401 274L247 63Q247 62 292 62H338V0H327Z" style="stroke-width:3;"></path></g></g><g data-mml-node="msub" transform="translate(4708,0)"><g data-mml-node="mo"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(422,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(345,0)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z" style="stroke-width:3;"></path></g></g></g><g data-mml-node="mo" transform="translate(5993.1,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mfrac" transform="translate(7048.8,0)"><g data-mml-node="mrow" transform="translate(1095.6,754.2)"><g data-mml-node="mi"><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" style="stroke-width:3;"></path><path data-c="78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z" transform="translate(444,0)" style="stroke-width:3;"></path><path data-c="70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z" transform="translate(972,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1528,0)"><path data-c="2061" d="" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1528,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(1917,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D417" d="M327 0Q306 3 174 3Q52 3 43 0H33V62H98L162 63L360 333L157 624H48V686H59Q80 683 217 683Q368 683 395 686H408V624H335L393 540L452 458L573 623Q573 624 528 624H483V686H494Q515 683 646 683Q769 683 778 686H787V624H658L575 511Q493 398 493 397L508 376Q522 356 553 312T611 229L727 62H835V0H824Q803 3 667 3Q516 3 489 0H476V62H513L549 63L401 274L247 63Q247 62 292 62H338V0H327Z" style="stroke-width:3;"></path></g></g><g data-mml-node="TeXAtom" transform="translate(902,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(345,0)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z" style="stroke-width:3;"></path></g></g></g><g data-mml-node="mo" transform="translate(3404.3,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mrow" transform="translate(220,-710)"><g data-mml-node="munder"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(1089,-285.4) scale(0.707)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mi" transform="translate(1674.1,0)"><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" style="stroke-width:3;"></path><path data-c="78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z" transform="translate(444,0)" style="stroke-width:3;"></path><path data-c="70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z" transform="translate(972,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3202.1,0)"><path data-c="2061" d="" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3202.1,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(3591.1,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D417" d="M327 0Q306 3 174 3Q52 3 43 0H33V62H98L162 63L360 333L157 624H48V686H59Q80 683 217 683Q368 683 395 686H408V624H335L393 540L452 458L573 623Q573 624 528 624H483V686H494Q515 683 646 683Q769 683 778 686H787V624H658L575 511Q493 398 493 397L508 376Q522 356 553 312T611 229L727 62H835V0H824Q803 3 667 3Q516 3 489 0H476V62H513L549 63L401 274L247 63Q247 62 292 62H338V0H327Z" style="stroke-width:3;"></path></g></g><g data-mml-node="TeXAtom" transform="translate(902,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(345,0)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z" style="stroke-width:3;"></path></g></g></g><g data-mml-node="mo" transform="translate(5155.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g><rect width="5744.4" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(13033.3,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;overflow:hidden;width:100%;"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow data-mjx-texclass="ORD"><mi data-mjx-auto-op="false">softmax</mi></mrow><mo stretchy="false">(</mo><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">X</mi></mrow><msub><mo stretchy="false">)</mo><mrow data-mjx-texclass="ORD"><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mfrac><mrow><mi>exp</mi><mo data-mjx-texclass="NONE">⁡</mo><mo stretchy="false">(</mo><msub><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">X</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">)</mo></mrow><mrow><munder><mo data-mjx-texclass="OP">∑</mo><mi>k</mi></munder><mi>exp</mi><mo data-mjx-texclass="NONE">⁡</mo><mo stretchy="false">(</mo><msub><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">X</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi><mi>k</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mfrac><mo>.</mo></math></mjx-assistive-mml></mjx-container><p>The (logarithm of the) denominator is called the (log) <em>partition function</em>. It was introduced in <a href="https://en.wikipedia.org/wiki/Partition_function_(statistical_mechanics)" target="_blank" rel="noreferrer">statistical physics</a> to sum over all possible states in a thermodynamic ensemble. The implementation is straightforward:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">function</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> softmax</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(o)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> exp</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.(o) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">./</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> sum</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">exp</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.(o), dims </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">end</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>softmax (generic function with 1 method)</span></span></code></pre></div><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> rand</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">X_prob </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> softmax</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(X)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">X_prob, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">sum</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(X_prob, dims </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>([0.18117506870593342 0.1320529047784991; 0.24739251918615013 0.2387184813952434; … ; 0.1465060090769004 0.14550354373976027; 0.20560534251721646 0.283534812827121], [1.0 0.9999999999999999])</span></span></code></pre></div><h2 id="The-Model" tabindex="-1">The Model <a class="header-anchor" href="#The-Model" aria-label="Permalink to &quot;The Model {#The-Model}&quot;">​</a></h2><p>We now have everything that we need to implement the softmax regression model. As in our linear regression example, each instance will be represented by a fixed-length vector. Since the raw data here consists of <mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.05ex;" xmlns="http://www.w3.org/2000/svg" width="7.291ex" height="1.557ex" role="img" focusable="false" viewBox="0 -666 3222.4 688" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" style="stroke-width:3;"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(500,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1222.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(2222.4,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" style="stroke-width:3;"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(500,0)" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>28</mn><mo>×</mo><mn>28</mn></math></mjx-assistive-mml></mjx-container> pixel images, we flatten each image, treating them as vectors of length 784. In later chapters, we will introduce convolutional neural networks, which exploit the spatial structure in a more satisfying way.</p><p>In softmax regression, the number of outputs from our network should be equal to the number of classes. Since our dataset has 10 classes, our network has an output dimension of 10. Consequently, our weights constitute a <mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.05ex;" xmlns="http://www.w3.org/2000/svg" width="8.422ex" height="1.581ex" role="img" focusable="false" viewBox="0 -677 3722.4 699" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="37" d="M55 458Q56 460 72 567L88 674Q88 676 108 676H128V672Q128 662 143 655T195 646T364 644H485V605L417 512Q408 500 387 472T360 435T339 403T319 367T305 330T292 284T284 230T278 162T275 80Q275 66 275 52T274 28V19Q270 2 255 -10T221 -22Q210 -22 200 -19T179 0T168 40Q168 198 265 368Q285 400 349 489L395 552H302Q128 552 119 546Q113 543 108 522T98 479L95 458V455H55V458Z" style="stroke-width:3;"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(500,0)" style="stroke-width:3;"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(1000,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1722.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(2722.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>784</mn><mo>×</mo><mn>10</mn></math></mjx-assistive-mml></mjx-container> matrix plus a <mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.05ex;" xmlns="http://www.w3.org/2000/svg" width="6.159ex" height="1.557ex" role="img" focusable="false" viewBox="0 -666 2722.4 688" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(1722.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1</mn><mo>×</mo><mn>10</mn></math></mjx-assistive-mml></mjx-container> row vector for the biases. As with linear regression, we initialize the weights <code>W</code> with Gaussian noise. The biases are initialized as zeros.</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">struct</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> SoftmaxRegressionScratch{A} </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> d2lai.AbstractClassifier</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    w</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">AbstractArray</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    b</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">AbstractArray</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    args</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">A</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">end</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">function</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> SoftmaxRegressionScratch</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(num_inputs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Int64</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, num_outputs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Int64</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, lr, sigma</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.01</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    w </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> rand</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Normal</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, sigma), (num_outputs, num_inputs))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    b </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> zeros</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(num_outputs, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    args </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (num_inputs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> num_inputs, num_outputs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> num_outputs, lr </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> lr, sigma </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sigma)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    SoftmaxRegressionScratch</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(w, b, args)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">end</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Flux</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">@layer</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> SoftmaxRegressionScratch trainable</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(w,b)</span></span></code></pre></div><p>The code below defines how the network maps each input to an output. Note that we flatten each <mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.05ex;" xmlns="http://www.w3.org/2000/svg" width="7.291ex" height="1.557ex" role="img" focusable="false" viewBox="0 -666 3222.4 688" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" style="stroke-width:3;"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(500,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1222.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(2222.4,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" style="stroke-width:3;"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(500,0)" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>28</mn><mo>×</mo><mn>28</mn></math></mjx-assistive-mml></mjx-container> pixel image in the batch into a vector using <code>reshape</code> before passing the data through our model.</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">function</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> d2lai</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">SoftmaxRegressionScratch</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, x)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    softmax</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">w </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x  </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.+</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">b)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">end</span></span></code></pre></div><h2 id="The-Cross-Entropy-Loss" tabindex="-1">The Cross-Entropy Loss <a class="header-anchor" href="#The-Cross-Entropy-Loss" aria-label="Permalink to &quot;The Cross-Entropy Loss {#The-Cross-Entropy-Loss}&quot;">​</a></h2><p>Next we need to implement the cross-entropy loss function (introduced in :numref:<code>subsec_softmax-regression-loss-func</code>). This may be the most common loss function in all of deep learning. At the moment, applications of deep learning easily cast as classification problems far outnumber those better treated as regression problems.</p><p>Recall that cross-entropy takes the negative log-likelihood of the predicted probability assigned to the true label. For efficiency we avoid Python for-loops and use indexing instead. In particular, the one-hot encoding in <mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.452ex;" xmlns="http://www.w3.org/2000/svg" width="1.373ex" height="1.457ex" role="img" focusable="false" viewBox="0 -444 607 644" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D432" d="M84 -102Q84 -110 87 -119T102 -138T133 -149Q148 -148 162 -143T186 -131T206 -114T222 -95T234 -76T243 -59T249 -45T252 -37L269 0L96 382H26V444H34Q49 441 146 441Q252 441 270 444H279V382H255Q232 382 232 380L337 151L442 382H394V444H401Q413 441 495 441Q568 441 574 444H580V382H510L406 152Q298 -84 297 -87Q269 -139 225 -169T131 -200Q85 -200 54 -172T23 -100Q23 -64 44 -50T87 -35Q111 -35 130 -50T152 -92V-100H84V-102Z" style="stroke-width:3;"></path></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">y</mi></mrow></math></mjx-assistive-mml></mjx-container> allows us to select the matching terms in <mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.452ex;" xmlns="http://www.w3.org/2000/svg" width="1.373ex" height="2.29ex" role="img" focusable="false" viewBox="0 -812 607 1012" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D432" d="M84 -102Q84 -110 87 -119T102 -138T133 -149Q148 -148 162 -143T186 -131T206 -114T222 -95T234 -76T243 -59T249 -45T252 -37L269 0L96 382H26V444H34Q49 441 146 441Q252 441 270 444H279V382H255Q232 382 232 380L337 151L442 382H394V444H401Q413 441 495 441Q568 441 574 444H580V382H510L406 152Q298 -84 297 -87Q269 -139 225 -169T131 -200Q85 -200 54 -172T23 -100Q23 -64 44 -50T87 -35Q111 -35 130 -50T152 -92V-100H84V-102Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(303.5,18) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z" style="stroke-width:3;"></path></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mover><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">y</mi></mrow><mo stretchy="false">^</mo></mover></mrow></math></mjx-assistive-mml></mjx-container>.</p><p>To see this in action we create sample data <code>y_hat</code> with 2 examples of predicted probabilities over 3 classes and their corresponding labels <code>y</code>. The correct labels are <mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.05ex;" xmlns="http://www.w3.org/2000/svg" width="1.131ex" height="1.557ex" role="img" focusable="false" viewBox="0 -666 500 688" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>0</mn></math></mjx-assistive-mml></mjx-container> and <mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:0;" xmlns="http://www.w3.org/2000/svg" width="1.131ex" height="1.507ex" role="img" focusable="false" viewBox="0 -666 500 666" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>2</mn></math></mjx-assistive-mml></mjx-container> respectively (i.e., the first and third class). Using <code>y</code> as the indices of the probabilities in <code>y_hat</code>, we can pick out terms efficiently.</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">y </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">y_hat </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.3</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.6</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]; [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.3</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.2</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]]</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&#39;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> |&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Matrix</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">getindex</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">eachcol</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(y_hat), y)</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>2-element Vector{Float64}:</span></span>
<span class="line"><span> 0.1</span></span>
<span class="line"><span> 0.5</span></span></code></pre></div><p>Now we can implement the cross-entropy loss function by averaging over the logarithms of the selected probabilities.</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">function</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> cross_entropy</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(y_pred, y)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    actual_class_prob </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> getindex</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">eachcol</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(y_pred), y)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> mean</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">log</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.(actual_class_prob))</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">end</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">cross_entropy</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(y_hat, y)</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>1.4978661367769954</span></span></code></pre></div><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">function</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> d2lai</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">loss</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">AbstractClassifier</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, y_pred, y)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # cross entropy </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    actual_class_prob </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> getindex</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">eachcol</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(y_pred), y </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> mean</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">log</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.(actual_class_prob))</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">end</span></span></code></pre></div><h2 id="Training" tabindex="-1">Training <a class="header-anchor" href="#Training" aria-label="Permalink to &quot;Training {#Training}&quot;">​</a></h2><p>We reuse the <code>fit</code> method defined in :numref:<code>sec_linear_scratch</code> to train the model with 10 epochs. Note that the number of epochs (<code>max_epochs</code>), the minibatch size (<code>batch_size</code>), and learning rate (<code>lr</code>) are adjustable hyperparameters. That means that while these values are not learned during our primary training loop, they still influence the performance of our model, both vis-à-vis training and generalization performance. In practice you will want to choose these values based on the <em>validation</em> split of the data and then, ultimately, to evaluate your final model on the <em>test</em> split. As discussed in :numref:<code>subsec_generalization-model-selection</code>, we will regard the test data of Fashion-MNIST as the validation set, thus reporting validation loss and validation accuracy on this split.</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">function</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> d2lai</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">fit_epoch</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">SoftmaxRegressionScratch</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, opt; train_dataloader </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> nothing</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, val_dataloader </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> nothing</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, gradient_clip_val </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    losses </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (train_losses </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [], val_losses </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [], val_acc </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [])</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    state </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Flux</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">setup</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(opt, model)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> batch </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> train_dataloader</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        gs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> gradient</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(model) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">do</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> m</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">            training_step</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(m, batch)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        end</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        Flux</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Optimise</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">update!</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(state, model, gs[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        train_loss </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> training_step</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(trainer</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model, batch)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        push!</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(losses</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">train_losses, train_loss)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    end</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> batch </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> val_dataloader</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        loss, acc </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> validation_step</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(trainer</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model, batch)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        push!</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(losses</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">val_losses , loss)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        push!</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(losses</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">val_acc, acc)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    end</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> losses</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">end</span></span></code></pre></div><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> SoftmaxRegressionScratch</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">784</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">opt </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> Descent</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.01</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">data </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> d2lai</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">FashionMNISTData</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(; batchsize </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, flatten </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> true</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">trainer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> Trainer</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(model, data, opt; max_epochs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">d2lai</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">fit</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(trainer)</span></span></code></pre></div><div style="max-height:300px;overflow-y:auto;background:#111;color:#eee;padding:1em;border-radius:5px;"><pre>    [ Info: Train Loss: 0.9744505899322733, Val Loss: 0.9459513653103493, Val Acc: 0.75
    [ Info: Train Loss: 0.857556675666966, Val Loss: 0.701497704394115, Val Acc: 0.8125
    [ Info: Train Loss: 0.6600560679149684, Val Loss: 0.586742316206024, Val Acc: 0.875
    [ Info: Train Loss: 0.6611845959614387, Val Loss: 0.5228459546142031, Val Acc: 0.875
    [ Info: Train Loss: 0.719965036150105, Val Loss: 0.4808186144074479, Val Acc: 0.875
    [ Info: Train Loss: 0.7226191125527701, Val Loss: 0.4522466632336129, Val Acc: 0.875
    [ Info: Train Loss: 0.5812198798524878, Val Loss: 0.42927084792834885, Val Acc: 0.9375
    [ Info: Train Loss: 0.5280942875767, Val Loss: 0.41469051986271566, Val Acc: 0.875
    [ Info: Train Loss: 0.6031487317898956, Val Loss: 0.4031099984548729, Val Acc: 0.875
    [ Info: Train Loss: 0.6575735590717978, Val Loss: 0.39428948561702787, Val Acc: 0.875</pre></div><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="600" height="400" viewBox="0 0 2400 1600"><defs><clipPath id="clip930"><rect x="0" y="0" width="2400" height="1600"></rect></clipPath></defs><path clip-path="url(#clip930)" d="M0 1600 L2400 1600 L2400 0 L0 0  Z" fill="#ffffff" fill-rule="evenodd" fill-opacity="1"></path><defs><clipPath id="clip931"><rect x="480" y="0" width="1681" height="1600"></rect></clipPath></defs><path clip-path="url(#clip930)" d="M224.554 1423.18 L2352.76 1423.18 L2352.76 47.2441 L224.554 47.2441  Z" fill="#ffffff" fill-rule="evenodd" fill-opacity="1"></path><defs><clipPath id="clip932"><rect x="224" y="47" width="2129" height="1377"></rect></clipPath></defs><polyline clip-path="url(#clip932)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:2;stroke-opacity:0.1;fill:none;" points="507.868,1423.18 507.868,47.2441 "></polyline><polyline clip-path="url(#clip932)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:2;stroke-opacity:0.1;fill:none;" points="954.032,1423.18 954.032,47.2441 "></polyline><polyline clip-path="url(#clip932)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:2;stroke-opacity:0.1;fill:none;" points="1400.2,1423.18 1400.2,47.2441 "></polyline><polyline clip-path="url(#clip932)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:2;stroke-opacity:0.1;fill:none;" points="1846.36,1423.18 1846.36,47.2441 "></polyline><polyline clip-path="url(#clip932)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:2;stroke-opacity:0.1;fill:none;" points="2292.52,1423.18 2292.52,47.2441 "></polyline><polyline clip-path="url(#clip932)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:2;stroke-opacity:0.1;fill:none;" points="224.554,1313.48 2352.76,1313.48 "></polyline><polyline clip-path="url(#clip932)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:2;stroke-opacity:0.1;fill:none;" points="224.554,571.037 2352.76,571.037 "></polyline><polyline clip-path="url(#clip930)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="224.554,1423.18 2352.76,1423.18 "></polyline><polyline clip-path="url(#clip930)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="507.868,1423.18 507.868,1404.28 "></polyline><polyline clip-path="url(#clip930)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="954.032,1423.18 954.032,1404.28 "></polyline><polyline clip-path="url(#clip930)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="1400.2,1423.18 1400.2,1404.28 "></polyline><polyline clip-path="url(#clip930)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="1846.36,1423.18 1846.36,1404.28 "></polyline><polyline clip-path="url(#clip930)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="2292.52,1423.18 2292.52,1404.28 "></polyline><path clip-path="url(#clip930)" d="M502.521 1481.64 L518.84 1481.64 L518.84 1485.58 L496.896 1485.58 L496.896 1481.64 Q499.558 1478.89 504.141 1474.26 Q508.747 1469.61 509.928 1468.27 Q512.173 1465.74 513.053 1464.01 Q513.956 1462.25 513.956 1460.56 Q513.956 1457.8 512.011 1456.07 Q510.09 1454.33 506.988 1454.33 Q504.789 1454.33 502.335 1455.09 Q499.905 1455.86 497.127 1457.41 L497.127 1452.69 Q499.951 1451.55 502.405 1450.97 Q504.858 1450.39 506.896 1450.39 Q512.266 1450.39 515.46 1453.08 Q518.655 1455.77 518.655 1460.26 Q518.655 1462.39 517.845 1464.31 Q517.058 1466.2 514.951 1468.8 Q514.372 1469.47 511.271 1472.69 Q508.169 1475.88 502.521 1481.64 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M957.041 1455.09 L945.235 1473.54 L957.041 1473.54 L957.041 1455.09 M955.814 1451.02 L961.694 1451.02 L961.694 1473.54 L966.624 1473.54 L966.624 1477.43 L961.694 1477.43 L961.694 1485.58 L957.041 1485.58 L957.041 1477.43 L941.439 1477.43 L941.439 1472.92 L955.814 1451.02 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M1400.6 1466.44 Q1397.45 1466.44 1395.6 1468.59 Q1393.77 1470.74 1393.77 1474.49 Q1393.77 1478.22 1395.6 1480.39 Q1397.45 1482.55 1400.6 1482.55 Q1403.75 1482.55 1405.58 1480.39 Q1407.43 1478.22 1407.43 1474.49 Q1407.43 1470.74 1405.58 1468.59 Q1403.75 1466.44 1400.6 1466.44 M1409.88 1451.78 L1409.88 1456.04 Q1408.12 1455.21 1406.32 1454.77 Q1404.54 1454.33 1402.78 1454.33 Q1398.15 1454.33 1395.69 1457.45 Q1393.26 1460.58 1392.92 1466.9 Q1394.28 1464.89 1396.34 1463.82 Q1398.4 1462.73 1400.88 1462.73 Q1406.09 1462.73 1409.1 1465.9 Q1412.13 1469.05 1412.13 1474.49 Q1412.13 1479.82 1408.98 1483.03 Q1405.83 1486.25 1400.6 1486.25 Q1394.61 1486.25 1391.43 1481.67 Q1388.26 1477.06 1388.26 1468.33 Q1388.26 1460.14 1392.15 1455.28 Q1396.04 1450.39 1402.59 1450.39 Q1404.35 1450.39 1406.13 1450.74 Q1407.94 1451.09 1409.88 1451.78 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M1846.36 1469.17 Q1843.03 1469.17 1841.11 1470.95 Q1839.21 1472.73 1839.21 1475.86 Q1839.21 1478.98 1841.11 1480.77 Q1843.03 1482.55 1846.36 1482.55 Q1849.69 1482.55 1851.61 1480.77 Q1853.54 1478.96 1853.54 1475.86 Q1853.54 1472.73 1851.61 1470.95 Q1849.72 1469.17 1846.36 1469.17 M1841.68 1467.18 Q1838.67 1466.44 1836.98 1464.38 Q1835.32 1462.32 1835.32 1459.35 Q1835.32 1455.21 1838.26 1452.8 Q1841.22 1450.39 1846.36 1450.39 Q1851.52 1450.39 1854.46 1452.8 Q1857.4 1455.21 1857.4 1459.35 Q1857.4 1462.32 1855.71 1464.38 Q1854.04 1466.44 1851.06 1467.18 Q1854.44 1467.96 1856.31 1470.26 Q1858.21 1472.55 1858.21 1475.86 Q1858.21 1480.88 1855.13 1483.57 Q1852.08 1486.25 1846.36 1486.25 Q1840.64 1486.25 1837.56 1483.57 Q1834.51 1480.88 1834.51 1475.86 Q1834.51 1472.55 1836.41 1470.26 Q1838.3 1467.96 1841.68 1467.18 M1839.97 1459.79 Q1839.97 1462.48 1841.64 1463.98 Q1843.33 1465.49 1846.36 1465.49 Q1849.37 1465.49 1851.06 1463.98 Q1852.77 1462.48 1852.77 1459.79 Q1852.77 1457.11 1851.06 1455.6 Q1849.37 1454.1 1846.36 1454.1 Q1843.33 1454.1 1841.64 1455.6 Q1839.97 1457.11 1839.97 1459.79 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M2267.21 1481.64 L2274.85 1481.64 L2274.85 1455.28 L2266.54 1456.95 L2266.54 1452.69 L2274.8 1451.02 L2279.48 1451.02 L2279.48 1481.64 L2287.12 1481.64 L2287.12 1485.58 L2267.21 1485.58 L2267.21 1481.64 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M2306.56 1454.1 Q2302.95 1454.1 2301.12 1457.66 Q2299.32 1461.2 2299.32 1468.33 Q2299.32 1475.44 2301.12 1479.01 Q2302.95 1482.55 2306.56 1482.55 Q2310.2 1482.55 2312 1479.01 Q2313.83 1475.44 2313.83 1468.33 Q2313.83 1461.2 2312 1457.66 Q2310.2 1454.1 2306.56 1454.1 M2306.56 1450.39 Q2312.37 1450.39 2315.43 1455 Q2318.51 1459.58 2318.51 1468.33 Q2318.51 1477.06 2315.43 1481.67 Q2312.37 1486.25 2306.56 1486.25 Q2300.75 1486.25 2297.67 1481.67 Q2294.62 1477.06 2294.62 1468.33 Q2294.62 1459.58 2297.67 1455 Q2300.75 1450.39 2306.56 1450.39 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M1208.84 1548.76 L1208.84 1551.62 L1181.92 1551.62 Q1182.3 1557.67 1185.55 1560.85 Q1188.82 1564 1194.65 1564 Q1198.02 1564 1201.17 1563.17 Q1204.36 1562.35 1207.48 1560.69 L1207.48 1566.23 Q1204.33 1567.57 1201.01 1568.27 Q1197.7 1568.97 1194.3 1568.97 Q1185.77 1568.97 1180.77 1564 Q1175.81 1559.04 1175.81 1550.57 Q1175.81 1541.82 1180.52 1536.69 Q1185.26 1531.54 1193.28 1531.54 Q1200.47 1531.54 1204.64 1536.18 Q1208.84 1540.8 1208.84 1548.76 M1202.99 1547.04 Q1202.92 1542.23 1200.28 1539.37 Q1197.67 1536.5 1193.34 1536.5 Q1188.44 1536.5 1185.48 1539.27 Q1182.55 1542.04 1182.11 1547.07 L1202.99 1547.04 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M1224.12 1562.7 L1224.12 1581.6 L1218.23 1581.6 L1218.23 1532.4 L1224.12 1532.4 L1224.12 1537.81 Q1225.97 1534.62 1228.77 1533.1 Q1231.6 1531.54 1235.52 1531.54 Q1242.01 1531.54 1246.05 1536.69 Q1250.13 1541.85 1250.13 1550.25 Q1250.13 1558.65 1246.05 1563.81 Q1242.01 1568.97 1235.52 1568.97 Q1231.6 1568.97 1228.77 1567.44 Q1225.97 1565.88 1224.12 1562.7 M1244.05 1550.25 Q1244.05 1543.79 1241.37 1540.13 Q1238.73 1536.44 1234.08 1536.44 Q1229.44 1536.44 1226.76 1540.13 Q1224.12 1543.79 1224.12 1550.25 Q1224.12 1556.71 1226.76 1560.4 Q1229.44 1564.07 1234.08 1564.07 Q1238.73 1564.07 1241.37 1560.4 Q1244.05 1556.71 1244.05 1550.25 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M1273.65 1536.5 Q1268.94 1536.5 1266.2 1540.19 Q1263.46 1543.85 1263.46 1550.25 Q1263.46 1556.65 1266.17 1560.34 Q1268.91 1564 1273.65 1564 Q1278.33 1564 1281.06 1560.31 Q1283.8 1556.62 1283.8 1550.25 Q1283.8 1543.92 1281.06 1540.23 Q1278.33 1536.5 1273.65 1536.5 M1273.65 1531.54 Q1281.29 1531.54 1285.65 1536.5 Q1290.01 1541.47 1290.01 1550.25 Q1290.01 1559 1285.65 1564 Q1281.29 1568.97 1273.65 1568.97 Q1265.98 1568.97 1261.62 1564 Q1257.29 1559 1257.29 1550.25 Q1257.29 1541.47 1261.62 1536.5 Q1265.98 1531.54 1273.65 1531.54 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M1325.37 1533.76 L1325.37 1539.24 Q1322.89 1537.87 1320.37 1537.2 Q1317.89 1536.5 1315.34 1536.5 Q1309.65 1536.5 1306.49 1540.13 Q1303.34 1543.73 1303.34 1550.25 Q1303.34 1556.78 1306.49 1560.4 Q1309.65 1564 1315.34 1564 Q1317.89 1564 1320.37 1563.33 Q1322.89 1562.63 1325.37 1561.26 L1325.37 1566.68 Q1322.92 1567.82 1320.28 1568.39 Q1317.67 1568.97 1314.71 1568.97 Q1306.65 1568.97 1301.91 1563.91 Q1297.17 1558.85 1297.17 1550.25 Q1297.17 1541.53 1301.94 1536.53 Q1306.75 1531.54 1315.09 1531.54 Q1317.79 1531.54 1320.37 1532.11 Q1322.95 1532.65 1325.37 1533.76 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M1365.19 1546.53 L1365.19 1568.04 L1359.33 1568.04 L1359.33 1546.72 Q1359.33 1541.66 1357.36 1539.14 Q1355.38 1536.63 1351.44 1536.63 Q1346.69 1536.63 1343.96 1539.65 Q1341.22 1542.68 1341.22 1547.9 L1341.22 1568.04 L1335.33 1568.04 L1335.33 1518.52 L1341.22 1518.52 L1341.22 1537.93 Q1343.32 1534.72 1346.15 1533.13 Q1349.02 1531.54 1352.74 1531.54 Q1358.88 1531.54 1362.04 1535.36 Q1365.19 1539.14 1365.19 1546.53 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M1399.59 1533.45 L1399.59 1538.98 Q1397.11 1537.71 1394.44 1537.07 Q1391.76 1536.44 1388.9 1536.44 Q1384.54 1536.44 1382.34 1537.77 Q1380.18 1539.11 1380.18 1541.79 Q1380.18 1543.82 1381.74 1545 Q1383.3 1546.15 1388.01 1547.2 L1390.01 1547.64 Q1396.25 1548.98 1398.86 1551.43 Q1401.5 1553.85 1401.5 1558.21 Q1401.5 1563.17 1397.56 1566.07 Q1393.64 1568.97 1386.77 1568.97 Q1383.9 1568.97 1380.78 1568.39 Q1377.7 1567.85 1374.26 1566.74 L1374.26 1560.69 Q1377.5 1562.38 1380.66 1563.24 Q1383.81 1564.07 1386.89 1564.07 Q1391.03 1564.07 1393.26 1562.66 Q1395.49 1561.23 1395.49 1558.65 Q1395.49 1556.27 1393.86 1554.99 Q1392.27 1553.72 1386.83 1552.54 L1384.79 1552.07 Q1379.35 1550.92 1376.93 1548.56 Q1374.51 1546.18 1374.51 1542.04 Q1374.51 1537.01 1378.08 1534.27 Q1381.64 1531.54 1388.2 1531.54 Q1391.45 1531.54 1394.31 1532.01 Q1397.17 1532.49 1399.59 1533.45 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><polyline clip-path="url(#clip930)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="224.554,1423.18 224.554,47.2441 "></polyline><polyline clip-path="url(#clip930)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="224.554,1313.48 243.451,1313.48 "></polyline><polyline clip-path="url(#clip930)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="224.554,571.037 243.451,571.037 "></polyline><path clip-path="url(#clip930)" d="M51.6634 1333.28 L59.3023 1333.28 L59.3023 1306.91 L50.9921 1308.58 L50.9921 1304.32 L59.256 1302.65 L63.9319 1302.65 L63.9319 1333.28 L71.5707 1333.28 L71.5707 1337.21 L51.6634 1337.21 L51.6634 1333.28 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M91.0151 1305.73 Q87.404 1305.73 85.5753 1309.29 Q83.7697 1312.84 83.7697 1319.97 Q83.7697 1327.07 85.5753 1330.64 Q87.404 1334.18 91.0151 1334.18 Q94.6493 1334.18 96.4548 1330.64 Q98.2835 1327.07 98.2835 1319.97 Q98.2835 1312.84 96.4548 1309.29 Q94.6493 1305.73 91.0151 1305.73 M91.0151 1302.03 Q96.8252 1302.03 99.8808 1306.63 Q102.959 1311.22 102.959 1319.97 Q102.959 1328.69 99.8808 1333.3 Q96.8252 1337.88 91.0151 1337.88 Q85.2049 1337.88 82.1262 1333.3 Q79.0707 1328.69 79.0707 1319.97 Q79.0707 1311.22 82.1262 1306.63 Q85.2049 1302.03 91.0151 1302.03 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M102.959 1296.13 L127.071 1296.13 L127.071 1299.32 L102.959 1299.32 L102.959 1296.13 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M143.396 1284.22 Q140.462 1284.22 138.976 1287.12 Q137.509 1290 137.509 1295.79 Q137.509 1301.56 138.976 1304.46 Q140.462 1307.34 143.396 1307.34 Q146.349 1307.34 147.816 1304.46 Q149.302 1301.56 149.302 1295.79 Q149.302 1290 147.816 1287.12 Q146.349 1284.22 143.396 1284.22 M143.396 1281.21 Q148.117 1281.21 150.6 1284.96 Q153.101 1288.68 153.101 1295.79 Q153.101 1302.88 150.6 1306.62 Q148.117 1310.35 143.396 1310.35 Q138.675 1310.35 136.174 1306.62 Q133.691 1302.88 133.691 1295.79 Q133.691 1288.68 136.174 1284.96 Q138.675 1281.21 143.396 1281.21 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M159.778 1305.02 L163.746 1305.02 L163.746 1309.8 L159.778 1309.8 L159.778 1305.02 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M175.294 1306.6 L188.554 1306.6 L188.554 1309.8 L170.724 1309.8 L170.724 1306.6 Q172.887 1304.37 176.611 1300.6 Q180.353 1296.82 181.313 1295.73 Q183.137 1293.68 183.852 1292.27 Q184.585 1290.84 184.585 1289.47 Q184.585 1287.23 183.005 1285.82 Q181.444 1284.41 178.924 1284.41 Q177.137 1284.41 175.144 1285.03 Q173.169 1285.65 170.912 1286.91 L170.912 1283.07 Q173.206 1282.15 175.2 1281.68 Q177.194 1281.21 178.849 1281.21 Q183.212 1281.21 185.808 1283.39 Q188.403 1285.58 188.403 1289.22 Q188.403 1290.96 187.745 1292.52 Q187.105 1294.06 185.394 1296.16 Q184.924 1296.71 182.403 1299.32 Q179.883 1301.92 175.294 1306.6 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M81.0976 590.829 L88.7364 590.829 L88.7364 564.463 L80.4263 566.13 L80.4263 561.871 L88.6901 560.204 L93.366 560.204 L93.366 590.829 L101.005 590.829 L101.005 594.764 L81.0976 594.764 L81.0976 590.829 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M120.449 563.283 Q116.838 563.283 115.009 566.848 Q113.204 570.389 113.204 577.519 Q113.204 584.625 115.009 588.19 Q116.838 591.732 120.449 591.732 Q124.083 591.732 125.889 588.19 Q127.718 584.625 127.718 577.519 Q127.718 570.389 125.889 566.848 Q124.083 563.283 120.449 563.283 M120.449 559.579 Q126.259 559.579 129.315 564.186 Q132.394 568.769 132.394 577.519 Q132.394 586.246 129.315 590.852 Q126.259 595.435 120.449 595.435 Q114.639 595.435 111.56 590.852 Q108.505 586.246 108.505 577.519 Q108.505 568.769 111.56 564.186 Q114.639 559.579 120.449 559.579 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M142.098 541.775 Q139.164 541.775 137.679 544.672 Q136.212 547.549 136.212 553.342 Q136.212 559.116 137.679 562.012 Q139.164 564.89 142.098 564.89 Q145.051 564.89 146.518 562.012 Q148.004 559.116 148.004 553.342 Q148.004 547.549 146.518 544.672 Q145.051 541.775 142.098 541.775 M142.098 538.766 Q146.819 538.766 149.302 542.509 Q151.803 546.233 151.803 553.342 Q151.803 560.433 149.302 564.175 Q146.819 567.899 142.098 567.899 Q137.378 567.899 134.876 564.175 Q132.394 560.433 132.394 553.342 Q132.394 546.233 134.876 542.509 Q137.378 538.766 142.098 538.766 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M158.48 562.577 L162.448 562.577 L162.448 567.354 L158.48 567.354 L158.48 562.577 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M178.849 541.775 Q175.915 541.775 174.429 544.672 Q172.962 547.549 172.962 553.342 Q172.962 559.116 174.429 562.012 Q175.915 564.89 178.849 564.89 Q181.802 564.89 183.269 562.012 Q184.754 559.116 184.754 553.342 Q184.754 547.549 183.269 544.672 Q181.802 541.775 178.849 541.775 M178.849 538.766 Q183.57 538.766 186.052 542.509 Q188.554 546.233 188.554 553.342 Q188.554 560.433 186.052 564.175 Q183.57 567.899 178.849 567.899 Q174.128 567.899 171.627 564.175 Q169.144 560.433 169.144 553.342 Q169.144 546.233 171.627 542.509 Q174.128 538.766 178.849 538.766 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><polyline clip-path="url(#clip932)" style="stroke:#009af9;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="284.786,86.1857 507.868,723.938 730.95,935.939 954.032,1060.41 1177.11,1147.61 1400.2,1214.44 1623.28,1269.01 1846.36,1314.33 2069.44,1351.75 2292.52,1384.24 "></polyline><polyline clip-path="url(#clip932)" style="stroke:#e26f46;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="284.786,537.233 507.868,827.167 730.95,977.098 954.032,1076.42 1177.11,1149.15 1400.2,1205.6 1623.28,1250.75 1846.36,1290.76 2069.44,1321.63 2292.52,1352.76 "></polyline><polyline clip-path="url(#clip932)" style="stroke:#3da44d;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="284.786,1172.14 507.868,1073.93 730.95,1033.79 954.032,1008.81 1177.11,984.821 1400.2,972.051 1623.28,954.58 1846.36,950.591 2069.44,946.015 2292.52,934.533 "></polyline><path clip-path="url(#clip930)" d="M1846.96 300.469 L2281.82 300.469 L2281.82 93.1086 L1846.96 93.1086  Z" fill="#ffffff" fill-rule="evenodd" fill-opacity="1"></path><polyline clip-path="url(#clip930)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="1846.96,300.469 2281.82,300.469 2281.82,93.1086 1846.96,93.1086 1846.96,300.469 "></polyline><polyline clip-path="url(#clip930)" style="stroke:#009af9;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="1870.61,144.949 2012.49,144.949 "></polyline><path clip-path="url(#clip930)" d="M2043.54 128.942 L2043.54 136.303 L2052.31 136.303 L2052.31 139.613 L2043.54 139.613 L2043.54 153.687 Q2043.54 156.858 2044.4 157.761 Q2045.28 158.664 2047.94 158.664 L2052.31 158.664 L2052.31 162.229 L2047.94 162.229 Q2043.01 162.229 2041.13 160.4 Q2039.26 158.548 2039.26 153.687 L2039.26 139.613 L2036.13 139.613 L2036.13 136.303 L2039.26 136.303 L2039.26 128.942 L2043.54 128.942 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M2072.94 140.284 Q2072.22 139.868 2071.36 139.682 Q2070.53 139.474 2069.51 139.474 Q2065.9 139.474 2063.96 141.835 Q2062.04 144.173 2062.04 148.571 L2062.04 162.229 L2057.75 162.229 L2057.75 136.303 L2062.04 136.303 L2062.04 140.331 Q2063.38 137.969 2065.53 136.835 Q2067.68 135.678 2070.76 135.678 Q2071.2 135.678 2071.73 135.747 Q2072.27 135.794 2072.92 135.909 L2072.94 140.284 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M2089.19 149.196 Q2084.03 149.196 2082.04 150.377 Q2080.05 151.557 2080.05 154.405 Q2080.05 156.673 2081.53 158.016 Q2083.03 159.335 2085.6 159.335 Q2089.14 159.335 2091.27 156.835 Q2093.42 154.312 2093.42 150.145 L2093.42 149.196 L2089.19 149.196 M2097.68 147.437 L2097.68 162.229 L2093.42 162.229 L2093.42 158.293 Q2091.97 160.655 2089.79 161.789 Q2087.61 162.9 2084.47 162.9 Q2080.48 162.9 2078.12 160.678 Q2075.79 158.432 2075.79 154.682 Q2075.79 150.307 2078.7 148.085 Q2081.64 145.863 2087.45 145.863 L2093.42 145.863 L2093.42 145.446 Q2093.42 142.507 2091.48 140.909 Q2089.56 139.289 2086.06 139.289 Q2083.84 139.289 2081.73 139.821 Q2079.63 140.354 2077.68 141.419 L2077.68 137.483 Q2080.02 136.581 2082.22 136.141 Q2084.42 135.678 2086.5 135.678 Q2092.13 135.678 2094.91 138.594 Q2097.68 141.511 2097.68 147.437 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M2106.46 136.303 L2110.72 136.303 L2110.72 162.229 L2106.46 162.229 L2106.46 136.303 M2106.46 126.21 L2110.72 126.21 L2110.72 131.604 L2106.46 131.604 L2106.46 126.21 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M2141.18 146.581 L2141.18 162.229 L2136.92 162.229 L2136.92 146.719 Q2136.92 143.039 2135.48 141.21 Q2134.05 139.382 2131.18 139.382 Q2127.73 139.382 2125.74 141.581 Q2123.75 143.78 2123.75 147.576 L2123.75 162.229 L2119.47 162.229 L2119.47 136.303 L2123.75 136.303 L2123.75 140.331 Q2125.28 137.993 2127.34 136.835 Q2129.42 135.678 2132.13 135.678 Q2136.6 135.678 2138.89 138.456 Q2141.18 141.21 2141.18 146.581 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M2169.37 170.099 L2169.37 173.409 L2144.74 173.409 L2144.74 170.099 L2169.37 170.099 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M2173.38 126.21 L2177.64 126.21 L2177.64 162.229 L2173.38 162.229 L2173.38 126.21 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M2196.6 139.289 Q2193.17 139.289 2191.18 141.974 Q2189.19 144.636 2189.19 149.289 Q2189.19 153.942 2191.16 156.627 Q2193.15 159.289 2196.6 159.289 Q2200 159.289 2201.99 156.604 Q2203.98 153.918 2203.98 149.289 Q2203.98 144.682 2201.99 141.997 Q2200 139.289 2196.6 139.289 M2196.6 135.678 Q2202.15 135.678 2205.32 139.289 Q2208.49 142.9 2208.49 149.289 Q2208.49 155.655 2205.32 159.289 Q2202.15 162.9 2196.6 162.9 Q2191.02 162.9 2187.85 159.289 Q2184.7 155.655 2184.7 149.289 Q2184.7 142.9 2187.85 139.289 Q2191.02 135.678 2196.6 135.678 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M2232.08 137.067 L2232.08 141.094 Q2230.28 140.169 2228.33 139.706 Q2226.39 139.243 2224.3 139.243 Q2221.13 139.243 2219.54 140.215 Q2217.96 141.187 2217.96 143.131 Q2217.96 144.613 2219.1 145.469 Q2220.23 146.303 2223.66 147.067 L2225.11 147.391 Q2229.65 148.363 2231.55 150.145 Q2233.47 151.905 2233.47 155.076 Q2233.47 158.687 2230.6 160.793 Q2227.75 162.9 2222.75 162.9 Q2220.67 162.9 2218.4 162.483 Q2216.16 162.09 2213.66 161.28 L2213.66 156.881 Q2216.02 158.108 2218.31 158.733 Q2220.6 159.335 2222.85 159.335 Q2225.85 159.335 2227.47 158.317 Q2229.1 157.275 2229.1 155.4 Q2229.1 153.664 2227.91 152.738 Q2226.76 151.812 2222.8 150.956 L2221.32 150.608 Q2217.36 149.775 2215.6 148.062 Q2213.84 146.326 2213.84 143.317 Q2213.84 139.659 2216.43 137.669 Q2219.03 135.678 2223.79 135.678 Q2226.16 135.678 2228.24 136.025 Q2230.32 136.372 2232.08 137.067 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M2256.78 137.067 L2256.78 141.094 Q2254.97 140.169 2253.03 139.706 Q2251.09 139.243 2249 139.243 Q2245.83 139.243 2244.23 140.215 Q2242.66 141.187 2242.66 143.131 Q2242.66 144.613 2243.79 145.469 Q2244.93 146.303 2248.35 147.067 L2249.81 147.391 Q2254.35 148.363 2256.25 150.145 Q2258.17 151.905 2258.17 155.076 Q2258.17 158.687 2255.3 160.793 Q2252.45 162.9 2247.45 162.9 Q2245.37 162.9 2243.1 162.483 Q2240.85 162.09 2238.35 161.28 L2238.35 156.881 Q2240.72 158.108 2243.01 158.733 Q2245.3 159.335 2247.54 159.335 Q2250.55 159.335 2252.17 158.317 Q2253.79 157.275 2253.79 155.4 Q2253.79 153.664 2252.61 152.738 Q2251.46 151.812 2247.5 150.956 L2246.02 150.608 Q2242.06 149.775 2240.3 148.062 Q2238.54 146.326 2238.54 143.317 Q2238.54 139.659 2241.13 137.669 Q2243.72 135.678 2248.49 135.678 Q2250.85 135.678 2252.94 136.025 Q2255.02 136.372 2256.78 137.067 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><polyline clip-path="url(#clip930)" style="stroke:#e26f46;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="1870.61,196.789 2012.49,196.789 "></polyline><path clip-path="url(#clip930)" d="M2036.13 188.143 L2040.65 188.143 L2048.75 209.902 L2056.85 188.143 L2061.36 188.143 L2051.64 214.069 L2045.86 214.069 L2036.13 188.143 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M2079.03 201.036 Q2073.86 201.036 2071.87 202.217 Q2069.88 203.397 2069.88 206.245 Q2069.88 208.513 2071.36 209.856 Q2072.87 211.175 2075.44 211.175 Q2078.98 211.175 2081.11 208.675 Q2083.26 206.152 2083.26 201.985 L2083.26 201.036 L2079.03 201.036 M2087.52 199.277 L2087.52 214.069 L2083.26 214.069 L2083.26 210.133 Q2081.8 212.495 2079.63 213.629 Q2077.45 214.74 2074.3 214.74 Q2070.32 214.74 2067.96 212.518 Q2065.62 210.272 2065.62 206.522 Q2065.62 202.147 2068.54 199.925 Q2071.48 197.703 2077.29 197.703 L2083.26 197.703 L2083.26 197.286 Q2083.26 194.347 2081.32 192.749 Q2079.4 191.129 2075.9 191.129 Q2073.68 191.129 2071.57 191.661 Q2069.47 192.194 2067.52 193.259 L2067.52 189.323 Q2069.86 188.421 2072.06 187.981 Q2074.26 187.518 2076.34 187.518 Q2081.97 187.518 2084.74 190.434 Q2087.52 193.351 2087.52 199.277 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M2096.3 178.05 L2100.55 178.05 L2100.55 214.069 L2096.3 214.069 L2096.3 178.05 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M2129.17 221.939 L2129.17 225.249 L2104.54 225.249 L2104.54 221.939 L2129.17 221.939 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M2133.17 178.05 L2137.43 178.05 L2137.43 214.069 L2133.17 214.069 L2133.17 178.05 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M2156.39 191.129 Q2152.96 191.129 2150.97 193.814 Q2148.98 196.476 2148.98 201.129 Q2148.98 205.782 2150.95 208.467 Q2152.94 211.129 2156.39 211.129 Q2159.79 211.129 2161.78 208.444 Q2163.77 205.758 2163.77 201.129 Q2163.77 196.522 2161.78 193.837 Q2159.79 191.129 2156.39 191.129 M2156.39 187.518 Q2161.94 187.518 2165.11 191.129 Q2168.29 194.74 2168.29 201.129 Q2168.29 207.495 2165.11 211.129 Q2161.94 214.74 2156.39 214.74 Q2150.81 214.74 2147.64 211.129 Q2144.49 207.495 2144.49 201.129 Q2144.49 194.74 2147.64 191.129 Q2150.81 187.518 2156.39 187.518 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M2191.87 188.907 L2191.87 192.934 Q2190.07 192.009 2188.12 191.546 Q2186.18 191.083 2184.1 191.083 Q2180.92 191.083 2179.33 192.055 Q2177.75 193.027 2177.75 194.971 Q2177.75 196.453 2178.89 197.309 Q2180.02 198.143 2183.45 198.907 L2184.91 199.231 Q2189.44 200.203 2191.34 201.985 Q2193.26 203.745 2193.26 206.916 Q2193.26 210.527 2190.39 212.633 Q2187.54 214.74 2182.54 214.74 Q2180.46 214.74 2178.19 214.323 Q2175.95 213.93 2173.45 213.12 L2173.45 208.721 Q2175.81 209.948 2178.1 210.573 Q2180.39 211.175 2182.64 211.175 Q2185.65 211.175 2187.27 210.157 Q2188.89 209.115 2188.89 207.24 Q2188.89 205.504 2187.71 204.578 Q2186.55 203.652 2182.59 202.796 L2181.11 202.448 Q2177.15 201.615 2175.39 199.902 Q2173.63 198.166 2173.63 195.157 Q2173.63 191.499 2176.23 189.509 Q2178.82 187.518 2183.59 187.518 Q2185.95 187.518 2188.03 187.865 Q2190.11 188.212 2191.87 188.907 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M2216.57 188.907 L2216.57 192.934 Q2214.77 192.009 2212.82 191.546 Q2210.88 191.083 2208.79 191.083 Q2205.62 191.083 2204.03 192.055 Q2202.45 193.027 2202.45 194.971 Q2202.45 196.453 2203.59 197.309 Q2204.72 198.143 2208.15 198.907 L2209.6 199.231 Q2214.14 200.203 2216.04 201.985 Q2217.96 203.745 2217.96 206.916 Q2217.96 210.527 2215.09 212.633 Q2212.24 214.74 2207.24 214.74 Q2205.16 214.74 2202.89 214.323 Q2200.65 213.93 2198.15 213.12 L2198.15 208.721 Q2200.51 209.948 2202.8 210.573 Q2205.09 211.175 2207.34 211.175 Q2210.35 211.175 2211.97 210.157 Q2213.59 209.115 2213.59 207.24 Q2213.59 205.504 2212.41 204.578 Q2211.25 203.652 2207.29 202.796 L2205.81 202.448 Q2201.85 201.615 2200.09 199.902 Q2198.33 198.166 2198.33 195.157 Q2198.33 191.499 2200.92 189.509 Q2203.52 187.518 2208.29 187.518 Q2210.65 187.518 2212.73 187.865 Q2214.81 188.212 2216.57 188.907 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><polyline clip-path="url(#clip930)" style="stroke:#3da44d;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="1870.61,248.629 2012.49,248.629 "></polyline><path clip-path="url(#clip930)" d="M2036.13 239.983 L2040.65 239.983 L2048.75 261.742 L2056.85 239.983 L2061.36 239.983 L2051.64 265.909 L2045.86 265.909 L2036.13 239.983 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M2079.03 252.876 Q2073.86 252.876 2071.87 254.057 Q2069.88 255.237 2069.88 258.085 Q2069.88 260.353 2071.36 261.696 Q2072.87 263.015 2075.44 263.015 Q2078.98 263.015 2081.11 260.515 Q2083.26 257.992 2083.26 253.825 L2083.26 252.876 L2079.03 252.876 M2087.52 251.117 L2087.52 265.909 L2083.26 265.909 L2083.26 261.973 Q2081.8 264.335 2079.63 265.469 Q2077.45 266.58 2074.3 266.58 Q2070.32 266.58 2067.96 264.358 Q2065.62 262.112 2065.62 258.362 Q2065.62 253.987 2068.54 251.765 Q2071.48 249.543 2077.29 249.543 L2083.26 249.543 L2083.26 249.126 Q2083.26 246.187 2081.32 244.589 Q2079.4 242.969 2075.9 242.969 Q2073.68 242.969 2071.57 243.501 Q2069.47 244.034 2067.52 245.099 L2067.52 241.163 Q2069.86 240.261 2072.06 239.821 Q2074.26 239.358 2076.34 239.358 Q2081.97 239.358 2084.74 242.274 Q2087.52 245.191 2087.52 251.117 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M2096.3 229.89 L2100.55 229.89 L2100.55 265.909 L2096.3 265.909 L2096.3 229.89 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M2129.17 273.779 L2129.17 277.089 L2104.54 277.089 L2104.54 273.779 L2129.17 273.779 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M2144.95 252.876 Q2139.79 252.876 2137.8 254.057 Q2135.81 255.237 2135.81 258.085 Q2135.81 260.353 2137.29 261.696 Q2138.79 263.015 2141.36 263.015 Q2144.91 263.015 2147.04 260.515 Q2149.19 257.992 2149.19 253.825 L2149.19 252.876 L2144.95 252.876 M2153.45 251.117 L2153.45 265.909 L2149.19 265.909 L2149.19 261.973 Q2147.73 264.335 2145.55 265.469 Q2143.38 266.58 2140.23 266.58 Q2136.25 266.58 2133.89 264.358 Q2131.55 262.112 2131.55 258.362 Q2131.55 253.987 2134.47 251.765 Q2137.41 249.543 2143.22 249.543 L2149.19 249.543 L2149.19 249.126 Q2149.19 246.187 2147.24 244.589 Q2145.32 242.969 2141.83 242.969 Q2139.6 242.969 2137.5 243.501 Q2135.39 244.034 2133.45 245.099 L2133.45 241.163 Q2135.79 240.261 2137.98 239.821 Q2140.18 239.358 2142.27 239.358 Q2147.89 239.358 2150.67 242.274 Q2153.45 245.191 2153.45 251.117 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M2180.88 240.978 L2180.88 244.96 Q2179.07 243.964 2177.24 243.478 Q2175.44 242.969 2173.59 242.969 Q2169.44 242.969 2167.15 245.608 Q2164.86 248.224 2164.86 252.969 Q2164.86 257.714 2167.15 260.353 Q2169.44 262.969 2173.59 262.969 Q2175.44 262.969 2177.24 262.483 Q2179.07 261.973 2180.88 260.978 L2180.88 264.913 Q2179.1 265.747 2177.17 266.163 Q2175.28 266.58 2173.12 266.58 Q2167.27 266.58 2163.82 262.899 Q2160.37 259.219 2160.37 252.969 Q2160.37 246.626 2163.84 242.992 Q2167.34 239.358 2173.4 239.358 Q2175.37 239.358 2177.24 239.775 Q2179.12 240.168 2180.88 240.978 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip930)" d="M2206.94 240.978 L2206.94 244.96 Q2205.14 243.964 2203.31 243.478 Q2201.5 242.969 2199.65 242.969 Q2195.51 242.969 2193.22 245.608 Q2190.92 248.224 2190.92 252.969 Q2190.92 257.714 2193.22 260.353 Q2195.51 262.969 2199.65 262.969 Q2201.5 262.969 2203.31 262.483 Q2205.14 261.973 2206.94 260.978 L2206.94 264.913 Q2205.16 265.747 2203.24 266.163 Q2201.34 266.58 2199.19 266.58 Q2193.33 266.58 2189.88 262.899 Q2186.43 259.219 2186.43 252.969 Q2186.43 246.626 2189.91 242.992 Q2193.4 239.358 2199.47 239.358 Q2201.43 239.358 2203.31 239.775 Q2205.18 240.168 2206.94 240.978 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path></svg><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>(SoftmaxRegressionScratch{@NamedTuple{num_inputs::Int64, num_outputs::Int64, lr::Float64, sigma::Float64}}([0.0012527126549554087 -0.003995983014698948 … 0.00024316815799139098 -0.010835742813268167; 0.010946987929790661 0.0007470507029887345 … 0.0037590020962039155 -0.001693456098599236; … ; -0.015148689989682912 0.00949050201467524 … -0.0029877327424057427 -0.00926534942949869; -0.002231184659765448 0.005786080370085332 … -0.011037629493372747 0.0038252662240478713], [0.021358851696887688; -0.010785774908621088; … ; -0.1387041380893096; -0.21438382105760126;;], (num_inputs = 784, num_outputs = 10, lr = 0.1, sigma = 0.01)), (val_loss = [0.5727241634986047, 0.5631760557383434, 0.6818548302699166, 0.589491698927436, 0.6573814641095722, 0.5667704315775226, 0.55887327005933, 0.6143094496749374, 0.535628902610172, 0.5898786127425825  …  0.6309338430578103, 0.6671986139663917, 0.5781126253850449, 0.5628897635900775, 0.6685902149846591, 0.6375603918786804, 0.5918919543446521, 0.6520028844786065, 0.5883492237570637, 0.39428948561702787], val_acc = [0.81640625, 0.8359375, 0.78125, 0.81640625, 0.78125, 0.81640625, 0.8359375, 0.80078125, 0.8203125, 0.796875  …  0.79296875, 0.78125, 0.8125, 0.828125, 0.7578125, 0.79296875, 0.79296875, 0.8125, 0.828125, 0.875]))</span></span></code></pre></div><h2 id="Summary" tabindex="-1">Summary <a class="header-anchor" href="#Summary" aria-label="Permalink to &quot;Summary {#Summary}&quot;">​</a></h2><p>By now we are starting to get some experience with solving linear regression and classification problems. With it, we have reached what would arguably be the state of the art of 1960–1970s of statistical modeling. In the next section, we will show you how to leverage deep learning frameworks to implement this model much more efficiently.</p><h2 id="Exercises" tabindex="-1">Exercises <a class="header-anchor" href="#Exercises" aria-label="Permalink to &quot;Exercises {#Exercises}&quot;">​</a></h2><ol><li><p>In this section, we directly implemented the softmax function based on the mathematical definition of the softmax operation. As discussed in :numref:<code>sec_softmax</code> this can cause numerical instabilities.</p></li><li><p>Test whether <code>softmax</code> still works correctly if an input has a value of <mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.05ex;" xmlns="http://www.w3.org/2000/svg" width="3.394ex" height="1.557ex" role="img" focusable="false" viewBox="0 -666 1500 688" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)" style="stroke-width:3;"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>100</mn></math></mjx-assistive-mml></mjx-container>.</p></li><li><p>Test whether <code>softmax</code> still works correctly if the largest of all inputs is smaller than <mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.186ex;" xmlns="http://www.w3.org/2000/svg" width="5.154ex" height="1.692ex" role="img" focusable="false" viewBox="0 -666 2278 748" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(778,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)" style="stroke-width:3;"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>−</mo><mn>100</mn></math></mjx-assistive-mml></mjx-container>.</p></li><li><p>Implement a fix by looking at the value relative to the largest entry in the argument.</p></li><li><p>Implement a <code>cross_entropy</code> function that follows the definition of the cross-entropy loss function <mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.663ex;" xmlns="http://www.w3.org/2000/svg" width="10.848ex" height="2.496ex" role="img" focusable="false" viewBox="0 -810 4794.9 1103.1" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="munder"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(1089,-285.4) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g></g><g data-mml-node="msub" transform="translate(1549.6,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mi" transform="translate(2533.2,0)"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" style="stroke-width:3;"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(278,0)" style="stroke-width:3;"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(778,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3811.2,0)"><path data-c="2061" d="" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(3977.9,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(300.6,16) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z" style="stroke-width:3;"></path></g></g></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><munder><mo data-mjx-texclass="OP">∑</mo><mi>i</mi></munder><msub><mi>y</mi><mi>i</mi></msub><mi>log</mi><mo data-mjx-texclass="NONE">⁡</mo><msub><mrow data-mjx-texclass="ORD"><mover><mi>y</mi><mo stretchy="false">^</mo></mover></mrow><mi>i</mi></msub></math></mjx-assistive-mml></mjx-container>.</p></li><li><p>Try it out in the code example of this section.</p></li><li><p>Why do you think it runs more slowly?</p></li><li><p>Should you use it? When would it make sense to?</p></li><li><p>What do you need to be careful of? Hint: consider the domain of the logarithm.</p></li><li><p>Is it always a good idea to return the most likely label? For example, would you do this for medical diagnosis? How would you try to address this?</p></li><li><p>Assume that we want to use softmax regression to predict the next word based on some features. What are some problems that might arise from a large vocabulary?</p></li><li><p>Experiment with the hyperparameters of the code in this section. In particular:</p></li><li><p>Plot how the validation loss changes as you change the learning rate.</p></li><li><p>Do the validation and training loss change as you change the minibatch size? How large or small do you need to go before you see an effect?</p></li></ol><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"></span></code></pre></div></div></div></main><footer class="VPDocFooter" data-v-83890dd9 data-v-4f9813fa><!--[--><!--]--><div class="edit-info" data-v-4f9813fa><div class="edit-link" data-v-4f9813fa><a class="VPLink link vp-external-link-icon no-icon edit-link-button" href="https://https://github.com/ashutosh-b-b/d2l-julia/edit/master/docs/src/CH4.Linear_Classification/LCN_3.md" target="_blank" rel="noreferrer" data-v-4f9813fa><!--[--><span class="vpi-square-pen edit-link-icon" data-v-4f9813fa></span> Edit this page<!--]--></a></div><!----></div><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-4f9813fa><span class="visually-hidden" id="doc-footer-aria-label" data-v-4f9813fa>Pager</span><div class="pager" data-v-4f9813fa><a class="VPLink link pager-link prev" href="/d2l-julia/previews/PR1/CH4.Linear_Classification/LCN_2" data-v-4f9813fa><!--[--><span class="desc" data-v-4f9813fa>Previous page</span><span class="title" data-v-4f9813fa>The Image Classification Dataset</span><!--]--></a></div><div class="pager" data-v-4f9813fa><a class="VPLink link pager-link next" href="/d2l-julia/previews/PR1/CH4.Linear_Classification/LCN_4" data-v-4f9813fa><!--[--><span class="desc" data-v-4f9813fa>Next page</span><span class="title" data-v-4f9813fa>Concise Implementation of Softmax Regression</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-a9a9e638 data-v-c970a860><div class="container" data-v-c970a860><p class="message" data-v-c970a860>Made with <a href="https://luxdl.github.io/DocumenterVitepress.jl/dev/" target="_blank"><strong>DocumenterVitepress.jl</strong></a><br></p><p class="copyright" data-v-c970a860>© Copyright 2025.</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"ch10.attention_mechanisms_and_transformers_attn_1.md\":\"BPTHOId7\",\"ch10.attention_mechanisms_and_transformers_attn_2.md\":\"CSvHAO07\",\"ch10.attention_mechanisms_and_transformers_attn_3.md\":\"B6P-XMmW\",\"ch10.attention_mechanisms_and_transformers_attn_4.md\":\"CB5DEaB1\",\"ch10.attention_mechanisms_and_transformers_attn_5.md\":\"DQHNoxkK\",\"ch10.attention_mechanisms_and_transformers_attn_6.md\":\"DJp_Cd3H\",\"ch10.attention_mechanisms_and_transformers_untitled.md\":\"AZxRWAaB\",\"ch3.linear_regression_lnn_1.md\":\"DTK1fX6I\",\"ch3.linear_regression_lnn_2.md\":\"BD8w6uR8\",\"ch3.linear_regression_lnn_3.md\":\"C4MB6zPT\",\"ch3.linear_regression_lnn_4.md\":\"B7J5MW04\",\"ch3.linear_regression_lnn_5.md\":\"CfF2CfNK\",\"ch3.linear_regression_lnn_6.md\":\"uj6xm8fY\",\"ch3.linear_regression_lnn_7.md\":\"B_zpSpiN\",\"ch4.linear_classification_lcn_1.md\":\"Boi1cDsh\",\"ch4.linear_classification_lcn_2.md\":\"CkOR2Iia\",\"ch4.linear_classification_lcn_3.md\":\"V-0rtib8\",\"ch4.linear_classification_lcn_4.md\":\"BX5UP2HZ\",\"ch4.linear_classification_lcn_5.md\":\"C-7KZE9h\",\"ch4.linear_classification_lcn_6.md\":\"DNDvKaZ3\",\"ch5.mlp_mlp_1.md\":\"DNcZmrDZ\",\"ch5.mlp_mlp_2.md\":\"MI21_tyz\",\"ch5.mlp_mlp_3.md\":\"DVB63m8H\",\"ch5.mlp_mlp_4.md\":\"BYjKXVG9\",\"ch5.mlp_mlp_5.md\":\"CxEzVy5G\",\"ch5.mlp_mlp_6.md\":\"CpygNHoD\",\"ch6.convolutional_neural_networks_cnn_2.md\":\"pAndzyT8\",\"ch6.convolutional_neural_networks_cnn_3.md\":\"CyHC0BXV\",\"ch6.convolutional_neural_networks_cnn_4.md\":\"-fYwA9iM\",\"ch6.convolutional_neural_networks_cnn_5.md\":\"DKCH7I6h\",\"ch6.convolutional_neural_networks_cnn_6.md\":\"BxTNLj1_\",\"ch7.modernconvolutionalneuralnetworks_mcnn_0.md\":\"Do42Pcb-\",\"ch7.modernconvolutionalneuralnetworks_mcnn_1.md\":\"DyrfEGE0\",\"ch7.modernconvolutionalneuralnetworks_mcnn_2.md\":\"BdK6e3J7\",\"ch7.modernconvolutionalneuralnetworks_mcnn_3.md\":\"CvJU8raL\",\"ch7.modernconvolutionalneuralnetworks_mcnn_4.md\":\"DfMUvHOO\",\"ch7.modernconvolutionalneuralnetworks_mcnn_5.md\":\"CVkY2ACS\",\"ch7.modernconvolutionalneuralnetworks_mcnn_6.md\":\"Cin-j3ht\",\"ch7.modernconvolutionalneuralnetworks_mcnn_7.md\":\"BY0qhW6e\",\"ch7.modernconvolutionalneuralnetworks_mcnn_8.md\":\"CfFt59lS\",\"ch8.recurrent_neural_networks_rnn_0.md\":\"CIW34d_V\",\"ch8.recurrent_neural_networks_rnn_1.md\":\"Dqwc86d0\",\"ch8.recurrent_neural_networks_rnn_2.md\":\"DVOnaLjw\",\"ch8.recurrent_neural_networks_rnn_3.md\":\"BzfHLTyo\",\"ch8.recurrent_neural_networks_rnn_4.md\":\"DnQjCEE3\",\"ch8.recurrent_neural_networks_rnn_5.md\":\"6IPEYW7M\",\"ch8.recurrent_neural_networks_rnn_6.md\":\"GS6Ynndo\",\"ch8.recurrent_neural_networks_rnn_7.md\":\"B3soXDbW\",\"ch9.modern_recurrent_neural_networks_mrnn_1.md\":\"zGzQsIzl\",\"ch9.modern_recurrent_neural_networks_mrnn_2.md\":\"CV4lwlnE\",\"ch9.modern_recurrent_neural_networks_mrnn_3.md\":\"DI9bj1mT\",\"ch9.modern_recurrent_neural_networks_mrnn_4.md\":\"CvMg8EjP\",\"ch9.modern_recurrent_neural_networks_mrnn_5.md\":\"CuOfLj02\",\"ch9.modern_recurrent_neural_networks_mrnn_6.md\":\"BrLASjSi\",\"ch9.modern_recurrent_neural_networks_mrnn_7.md\":\"D5R7Lv49\",\"chapters.md\":\"BCfSINH3\",\"index.md\":\"C9fKtYo7\",\"references.md\":\"Dwf5fRK0\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"d2l Julia\",\"description\":\"Documentation for d2l-julia\",\"base\":\"/d2l-julia/previews/PR1/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"outline\":\"deep\",\"logo\":{\"src\":\"/logo.png\",\"width\":24,\"height\":24},\"search\":{\"provider\":\"local\",\"options\":{\"detailedView\":true}},\"nav\":[{\"text\":\"Home\",\"link\":\"/index\"},{\"text\":\"Chapters\",\"collapsed\":false,\"items\":[{\"text\":\"📘 Chapters Overview\",\"link\":\"/chapters\"},{\"text\":\"Linear Neural Networks for Regression\",\"collapsed\":false,\"items\":[{\"text\":\"Linear Regression\",\"link\":\"/CH3.Linear_Regression/LNN_1\"},{\"text\":\"Multiple Dispatch Design for Implementation\",\"link\":\"/CH3.Linear_Regression/LNN_2\"},{\"text\":\"Synthetic Regression Data\",\"link\":\"/CH3.Linear_Regression/LNN_3\"},{\"text\":\"Linear Regression Implementation from Scratch\",\"link\":\"/CH3.Linear_Regression/LNN_4\"},{\"text\":\"Concise Implementation of Linear Regression\",\"link\":\"/CH3.Linear_Regression/LNN_5\"},{\"text\":\"Generalization\",\"link\":\"/CH3.Linear_Regression/LNN_6\"},{\"text\":\"Weight Decay\",\"link\":\"/CH3.Linear_Regression/LNN_7\"}]},{\"text\":\"Linear Neural Networks for Classification\",\"collapsed\":false,\"items\":[{\"text\":\"Softmax Regression\",\"link\":\"/CH4.Linear_Classification/LCN_1\"},{\"text\":\"The Image Classification Dataset\",\"link\":\"/CH4.Linear_Classification/LCN_2\"},{\"text\":\"Softmax Regression Implementation from Scratch\",\"link\":\"/CH4.Linear_Classification/LCN_3\"},{\"text\":\"Concise Implementation of Softmax Regression\",\"link\":\"/CH4.Linear_Classification/LCN_4\"},{\"text\":\"Generalization in Classification\",\"link\":\"/CH4.Linear_Classification/LCN_5\"},{\"text\":\"Environment and Distribution Shift\",\"link\":\"/CH4.Linear_Classification/LCN_6\"}]},{\"text\":\"Multilayer Perceptron\",\"collapsed\":false,\"items\":[{\"text\":\"Multilayer Perceptrons\",\"link\":\"/CH5.MLP/MLP_1\"},{\"text\":\"Implementation of Multilayer Perceptrons\",\"link\":\"/CH5.MLP/MLP_2\"},{\"text\":\"Forward Propagation, Backward Propagation, and Computational Graphs\",\"link\":\"/CH5.MLP/MLP_3\"},{\"text\":\"Numerical Stability and Initialization\",\"link\":\"/CH5.MLP/MLP_4\"},{\"text\":\"Generalization in Deep Learning\",\"link\":\"/CH5.MLP/MLP_5\"},{\"text\":\"Dropout\",\"link\":\"/CH5.MLP/MLP_6\"}]},{\"text\":\"Convolutional Neural Networks\",\"collapsed\":false,\"items\":[{\"text\":\"Convolutions for Images\",\"link\":\"/CH6.Convolutional_Neural_Networks/CNN_2\"},{\"text\":\"Padding and Stride\",\"link\":\"/CH6.Convolutional_Neural_Networks/CNN_3\"},{\"text\":\"Multiple Input and Multiple Output Channels\",\"link\":\"/CH6.Convolutional_Neural_Networks/CNN_4\"},{\"text\":\"Pooling\",\"link\":\"/CH6.Convolutional_Neural_Networks/CNN_5\"},{\"text\":\"Convolutional Neural Networks (LeNet)\",\"link\":\"/CH6.Convolutional_Neural_Networks/CNN_6\"}]},{\"text\":\"Modern Convolutional Neural Networks\",\"collapsed\":false,\"items\":[{\"text\":\"Modern Convolutional Neural Networks\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_0\"},{\"text\":\"Deep Convolutional Neural Networks (AlexNet)\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_1\"},{\"text\":\"Networks Using Blocks (VGG)\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_2\"},{\"text\":\"Network in Network (NiN)\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_3\"},{\"text\":\"Multi-Branch Networks  (GoogLeNet)\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_4\"},{\"text\":\"Batch Normalization\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_5\"},{\"text\":\"Residual Networks (ResNet) and ResNeXt\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_6\"},{\"text\":\"Densely Connected Networks (DenseNet)\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_7\"},{\"text\":\"Designing Convolution Network Architectures\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_8\"}]},{\"text\":\"Recurrent Neural Networks\",\"collapsed\":false,\"items\":[{\"text\":\"Recurrent Neural Networks\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_0\"},{\"text\":\"Working with Sequences\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_1\"},{\"text\":\"Converting Raw Text into Sequence Data\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_2\"},{\"text\":\"Language Models\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_3\"},{\"text\":\"Recurrent Neural Networks\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_4\"},{\"text\":\"Recurrent Neural Network Implementation from Scratch\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_5\"},{\"text\":\"Concise Implementation of Recurrent Neural Networks\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_6\"},{\"text\":\"Backpropagation Through Time\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_7\"}]},{\"text\":\"Modern Recurrent Neural Networks\",\"collapsed\":false,\"items\":[{\"text\":\"Long Short-Term Memory (LSTM)\",\"link\":\"/CH9.Modern_Recurrent_Neural_Networks/MRNN_1\"},{\"text\":\"Gated Recurrent Units (GRU)\",\"link\":\"/CH9.Modern_Recurrent_Neural_Networks/MRNN_2\"},{\"text\":\"Deep Recurrent Neural Networks\",\"link\":\"/CH9.Modern_Recurrent_Neural_Networks/MRNN_3\"},{\"text\":\"Bidirectional Recurrent Neural Networks\",\"link\":\"/CH9.Modern_Recurrent_Neural_Networks/MRNN_4\"},{\"text\":\"Machine Translation and the Dataset\",\"link\":\"/CH9.Modern_Recurrent_Neural_Networks/MRNN_5\"},{\"text\":\"The Encoder–Decoder Architecture\",\"link\":\"/CH9.Modern_Recurrent_Neural_Networks/MRNN_6\"},{\"text\":\"Sequence-to-Sequence Learning for Machine Translation\",\"link\":\"/CH9.Modern_Recurrent_Neural_Networks/MRNN_7\"}]},{\"text\":\"Attention Mechanisms and Transformers\",\"collapsed\":false,\"items\":[{\"text\":\"Queries, Keys, and Values\",\"link\":\"/CH10.Attention_Mechanisms_and_Transformers/ATTN_1\"},{\"text\":\"Attention Pooling by Similarity\",\"link\":\"/CH10.Attention_Mechanisms_and_Transformers/ATTN_2\"},{\"text\":\"Attention Scoring Functions\",\"link\":\"/CH10.Attention_Mechanisms_and_Transformers/ATTN_3\"},{\"text\":\"The Bahdanau Attention Mechanism\",\"link\":\"/CH10.Attention_Mechanisms_and_Transformers/ATTN_4\"},{\"text\":\"Multi-Head Attention\",\"link\":\"/CH10.Attention_Mechanisms_and_Transformers/ATTN_5\"},{\"text\":\"Self-Attention and Positional Encoding\",\"link\":\"/CH10.Attention_Mechanisms_and_Transformers/ATTN_6\"},{\"text\":\"CH10.Attention_Mechanisms_and_Transformers/Untitled\",\"link\":\"/CH10.Attention_Mechanisms_and_Transformers/Untitled\"}]}]},{\"text\":\"References\",\"link\":\"/references\"},{\"component\":\"VersionPicker\"}],\"sidebar\":[{\"text\":\"Home\",\"link\":\"/index\"},{\"text\":\"Chapters\",\"collapsed\":false,\"items\":[{\"text\":\"📘 Chapters Overview\",\"link\":\"/chapters\"},{\"text\":\"Linear Neural Networks for Regression\",\"collapsed\":false,\"items\":[{\"text\":\"Linear Regression\",\"link\":\"/CH3.Linear_Regression/LNN_1\"},{\"text\":\"Multiple Dispatch Design for Implementation\",\"link\":\"/CH3.Linear_Regression/LNN_2\"},{\"text\":\"Synthetic Regression Data\",\"link\":\"/CH3.Linear_Regression/LNN_3\"},{\"text\":\"Linear Regression Implementation from Scratch\",\"link\":\"/CH3.Linear_Regression/LNN_4\"},{\"text\":\"Concise Implementation of Linear Regression\",\"link\":\"/CH3.Linear_Regression/LNN_5\"},{\"text\":\"Generalization\",\"link\":\"/CH3.Linear_Regression/LNN_6\"},{\"text\":\"Weight Decay\",\"link\":\"/CH3.Linear_Regression/LNN_7\"}]},{\"text\":\"Linear Neural Networks for Classification\",\"collapsed\":false,\"items\":[{\"text\":\"Softmax Regression\",\"link\":\"/CH4.Linear_Classification/LCN_1\"},{\"text\":\"The Image Classification Dataset\",\"link\":\"/CH4.Linear_Classification/LCN_2\"},{\"text\":\"Softmax Regression Implementation from Scratch\",\"link\":\"/CH4.Linear_Classification/LCN_3\"},{\"text\":\"Concise Implementation of Softmax Regression\",\"link\":\"/CH4.Linear_Classification/LCN_4\"},{\"text\":\"Generalization in Classification\",\"link\":\"/CH4.Linear_Classification/LCN_5\"},{\"text\":\"Environment and Distribution Shift\",\"link\":\"/CH4.Linear_Classification/LCN_6\"}]},{\"text\":\"Multilayer Perceptron\",\"collapsed\":false,\"items\":[{\"text\":\"Multilayer Perceptrons\",\"link\":\"/CH5.MLP/MLP_1\"},{\"text\":\"Implementation of Multilayer Perceptrons\",\"link\":\"/CH5.MLP/MLP_2\"},{\"text\":\"Forward Propagation, Backward Propagation, and Computational Graphs\",\"link\":\"/CH5.MLP/MLP_3\"},{\"text\":\"Numerical Stability and Initialization\",\"link\":\"/CH5.MLP/MLP_4\"},{\"text\":\"Generalization in Deep Learning\",\"link\":\"/CH5.MLP/MLP_5\"},{\"text\":\"Dropout\",\"link\":\"/CH5.MLP/MLP_6\"}]},{\"text\":\"Convolutional Neural Networks\",\"collapsed\":false,\"items\":[{\"text\":\"Convolutions for Images\",\"link\":\"/CH6.Convolutional_Neural_Networks/CNN_2\"},{\"text\":\"Padding and Stride\",\"link\":\"/CH6.Convolutional_Neural_Networks/CNN_3\"},{\"text\":\"Multiple Input and Multiple Output Channels\",\"link\":\"/CH6.Convolutional_Neural_Networks/CNN_4\"},{\"text\":\"Pooling\",\"link\":\"/CH6.Convolutional_Neural_Networks/CNN_5\"},{\"text\":\"Convolutional Neural Networks (LeNet)\",\"link\":\"/CH6.Convolutional_Neural_Networks/CNN_6\"}]},{\"text\":\"Modern Convolutional Neural Networks\",\"collapsed\":false,\"items\":[{\"text\":\"Modern Convolutional Neural Networks\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_0\"},{\"text\":\"Deep Convolutional Neural Networks (AlexNet)\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_1\"},{\"text\":\"Networks Using Blocks (VGG)\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_2\"},{\"text\":\"Network in Network (NiN)\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_3\"},{\"text\":\"Multi-Branch Networks  (GoogLeNet)\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_4\"},{\"text\":\"Batch Normalization\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_5\"},{\"text\":\"Residual Networks (ResNet) and ResNeXt\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_6\"},{\"text\":\"Densely Connected Networks (DenseNet)\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_7\"},{\"text\":\"Designing Convolution Network Architectures\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_8\"}]},{\"text\":\"Recurrent Neural Networks\",\"collapsed\":false,\"items\":[{\"text\":\"Recurrent Neural Networks\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_0\"},{\"text\":\"Working with Sequences\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_1\"},{\"text\":\"Converting Raw Text into Sequence Data\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_2\"},{\"text\":\"Language Models\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_3\"},{\"text\":\"Recurrent Neural Networks\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_4\"},{\"text\":\"Recurrent Neural Network Implementation from Scratch\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_5\"},{\"text\":\"Concise Implementation of Recurrent Neural Networks\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_6\"},{\"text\":\"Backpropagation Through Time\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_7\"}]},{\"text\":\"Modern Recurrent Neural Networks\",\"collapsed\":false,\"items\":[{\"text\":\"Long Short-Term Memory (LSTM)\",\"link\":\"/CH9.Modern_Recurrent_Neural_Networks/MRNN_1\"},{\"text\":\"Gated Recurrent Units (GRU)\",\"link\":\"/CH9.Modern_Recurrent_Neural_Networks/MRNN_2\"},{\"text\":\"Deep Recurrent Neural Networks\",\"link\":\"/CH9.Modern_Recurrent_Neural_Networks/MRNN_3\"},{\"text\":\"Bidirectional Recurrent Neural Networks\",\"link\":\"/CH9.Modern_Recurrent_Neural_Networks/MRNN_4\"},{\"text\":\"Machine Translation and the Dataset\",\"link\":\"/CH9.Modern_Recurrent_Neural_Networks/MRNN_5\"},{\"text\":\"The Encoder–Decoder Architecture\",\"link\":\"/CH9.Modern_Recurrent_Neural_Networks/MRNN_6\"},{\"text\":\"Sequence-to-Sequence Learning for Machine Translation\",\"link\":\"/CH9.Modern_Recurrent_Neural_Networks/MRNN_7\"}]},{\"text\":\"Attention Mechanisms and Transformers\",\"collapsed\":false,\"items\":[{\"text\":\"Queries, Keys, and Values\",\"link\":\"/CH10.Attention_Mechanisms_and_Transformers/ATTN_1\"},{\"text\":\"Attention Pooling by Similarity\",\"link\":\"/CH10.Attention_Mechanisms_and_Transformers/ATTN_2\"},{\"text\":\"Attention Scoring Functions\",\"link\":\"/CH10.Attention_Mechanisms_and_Transformers/ATTN_3\"},{\"text\":\"The Bahdanau Attention Mechanism\",\"link\":\"/CH10.Attention_Mechanisms_and_Transformers/ATTN_4\"},{\"text\":\"Multi-Head Attention\",\"link\":\"/CH10.Attention_Mechanisms_and_Transformers/ATTN_5\"},{\"text\":\"Self-Attention and Positional Encoding\",\"link\":\"/CH10.Attention_Mechanisms_and_Transformers/ATTN_6\"},{\"text\":\"CH10.Attention_Mechanisms_and_Transformers/Untitled\",\"link\":\"/CH10.Attention_Mechanisms_and_Transformers/Untitled\"}]}]},{\"text\":\"References\",\"link\":\"/references\"}],\"editLink\":{\"pattern\":\"https://https://github.com/ashutosh-b-b/d2l-julia/edit/master/docs/src/:path\"},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/ashutosh-b-b/d2l-julia\"}],\"footer\":{\"message\":\"Made with <a href=\\\"https://luxdl.github.io/DocumenterVitepress.jl/dev/\\\" target=\\\"_blank\\\"><strong>DocumenterVitepress.jl</strong></a><br>\",\"copyright\":\"© Copyright 2025.\"}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":true}");</script>
    
  </body>
</html>