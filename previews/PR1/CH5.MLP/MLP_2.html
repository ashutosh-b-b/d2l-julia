<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Implementation of Multilayer Perceptrons | d2l Julia</title>
    <meta name="description" content="Documentation for d2l-julia">
    <meta name="generator" content="VitePress v1.6.3">
    <link rel="preload stylesheet" href="/d2l-julia/previews/PR1/assets/style.BUOi7SFr.css" as="style">
    <link rel="preload stylesheet" href="/d2l-julia/previews/PR1/vp-icons.css" as="style">
    
    <script type="module" src="/d2l-julia/previews/PR1/assets/app.DyCk50An.js"></script>
    <link rel="preload" href="/d2l-julia/previews/PR1/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/d2l-julia/previews/PR1/assets/chunks/theme.CszcN3qP.js">
    <link rel="modulepreload" href="/d2l-julia/previews/PR1/assets/chunks/framework.DjA5121Y.js">
    <link rel="modulepreload" href="/d2l-julia/previews/PR1/assets/CH5.MLP_MLP_2.md.MI21_tyz.lean.js">
    <script src="/d2l-julia/versions.js"></script>
    <script src="/d2l-julia/previews/PR1/siteinfo.js"></script>
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-a9a9e638><!--[--><!--]--><!--[--><span tabindex="-1" data-v-492508fc></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-492508fc>Skip to content</a><!--]--><!----><header class="VPNav" data-v-a9a9e638 data-v-f1e365da><div class="VPNavBar" data-v-f1e365da data-v-822684d1><div class="wrapper" data-v-822684d1><div class="container" data-v-822684d1><div class="title" data-v-822684d1><div class="VPNavBarTitle has-sidebar" data-v-822684d1 data-v-0f4f798b><a class="title" href="/d2l-julia/previews/PR1/" data-v-0f4f798b><!--[--><!--]--><!--[--><img class="VPImage logo" src="/d2l-julia/previews/PR1/logo.png" width="24" height="24" alt data-v-35a7d0b8><!--]--><span data-v-0f4f798b>d2l Julia</span><!--[--><!--]--></a></div></div><div class="content" data-v-822684d1><div class="content-body" data-v-822684d1><!--[--><!--]--><div class="VPNavBarSearch search" data-v-822684d1><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-822684d1 data-v-e6d46098><span id="main-nav-aria-label" class="visually-hidden" data-v-e6d46098> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/d2l-julia/previews/PR1/index" tabindex="0" data-v-e6d46098 data-v-956ec74c><!--[--><span data-v-956ec74c>Home</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup active" data-v-e6d46098 data-v-04f5c5e9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-04f5c5e9><span class="text" data-v-04f5c5e9><!----><span data-v-04f5c5e9>Chapters</span><span class="vpi-chevron-down text-icon" data-v-04f5c5e9></span></span></button><div class="menu" data-v-04f5c5e9><div class="VPMenu" data-v-04f5c5e9 data-v-7dd3104a><div class="items" data-v-7dd3104a><!--[--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/chapters" data-v-acbfed09><!--[--><span data-v-acbfed09>ðŸ“˜ Chapters Overview</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuGroup" data-v-7dd3104a data-v-48c802d0><p class="title" data-v-48c802d0>Linear Neural Networks for Regression</p><!--[--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH3.Linear_Regression/LNN_1" data-v-acbfed09><!--[--><span data-v-acbfed09>Linear Regression</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH3.Linear_Regression/LNN_2" data-v-acbfed09><!--[--><span data-v-acbfed09>Multiple Dispatch Design for Implementation</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH3.Linear_Regression/LNN_3" data-v-acbfed09><!--[--><span data-v-acbfed09>Synthetic Regression Data</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH3.Linear_Regression/LNN_4" data-v-acbfed09><!--[--><span data-v-acbfed09>Linear Regression Implementation from Scratch</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH3.Linear_Regression/LNN_5" data-v-acbfed09><!--[--><span data-v-acbfed09>Concise Implementation of Linear Regression</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH3.Linear_Regression/LNN_6" data-v-acbfed09><!--[--><span data-v-acbfed09>Generalization</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH3.Linear_Regression/LNN_7" data-v-acbfed09><!--[--><span data-v-acbfed09>Weight Decay</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-7dd3104a data-v-48c802d0><p class="title" data-v-48c802d0>Linear Neural Networks for Classification</p><!--[--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH4.Linear_Classification/LCN_1" data-v-acbfed09><!--[--><span data-v-acbfed09>Softmax Regression</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH4.Linear_Classification/LCN_2" data-v-acbfed09><!--[--><span data-v-acbfed09>The Image Classification Dataset</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH4.Linear_Classification/LCN_3" data-v-acbfed09><!--[--><span data-v-acbfed09>Softmax Regression Implementation from Scratch</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH4.Linear_Classification/LCN_4" data-v-acbfed09><!--[--><span data-v-acbfed09>Concise Implementation of Softmax Regression</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH4.Linear_Classification/LCN_5" data-v-acbfed09><!--[--><span data-v-acbfed09>Generalization in Classification</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH4.Linear_Classification/LCN_6" data-v-acbfed09><!--[--><span data-v-acbfed09>Environment and Distribution Shift</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-7dd3104a data-v-48c802d0><p class="title" data-v-48c802d0>Multilayer Perceptron</p><!--[--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH5.MLP/MLP_1" data-v-acbfed09><!--[--><span data-v-acbfed09>Multilayer Perceptrons</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link active" href="/d2l-julia/previews/PR1/CH5.MLP/MLP_2" data-v-acbfed09><!--[--><span data-v-acbfed09>Implementation of Multilayer Perceptrons</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH5.MLP/MLP_3" data-v-acbfed09><!--[--><span data-v-acbfed09>Forward Propagation, Backward Propagation, and Computational Graphs</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH5.MLP/MLP_4" data-v-acbfed09><!--[--><span data-v-acbfed09>Numerical Stability and Initialization</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH5.MLP/MLP_5" data-v-acbfed09><!--[--><span data-v-acbfed09>Generalization in Deep Learning</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH5.MLP/MLP_6" data-v-acbfed09><!--[--><span data-v-acbfed09>Dropout</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-7dd3104a data-v-48c802d0><p class="title" data-v-48c802d0>Convolutional Neural Networks</p><!--[--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH6.Convolutional_Neural_Networks/CNN_2" data-v-acbfed09><!--[--><span data-v-acbfed09>Convolutions for Images</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH6.Convolutional_Neural_Networks/CNN_3" data-v-acbfed09><!--[--><span data-v-acbfed09>Padding and Stride</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH6.Convolutional_Neural_Networks/CNN_4" data-v-acbfed09><!--[--><span data-v-acbfed09>Multiple Input and Multiple Output Channels</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH6.Convolutional_Neural_Networks/CNN_5" data-v-acbfed09><!--[--><span data-v-acbfed09>Pooling</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH6.Convolutional_Neural_Networks/CNN_6" data-v-acbfed09><!--[--><span data-v-acbfed09>Convolutional Neural Networks (LeNet)</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-7dd3104a data-v-48c802d0><p class="title" data-v-48c802d0>Modern Convolutional Neural Networks</p><!--[--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_0" data-v-acbfed09><!--[--><span data-v-acbfed09>Modern Convolutional Neural Networks</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_1" data-v-acbfed09><!--[--><span data-v-acbfed09>Deep Convolutional Neural Networks (AlexNet)</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_2" data-v-acbfed09><!--[--><span data-v-acbfed09>Networks Using Blocks (VGG)</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_3" data-v-acbfed09><!--[--><span data-v-acbfed09>Network in Network (NiN)</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_4" data-v-acbfed09><!--[--><span data-v-acbfed09>Multi-Branch Networks  (GoogLeNet)</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_5" data-v-acbfed09><!--[--><span data-v-acbfed09>Batch Normalization</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_6" data-v-acbfed09><!--[--><span data-v-acbfed09>Residual Networks (ResNet) and ResNeXt</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_7" data-v-acbfed09><!--[--><span data-v-acbfed09>Densely Connected Networks (DenseNet)</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_8" data-v-acbfed09><!--[--><span data-v-acbfed09>Designing Convolution Network Architectures</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-7dd3104a data-v-48c802d0><p class="title" data-v-48c802d0>Recurrent Neural Networks</p><!--[--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_0" data-v-acbfed09><!--[--><span data-v-acbfed09>Recurrent Neural Networks</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_1" data-v-acbfed09><!--[--><span data-v-acbfed09>Working with Sequences</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_2" data-v-acbfed09><!--[--><span data-v-acbfed09>Converting Raw Text into Sequence Data</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_3" data-v-acbfed09><!--[--><span data-v-acbfed09>Language Models</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_4" data-v-acbfed09><!--[--><span data-v-acbfed09>Recurrent Neural Networks</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_5" data-v-acbfed09><!--[--><span data-v-acbfed09>Recurrent Neural Network Implementation from Scratch</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_6" data-v-acbfed09><!--[--><span data-v-acbfed09>Concise Implementation of Recurrent Neural Networks</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_7" data-v-acbfed09><!--[--><span data-v-acbfed09>Backpropagation Through Time</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-7dd3104a data-v-48c802d0><p class="title" data-v-48c802d0>Modern Recurrent Neural Networks</p><!--[--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH9.Modern_Recurrent_Neural_Networks/MRNN_1" data-v-acbfed09><!--[--><span data-v-acbfed09>Long Short-Term Memory (LSTM)</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH9.Modern_Recurrent_Neural_Networks/MRNN_2" data-v-acbfed09><!--[--><span data-v-acbfed09>Gated Recurrent Units (GRU)</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH9.Modern_Recurrent_Neural_Networks/MRNN_3" data-v-acbfed09><!--[--><span data-v-acbfed09>Deep Recurrent Neural Networks</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH9.Modern_Recurrent_Neural_Networks/MRNN_4" data-v-acbfed09><!--[--><span data-v-acbfed09>Bidirectional Recurrent Neural Networks</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH9.Modern_Recurrent_Neural_Networks/MRNN_5" data-v-acbfed09><!--[--><span data-v-acbfed09>Machine Translation and the Dataset</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH9.Modern_Recurrent_Neural_Networks/MRNN_6" data-v-acbfed09><!--[--><span data-v-acbfed09>The Encoderâ€“Decoder Architecture</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH9.Modern_Recurrent_Neural_Networks/MRNN_7" data-v-acbfed09><!--[--><span data-v-acbfed09>Sequence-to-Sequence Learning for Machine Translation</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-7dd3104a data-v-48c802d0><p class="title" data-v-48c802d0>Attention Mechanisms and Transformers</p><!--[--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH10.Attention_Mechanisms_and_Transformers/ATTN_1" data-v-acbfed09><!--[--><span data-v-acbfed09>Queries, Keys, and Values</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH10.Attention_Mechanisms_and_Transformers/ATTN_2" data-v-acbfed09><!--[--><span data-v-acbfed09>Attention Pooling by Similarity</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH10.Attention_Mechanisms_and_Transformers/ATTN_3" data-v-acbfed09><!--[--><span data-v-acbfed09>Attention Scoring Functions</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH10.Attention_Mechanisms_and_Transformers/ATTN_4" data-v-acbfed09><!--[--><span data-v-acbfed09>The Bahdanau Attention Mechanism</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH10.Attention_Mechanisms_and_Transformers/ATTN_5" data-v-acbfed09><!--[--><span data-v-acbfed09>Multi-Head Attention</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH10.Attention_Mechanisms_and_Transformers/ATTN_6" data-v-acbfed09><!--[--><span data-v-acbfed09>Self-Attention and Positional Encoding</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-48c802d0 data-v-acbfed09><a class="VPLink link" href="/d2l-julia/previews/PR1/CH10.Attention_Mechanisms_and_Transformers/Untitled" data-v-acbfed09><!--[--><span data-v-acbfed09>CH10.Attention_Mechanisms_and_Transformers/Untitled</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/d2l-julia/previews/PR1/references" tabindex="0" data-v-e6d46098 data-v-956ec74c><!--[--><span data-v-956ec74c>References</span><!--]--></a><!--]--><!--[--><!----><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-822684d1 data-v-af096f4a><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-af096f4a data-v-e40a8bb6 data-v-4a1c76db><span class="check" data-v-4a1c76db><span class="icon" data-v-4a1c76db><!--[--><span class="vpi-sun sun" data-v-e40a8bb6></span><span class="vpi-moon moon" data-v-e40a8bb6></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-822684d1 data-v-164c457f data-v-ee7a9424><!--[--><a class="VPSocialLink no-icon" href="https://github.com/ashutosh-b-b/d2l-julia" aria-label="github" target="_blank" rel="noopener" data-v-ee7a9424 data-v-d26d30cb><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-822684d1 data-v-925effce data-v-04f5c5e9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-04f5c5e9><span class="vpi-more-horizontal icon" data-v-04f5c5e9></span></button><div class="menu" data-v-04f5c5e9><div class="VPMenu" data-v-04f5c5e9 data-v-7dd3104a><!----><!--[--><!--[--><!----><div class="group" data-v-925effce><div class="item appearance" data-v-925effce><p class="label" data-v-925effce>Appearance</p><div class="appearance-action" data-v-925effce><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-925effce data-v-e40a8bb6 data-v-4a1c76db><span class="check" data-v-4a1c76db><span class="icon" data-v-4a1c76db><!--[--><span class="vpi-sun sun" data-v-e40a8bb6></span><span class="vpi-moon moon" data-v-e40a8bb6></span><!--]--></span></span></button></div></div></div><div class="group" data-v-925effce><div class="item social-links" data-v-925effce><div class="VPSocialLinks social-links-list" data-v-925effce data-v-ee7a9424><!--[--><a class="VPSocialLink no-icon" href="https://github.com/ashutosh-b-b/d2l-julia" aria-label="github" target="_blank" rel="noopener" data-v-ee7a9424 data-v-d26d30cb><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--[--><!--[--><div class="VPFlyout VPNolebaseEnhancedReadabilitiesMenu VPNolebaseEnhancedReadabilitiesMenuFlyout" aria-label="Enhanced Readability" role="menuitem" data-v-04f5c5e9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-04f5c5e9><span class="text" data-v-04f5c5e9><span class="i-icon-park-outline:book-open option-icon" data-v-04f5c5e9></span><!----><span class="vpi-chevron-down text-icon" data-v-04f5c5e9></span></span></button><div class="menu" data-v-04f5c5e9><div class="VPMenu" data-v-04f5c5e9 data-v-7dd3104a><!----><!--[--><!--]--></div></div></div><!--]--><!--]--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-822684d1 data-v-5dea55bf><span class="container" data-v-5dea55bf><span class="top" data-v-5dea55bf></span><span class="middle" data-v-5dea55bf></span><span class="bottom" data-v-5dea55bf></span></span></button></div></div></div></div><div class="divider" data-v-822684d1><div class="divider-line" data-v-822684d1></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-a9a9e638 data-v-070ab83d><div class="container" data-v-070ab83d><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-070ab83d><span class="vpi-align-left menu-icon" data-v-070ab83d></span><span class="menu-text" data-v-070ab83d>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-070ab83d data-v-168ddf5d><button data-v-168ddf5d>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-a9a9e638 data-v-18756405><div class="curtain" data-v-18756405></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-18756405><span class="visually-hidden" id="sidebar-aria-label" data-v-18756405> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-9e426adc><section class="VPSidebarItem level-0" data-v-9e426adc data-v-a4b0d9bf><!----><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/index" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Home</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-9e426adc><section class="VPSidebarItem level-0 collapsible has-active" data-v-9e426adc data-v-a4b0d9bf><div class="item" role="button" tabindex="0" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><h2 class="text" data-v-a4b0d9bf>Chapters</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-a4b0d9bf><span class="vpi-chevron-right caret-icon" data-v-a4b0d9bf></span></div></div><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/chapters" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>ðŸ“˜ Chapters Overview</p><!--]--></a><!----></div><!----></div><section class="VPSidebarItem level-1 collapsible" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" role="button" tabindex="0" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><h3 class="text" data-v-a4b0d9bf>Linear Neural Networks for Regression</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-a4b0d9bf><span class="vpi-chevron-right caret-icon" data-v-a4b0d9bf></span></div></div><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH3.Linear_Regression/LNN_1" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Linear Regression</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH3.Linear_Regression/LNN_2" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Multiple Dispatch Design for Implementation</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH3.Linear_Regression/LNN_3" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Synthetic Regression Data</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH3.Linear_Regression/LNN_4" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Linear Regression Implementation from Scratch</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH3.Linear_Regression/LNN_5" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Concise Implementation of Linear Regression</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH3.Linear_Regression/LNN_6" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Generalization</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH3.Linear_Regression/LNN_7" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Weight Decay</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" role="button" tabindex="0" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><h3 class="text" data-v-a4b0d9bf>Linear Neural Networks for Classification</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-a4b0d9bf><span class="vpi-chevron-right caret-icon" data-v-a4b0d9bf></span></div></div><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH4.Linear_Classification/LCN_1" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Softmax Regression</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH4.Linear_Classification/LCN_2" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>The Image Classification Dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH4.Linear_Classification/LCN_3" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Softmax Regression Implementation from Scratch</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH4.Linear_Classification/LCN_4" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Concise Implementation of Softmax Regression</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH4.Linear_Classification/LCN_5" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Generalization in Classification</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH4.Linear_Classification/LCN_6" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Environment and Distribution Shift</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible has-active" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" role="button" tabindex="0" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><h3 class="text" data-v-a4b0d9bf>Multilayer Perceptron</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-a4b0d9bf><span class="vpi-chevron-right caret-icon" data-v-a4b0d9bf></span></div></div><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH5.MLP/MLP_1" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Multilayer Perceptrons</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH5.MLP/MLP_2" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Implementation of Multilayer Perceptrons</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH5.MLP/MLP_3" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Forward Propagation, Backward Propagation, and Computational Graphs</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH5.MLP/MLP_4" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Numerical Stability and Initialization</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH5.MLP/MLP_5" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Generalization in Deep Learning</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH5.MLP/MLP_6" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Dropout</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" role="button" tabindex="0" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><h3 class="text" data-v-a4b0d9bf>Convolutional Neural Networks</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-a4b0d9bf><span class="vpi-chevron-right caret-icon" data-v-a4b0d9bf></span></div></div><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH6.Convolutional_Neural_Networks/CNN_2" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Convolutions for Images</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH6.Convolutional_Neural_Networks/CNN_3" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Padding and Stride</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH6.Convolutional_Neural_Networks/CNN_4" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Multiple Input and Multiple Output Channels</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH6.Convolutional_Neural_Networks/CNN_5" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Pooling</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH6.Convolutional_Neural_Networks/CNN_6" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Convolutional Neural Networks (LeNet)</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" role="button" tabindex="0" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><h3 class="text" data-v-a4b0d9bf>Modern Convolutional Neural Networks</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-a4b0d9bf><span class="vpi-chevron-right caret-icon" data-v-a4b0d9bf></span></div></div><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_0" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Modern Convolutional Neural Networks</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_1" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Deep Convolutional Neural Networks (AlexNet)</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_2" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Networks Using Blocks (VGG)</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_3" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Network in Network (NiN)</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_4" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Multi-Branch Networks  (GoogLeNet)</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_5" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Batch Normalization</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_6" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Residual Networks (ResNet) and ResNeXt</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_7" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Densely Connected Networks (DenseNet)</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH7.ModernConvolutionalNeuralNetworks/MCNN_8" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Designing Convolution Network Architectures</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" role="button" tabindex="0" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><h3 class="text" data-v-a4b0d9bf>Recurrent Neural Networks</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-a4b0d9bf><span class="vpi-chevron-right caret-icon" data-v-a4b0d9bf></span></div></div><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_0" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Recurrent Neural Networks</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_1" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Working with Sequences</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_2" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Converting Raw Text into Sequence Data</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_3" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Language Models</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_4" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Recurrent Neural Networks</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_5" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Recurrent Neural Network Implementation from Scratch</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_6" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Concise Implementation of Recurrent Neural Networks</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH8.Recurrent_Neural_Networks/RNN_7" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Backpropagation Through Time</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" role="button" tabindex="0" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><h3 class="text" data-v-a4b0d9bf>Modern Recurrent Neural Networks</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-a4b0d9bf><span class="vpi-chevron-right caret-icon" data-v-a4b0d9bf></span></div></div><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH9.Modern_Recurrent_Neural_Networks/MRNN_1" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Long Short-Term Memory (LSTM)</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH9.Modern_Recurrent_Neural_Networks/MRNN_2" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Gated Recurrent Units (GRU)</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH9.Modern_Recurrent_Neural_Networks/MRNN_3" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Deep Recurrent Neural Networks</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH9.Modern_Recurrent_Neural_Networks/MRNN_4" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Bidirectional Recurrent Neural Networks</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH9.Modern_Recurrent_Neural_Networks/MRNN_5" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Machine Translation and the Dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH9.Modern_Recurrent_Neural_Networks/MRNN_6" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>The Encoderâ€“Decoder Architecture</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH9.Modern_Recurrent_Neural_Networks/MRNN_7" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Sequence-to-Sequence Learning for Machine Translation</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" role="button" tabindex="0" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><h3 class="text" data-v-a4b0d9bf>Attention Mechanisms and Transformers</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-a4b0d9bf><span class="vpi-chevron-right caret-icon" data-v-a4b0d9bf></span></div></div><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH10.Attention_Mechanisms_and_Transformers/ATTN_1" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Queries, Keys, and Values</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH10.Attention_Mechanisms_and_Transformers/ATTN_2" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Attention Pooling by Similarity</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH10.Attention_Mechanisms_and_Transformers/ATTN_3" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Attention Scoring Functions</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH10.Attention_Mechanisms_and_Transformers/ATTN_4" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>The Bahdanau Attention Mechanism</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH10.Attention_Mechanisms_and_Transformers/ATTN_5" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Multi-Head Attention</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH10.Attention_Mechanisms_and_Transformers/ATTN_6" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Self-Attention and Positional Encoding</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/CH10.Attention_Mechanisms_and_Transformers/Untitled" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>CH10.Attention_Mechanisms_and_Transformers/Untitled</p><!--]--></a><!----></div><!----></div><!--]--></div></section><!--]--></div></section></div><div class="no-transition group" data-v-9e426adc><section class="VPSidebarItem level-0" data-v-9e426adc data-v-a4b0d9bf><!----><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/d2l-julia/previews/PR1/references" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>References</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-a9a9e638 data-v-91765379><div class="VPDoc has-sidebar has-aside" data-v-91765379 data-v-83890dd9><!--[--><!--]--><div class="container" data-v-83890dd9><div class="aside" data-v-83890dd9><div class="aside-curtain" data-v-83890dd9></div><div class="aside-container" data-v-83890dd9><div class="aside-content" data-v-83890dd9><div class="VPDocAside" data-v-83890dd9 data-v-6d7b3c46><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-6d7b3c46 data-v-b38bf2ff><div class="content" data-v-b38bf2ff><div class="outline-marker" data-v-b38bf2ff></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-b38bf2ff>On this page</div><ul class="VPDocOutlineItem root" data-v-b38bf2ff data-v-3f927ebe><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-6d7b3c46></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-83890dd9><div class="content-container" data-v-83890dd9><!--[--><!--]--><main class="main" data-v-83890dd9><div style="position:relative;" class="vp-doc _d2l-julia_previews_PR1_CH5_MLP_MLP_2" data-v-83890dd9><div><h1 id="Implementation-of-Multilayer-Perceptrons" tabindex="-1">Implementation of Multilayer Perceptrons <a class="header-anchor" href="#Implementation-of-Multilayer-Perceptrons" aria-label="Permalink to &quot;Implementation of Multilayer Perceptrons {#Implementation-of-Multilayer-Perceptrons}&quot;">â€‹</a></h1><p>Multilayer perceptrons (MLPs) are not much more complex to implement than simple linear models. The key conceptual difference is that we now concatenate multiple layers.</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">using</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Pkg</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Pkg</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">activate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;../../d2lai&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">using</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> d2lai, Flux, Plots, Distributions</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>  Activating project at `/workspace/workspace/d2l-julia/d2lai`</span></span></code></pre></div><h3 id="Initializing-Model-Parameters" tabindex="-1">Initializing Model Parameters <a class="header-anchor" href="#Initializing-Model-Parameters" aria-label="Permalink to &quot;Initializing Model Parameters {#Initializing-Model-Parameters}&quot;">â€‹</a></h3><p>Recall that Fashion-MNIST contains 10 classes, and that each image consists of a <mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.186ex;" xmlns="http://www.w3.org/2000/svg" width="13.701ex" height="1.717ex" role="img" focusable="false" viewBox="0 -677 6056 759" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" style="stroke-width:3;"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(500,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1222.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(2222.4,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" style="stroke-width:3;"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(500,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3500.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(4556,0)"><path data-c="37" d="M55 458Q56 460 72 567L88 674Q88 676 108 676H128V672Q128 662 143 655T195 646T364 644H485V605L417 512Q408 500 387 472T360 435T339 403T319 367T305 330T292 284T284 230T278 162T275 80Q275 66 275 52T274 28V19Q270 2 255 -10T221 -22Q210 -22 200 -19T179 0T168 40Q168 198 265 368Q285 400 349 489L395 552H302Q128 552 119 546Q113 543 108 522T98 479L95 458V455H55V458Z" style="stroke-width:3;"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(500,0)" style="stroke-width:3;"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(1000,0)" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>28</mn><mo>Ã—</mo><mn>28</mn><mo>=</mo><mn>784</mn></math></mjx-assistive-mml></mjx-container> grid of grayscale pixel values. As before we will disregard the spatial structure among the pixels for now, so we can think of this as a classification dataset with 784 input features and 10 classes. To begin, we will implement an MLP with one hidden layer and 256 hidden units. Both the number of layers and their width are adjustable (they are considered hyperparameters). Typically, we choose the layer widths to be divisible by larger powers of 2. This is computationally efficient due to the way memory is allocated and addressed in hardware.</p><p>Again, we will represent our parameters with several tensors. Note that <em>for every layer</em>, we must keep track of one weight matrix and one bias vector. As always, we allocate memory for the gradients of the loss with respect to these parameters.</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">struct</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> MLP </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> AbstractClassifier</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    W1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">AbstractArray</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    W2</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">AbstractArray</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    B1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">AbstractArray</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    B2</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">AbstractArray</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    args</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">NamedTuple</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">end</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">function</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> MLP</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(num_inputs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, num_outputs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, num_hiddens</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, lr, sigma </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.01</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    W1 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> rand</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Normal</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, sigma), (num_hiddens, num_inputs))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    B1 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> zeros</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(num_hiddens, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    W2 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> rand</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Normal</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, sigma), (num_outputs, num_hiddens))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    B2 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> zeros</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(num_outputs, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    args </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (num_inputs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> num_inputs, num_hiddens </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> num_hiddens, num_outputs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> num_outputs, lr </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> lr)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    MLP</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(W1, W2, B1, B2, args)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">end</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Flux</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">@layer</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> MLP trainable</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(W1,W2,B1,B2)</span></span></code></pre></div><h3 id="Model" tabindex="-1">Model <a class="header-anchor" href="#Model" aria-label="Permalink to &quot;Model {#Model}&quot;">â€‹</a></h3><p>To make sure we know how everything works, we will implement the ReLU activation ourselves rather than invoking the built-in <code>relu</code> function directly.</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">relu_custom</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> max</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>relu_custom (generic function with 1 method)</span></span></code></pre></div><p>Since we are disregarding spatial structure, we <code>reshape</code> each two-dimensional image into a flat vector of length <code>num_inputs</code>. Finally, we (<strong>implement our model</strong>) with just a few lines of code. Since we use the framework built-in autograd this is all that it takes.</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">function</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> d2lai</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(m</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">MLP</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, x)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    H </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> relu_custom</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.(m</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">W1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.+</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> m</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">B1)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    O </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> softmax</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(m</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">W2</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">H </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.+</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> m</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">B2)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> O</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">end</span></span></code></pre></div><h3 id="Training" tabindex="-1">Training <a class="header-anchor" href="#Training" aria-label="Permalink to &quot;Training {#Training}&quot;">â€‹</a></h3><p>Fortunately, the training loop for MLPs is exactly the same as for softmax regression. We define the model, data, and trainer, then finally invoke the <code>fit</code> method on model and data.</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">function</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> d2lai</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">loss</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(m</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">MLP</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, y_pred, y)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # cross entropy </span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # y_pred is an array of n_outputs x batchsize </span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # y actual is a vector of labels </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    y_prob </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> getindex</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">eachcol</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(y_pred), y </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    mean</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">log</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.(y_prob))</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">end</span></span></code></pre></div><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> MLP</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">28</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">28</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.01</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">opt </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> Descent</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.01</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">data </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> d2lai</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">FashionMNISTData</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(; batchsize </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, flatten</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">true</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">trainer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> Trainer</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(model, data, opt; max_epochs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">d2lai</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">fit</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(trainer)</span></span></code></pre></div><div style="max-height:300px;overflow-y:auto;background:#111;color:#eee;padding:1em;border-radius:5px;"><pre>    [ Info: Train Loss: 1.8086399910502988, Val Loss: 1.8758227031595318, Val Acc: 0.4375
    [ Info: Train Loss: 1.1667184916733622, Val Loss: 1.2518912257203245, Val Acc: 0.625
    [ Info: Train Loss: 1.0179561515744096, Val Loss: 0.9484510179121753, Val Acc: 0.6875
    [ Info: Train Loss: 0.8624210317622039, Val Loss: 0.792685096123279, Val Acc: 0.75
    [ Info: Train Loss: 0.8150524736874862, Val Loss: 0.6771740790875137, Val Acc: 0.75
    [ Info: Train Loss: 0.7064154271294161, Val Loss: 0.5977226518346531, Val Acc: 0.75
    [ Info: Train Loss: 0.6743462036084669, Val Loss: 0.5277229711836189, Val Acc: 0.8125
    [ Info: Train Loss: 0.5125813502508515, Val Loss: 0.47928279763561915, Val Acc: 0.9375
    [ Info: Train Loss: 0.6353711775451608, Val Loss: 0.4239313740731752, Val Acc: 0.9375
    [ Info: Train Loss: 0.49330677526811845, Val Loss: 0.39833012812119917, Val Acc: 0.875</pre></div><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="600" height="400" viewBox="0 0 2400 1600"><defs><clipPath id="clip580"><rect x="0" y="0" width="2400" height="1600"></rect></clipPath></defs><path clip-path="url(#clip580)" d="M0 1600 L2400 1600 L2400 0 L0 0  Z" fill="#ffffff" fill-rule="evenodd" fill-opacity="1"></path><defs><clipPath id="clip581"><rect x="480" y="0" width="1681" height="1600"></rect></clipPath></defs><path clip-path="url(#clip580)" d="M224.554 1423.18 L2352.76 1423.18 L2352.76 47.2441 L224.554 47.2441  Z" fill="#ffffff" fill-rule="evenodd" fill-opacity="1"></path><defs><clipPath id="clip582"><rect x="224" y="47" width="2129" height="1377"></rect></clipPath></defs><polyline clip-path="url(#clip582)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:2;stroke-opacity:0.1;fill:none;" points="507.868,1423.18 507.868,47.2441 "></polyline><polyline clip-path="url(#clip582)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:2;stroke-opacity:0.1;fill:none;" points="954.032,1423.18 954.032,47.2441 "></polyline><polyline clip-path="url(#clip582)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:2;stroke-opacity:0.1;fill:none;" points="1400.2,1423.18 1400.2,47.2441 "></polyline><polyline clip-path="url(#clip582)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:2;stroke-opacity:0.1;fill:none;" points="1846.36,1423.18 1846.36,47.2441 "></polyline><polyline clip-path="url(#clip582)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:2;stroke-opacity:0.1;fill:none;" points="2292.52,1423.18 2292.52,47.2441 "></polyline><polyline clip-path="url(#clip582)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:2;stroke-opacity:0.1;fill:none;" points="224.554,1149.64 2352.76,1149.64 "></polyline><polyline clip-path="url(#clip582)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:2;stroke-opacity:0.1;fill:none;" points="224.554,747.762 2352.76,747.762 "></polyline><polyline clip-path="url(#clip582)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:2;stroke-opacity:0.1;fill:none;" points="224.554,345.881 2352.76,345.881 "></polyline><polyline clip-path="url(#clip580)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="224.554,1423.18 2352.76,1423.18 "></polyline><polyline clip-path="url(#clip580)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="507.868,1423.18 507.868,1404.28 "></polyline><polyline clip-path="url(#clip580)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="954.032,1423.18 954.032,1404.28 "></polyline><polyline clip-path="url(#clip580)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="1400.2,1423.18 1400.2,1404.28 "></polyline><polyline clip-path="url(#clip580)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="1846.36,1423.18 1846.36,1404.28 "></polyline><polyline clip-path="url(#clip580)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="2292.52,1423.18 2292.52,1404.28 "></polyline><path clip-path="url(#clip580)" d="M502.521 1481.64 L518.84 1481.64 L518.84 1485.58 L496.896 1485.58 L496.896 1481.64 Q499.558 1478.89 504.141 1474.26 Q508.747 1469.61 509.928 1468.27 Q512.173 1465.74 513.053 1464.01 Q513.956 1462.25 513.956 1460.56 Q513.956 1457.8 512.011 1456.07 Q510.09 1454.33 506.988 1454.33 Q504.789 1454.33 502.335 1455.09 Q499.905 1455.86 497.127 1457.41 L497.127 1452.69 Q499.951 1451.55 502.405 1450.97 Q504.858 1450.39 506.896 1450.39 Q512.266 1450.39 515.46 1453.08 Q518.655 1455.77 518.655 1460.26 Q518.655 1462.39 517.845 1464.31 Q517.058 1466.2 514.951 1468.8 Q514.372 1469.47 511.271 1472.69 Q508.169 1475.88 502.521 1481.64 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M957.041 1455.09 L945.235 1473.54 L957.041 1473.54 L957.041 1455.09 M955.814 1451.02 L961.694 1451.02 L961.694 1473.54 L966.624 1473.54 L966.624 1477.43 L961.694 1477.43 L961.694 1485.58 L957.041 1485.58 L957.041 1477.43 L941.439 1477.43 L941.439 1472.92 L955.814 1451.02 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M1400.6 1466.44 Q1397.45 1466.44 1395.6 1468.59 Q1393.77 1470.74 1393.77 1474.49 Q1393.77 1478.22 1395.6 1480.39 Q1397.45 1482.55 1400.6 1482.55 Q1403.75 1482.55 1405.58 1480.39 Q1407.43 1478.22 1407.43 1474.49 Q1407.43 1470.74 1405.58 1468.59 Q1403.75 1466.44 1400.6 1466.44 M1409.88 1451.78 L1409.88 1456.04 Q1408.12 1455.21 1406.32 1454.77 Q1404.54 1454.33 1402.78 1454.33 Q1398.15 1454.33 1395.69 1457.45 Q1393.26 1460.58 1392.92 1466.9 Q1394.28 1464.89 1396.34 1463.82 Q1398.4 1462.73 1400.88 1462.73 Q1406.09 1462.73 1409.1 1465.9 Q1412.13 1469.05 1412.13 1474.49 Q1412.13 1479.82 1408.98 1483.03 Q1405.83 1486.25 1400.6 1486.25 Q1394.61 1486.25 1391.43 1481.67 Q1388.26 1477.06 1388.26 1468.33 Q1388.26 1460.14 1392.15 1455.28 Q1396.04 1450.39 1402.59 1450.39 Q1404.35 1450.39 1406.13 1450.74 Q1407.94 1451.09 1409.88 1451.78 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M1846.36 1469.17 Q1843.03 1469.17 1841.11 1470.95 Q1839.21 1472.73 1839.21 1475.86 Q1839.21 1478.98 1841.11 1480.77 Q1843.03 1482.55 1846.36 1482.55 Q1849.69 1482.55 1851.61 1480.77 Q1853.54 1478.96 1853.54 1475.86 Q1853.54 1472.73 1851.61 1470.95 Q1849.72 1469.17 1846.36 1469.17 M1841.68 1467.18 Q1838.67 1466.44 1836.98 1464.38 Q1835.32 1462.32 1835.32 1459.35 Q1835.32 1455.21 1838.26 1452.8 Q1841.22 1450.39 1846.36 1450.39 Q1851.52 1450.39 1854.46 1452.8 Q1857.4 1455.21 1857.4 1459.35 Q1857.4 1462.32 1855.71 1464.38 Q1854.04 1466.44 1851.06 1467.18 Q1854.44 1467.96 1856.31 1470.26 Q1858.21 1472.55 1858.21 1475.86 Q1858.21 1480.88 1855.13 1483.57 Q1852.08 1486.25 1846.36 1486.25 Q1840.64 1486.25 1837.56 1483.57 Q1834.51 1480.88 1834.51 1475.86 Q1834.51 1472.55 1836.41 1470.26 Q1838.3 1467.96 1841.68 1467.18 M1839.97 1459.79 Q1839.97 1462.48 1841.64 1463.98 Q1843.33 1465.49 1846.36 1465.49 Q1849.37 1465.49 1851.06 1463.98 Q1852.77 1462.48 1852.77 1459.79 Q1852.77 1457.11 1851.06 1455.6 Q1849.37 1454.1 1846.36 1454.1 Q1843.33 1454.1 1841.64 1455.6 Q1839.97 1457.11 1839.97 1459.79 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M2267.21 1481.64 L2274.85 1481.64 L2274.85 1455.28 L2266.54 1456.95 L2266.54 1452.69 L2274.8 1451.02 L2279.48 1451.02 L2279.48 1481.64 L2287.12 1481.64 L2287.12 1485.58 L2267.21 1485.58 L2267.21 1481.64 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M2306.56 1454.1 Q2302.95 1454.1 2301.12 1457.66 Q2299.32 1461.2 2299.32 1468.33 Q2299.32 1475.44 2301.12 1479.01 Q2302.95 1482.55 2306.56 1482.55 Q2310.2 1482.55 2312 1479.01 Q2313.83 1475.44 2313.83 1468.33 Q2313.83 1461.2 2312 1457.66 Q2310.2 1454.1 2306.56 1454.1 M2306.56 1450.39 Q2312.37 1450.39 2315.43 1455 Q2318.51 1459.58 2318.51 1468.33 Q2318.51 1477.06 2315.43 1481.67 Q2312.37 1486.25 2306.56 1486.25 Q2300.75 1486.25 2297.67 1481.67 Q2294.62 1477.06 2294.62 1468.33 Q2294.62 1459.58 2297.67 1455 Q2300.75 1450.39 2306.56 1450.39 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M1208.84 1548.76 L1208.84 1551.62 L1181.92 1551.62 Q1182.3 1557.67 1185.55 1560.85 Q1188.82 1564 1194.65 1564 Q1198.02 1564 1201.17 1563.17 Q1204.36 1562.35 1207.48 1560.69 L1207.48 1566.23 Q1204.33 1567.57 1201.01 1568.27 Q1197.7 1568.97 1194.3 1568.97 Q1185.77 1568.97 1180.77 1564 Q1175.81 1559.04 1175.81 1550.57 Q1175.81 1541.82 1180.52 1536.69 Q1185.26 1531.54 1193.28 1531.54 Q1200.47 1531.54 1204.64 1536.18 Q1208.84 1540.8 1208.84 1548.76 M1202.99 1547.04 Q1202.92 1542.23 1200.28 1539.37 Q1197.67 1536.5 1193.34 1536.5 Q1188.44 1536.5 1185.48 1539.27 Q1182.55 1542.04 1182.11 1547.07 L1202.99 1547.04 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M1224.12 1562.7 L1224.12 1581.6 L1218.23 1581.6 L1218.23 1532.4 L1224.12 1532.4 L1224.12 1537.81 Q1225.97 1534.62 1228.77 1533.1 Q1231.6 1531.54 1235.52 1531.54 Q1242.01 1531.54 1246.05 1536.69 Q1250.13 1541.85 1250.13 1550.25 Q1250.13 1558.65 1246.05 1563.81 Q1242.01 1568.97 1235.52 1568.97 Q1231.6 1568.97 1228.77 1567.44 Q1225.97 1565.88 1224.12 1562.7 M1244.05 1550.25 Q1244.05 1543.79 1241.37 1540.13 Q1238.73 1536.44 1234.08 1536.44 Q1229.44 1536.44 1226.76 1540.13 Q1224.12 1543.79 1224.12 1550.25 Q1224.12 1556.71 1226.76 1560.4 Q1229.44 1564.07 1234.08 1564.07 Q1238.73 1564.07 1241.37 1560.4 Q1244.05 1556.71 1244.05 1550.25 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M1273.65 1536.5 Q1268.94 1536.5 1266.2 1540.19 Q1263.46 1543.85 1263.46 1550.25 Q1263.46 1556.65 1266.17 1560.34 Q1268.91 1564 1273.65 1564 Q1278.33 1564 1281.06 1560.31 Q1283.8 1556.62 1283.8 1550.25 Q1283.8 1543.92 1281.06 1540.23 Q1278.33 1536.5 1273.65 1536.5 M1273.65 1531.54 Q1281.29 1531.54 1285.65 1536.5 Q1290.01 1541.47 1290.01 1550.25 Q1290.01 1559 1285.65 1564 Q1281.29 1568.97 1273.65 1568.97 Q1265.98 1568.97 1261.62 1564 Q1257.29 1559 1257.29 1550.25 Q1257.29 1541.47 1261.62 1536.5 Q1265.98 1531.54 1273.65 1531.54 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M1325.37 1533.76 L1325.37 1539.24 Q1322.89 1537.87 1320.37 1537.2 Q1317.89 1536.5 1315.34 1536.5 Q1309.65 1536.5 1306.49 1540.13 Q1303.34 1543.73 1303.34 1550.25 Q1303.34 1556.78 1306.49 1560.4 Q1309.65 1564 1315.34 1564 Q1317.89 1564 1320.37 1563.33 Q1322.89 1562.63 1325.37 1561.26 L1325.37 1566.68 Q1322.92 1567.82 1320.28 1568.39 Q1317.67 1568.97 1314.71 1568.97 Q1306.65 1568.97 1301.91 1563.91 Q1297.17 1558.85 1297.17 1550.25 Q1297.17 1541.53 1301.94 1536.53 Q1306.75 1531.54 1315.09 1531.54 Q1317.79 1531.54 1320.37 1532.11 Q1322.95 1532.65 1325.37 1533.76 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M1365.19 1546.53 L1365.19 1568.04 L1359.33 1568.04 L1359.33 1546.72 Q1359.33 1541.66 1357.36 1539.14 Q1355.38 1536.63 1351.44 1536.63 Q1346.69 1536.63 1343.96 1539.65 Q1341.22 1542.68 1341.22 1547.9 L1341.22 1568.04 L1335.33 1568.04 L1335.33 1518.52 L1341.22 1518.52 L1341.22 1537.93 Q1343.32 1534.72 1346.15 1533.13 Q1349.02 1531.54 1352.74 1531.54 Q1358.88 1531.54 1362.04 1535.36 Q1365.19 1539.14 1365.19 1546.53 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M1399.59 1533.45 L1399.59 1538.98 Q1397.11 1537.71 1394.44 1537.07 Q1391.76 1536.44 1388.9 1536.44 Q1384.54 1536.44 1382.34 1537.77 Q1380.18 1539.11 1380.18 1541.79 Q1380.18 1543.82 1381.74 1545 Q1383.3 1546.15 1388.01 1547.2 L1390.01 1547.64 Q1396.25 1548.98 1398.86 1551.43 Q1401.5 1553.85 1401.5 1558.21 Q1401.5 1563.17 1397.56 1566.07 Q1393.64 1568.97 1386.77 1568.97 Q1383.9 1568.97 1380.78 1568.39 Q1377.7 1567.85 1374.26 1566.74 L1374.26 1560.69 Q1377.5 1562.38 1380.66 1563.24 Q1383.81 1564.07 1386.89 1564.07 Q1391.03 1564.07 1393.26 1562.66 Q1395.49 1561.23 1395.49 1558.65 Q1395.49 1556.27 1393.86 1554.99 Q1392.27 1553.72 1386.83 1552.54 L1384.79 1552.07 Q1379.35 1550.92 1376.93 1548.56 Q1374.51 1546.18 1374.51 1542.04 Q1374.51 1537.01 1378.08 1534.27 Q1381.64 1531.54 1388.2 1531.54 Q1391.45 1531.54 1394.31 1532.01 Q1397.17 1532.49 1399.59 1533.45 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><polyline clip-path="url(#clip580)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="224.554,1423.18 224.554,47.2441 "></polyline><polyline clip-path="url(#clip580)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="224.554,1149.64 243.451,1149.64 "></polyline><polyline clip-path="url(#clip580)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="224.554,747.762 243.451,747.762 "></polyline><polyline clip-path="url(#clip580)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="224.554,345.881 243.451,345.881 "></polyline><path clip-path="url(#clip580)" d="M51.6634 1169.44 L59.3023 1169.44 L59.3023 1143.07 L50.9921 1144.74 L50.9921 1140.48 L59.256 1138.81 L63.9319 1138.81 L63.9319 1169.44 L71.5707 1169.44 L71.5707 1173.37 L51.6634 1173.37 L51.6634 1169.44 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M91.0151 1141.89 Q87.404 1141.89 85.5753 1145.45 Q83.7697 1149 83.7697 1156.12 Q83.7697 1163.23 85.5753 1166.8 Q87.404 1170.34 91.0151 1170.34 Q94.6493 1170.34 96.4548 1166.8 Q98.2835 1163.23 98.2835 1156.12 Q98.2835 1149 96.4548 1145.45 Q94.6493 1141.89 91.0151 1141.89 M91.0151 1138.19 Q96.8252 1138.19 99.8808 1142.79 Q102.959 1147.38 102.959 1156.12 Q102.959 1164.85 99.8808 1169.46 Q96.8252 1174.04 91.0151 1174.04 Q85.2049 1174.04 82.1262 1169.46 Q79.0707 1164.85 79.0707 1156.12 Q79.0707 1147.38 82.1262 1142.79 Q85.2049 1138.19 91.0151 1138.19 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M102.959 1132.29 L127.071 1132.29 L127.071 1135.48 L102.959 1135.48 L102.959 1132.29 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M143.396 1120.38 Q140.462 1120.38 138.976 1123.28 Q137.509 1126.16 137.509 1131.95 Q137.509 1137.72 138.976 1140.62 Q140.462 1143.5 143.396 1143.5 Q146.349 1143.5 147.816 1140.62 Q149.302 1137.72 149.302 1131.95 Q149.302 1126.16 147.816 1123.28 Q146.349 1120.38 143.396 1120.38 M143.396 1117.37 Q148.117 1117.37 150.6 1121.11 Q153.101 1124.84 153.101 1131.95 Q153.101 1139.04 150.6 1142.78 Q148.117 1146.51 143.396 1146.51 Q138.675 1146.51 136.174 1142.78 Q133.691 1139.04 133.691 1131.95 Q133.691 1124.84 136.174 1121.11 Q138.675 1117.37 143.396 1117.37 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M159.778 1141.18 L163.746 1141.18 L163.746 1145.96 L159.778 1145.96 L159.778 1141.18 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M175.294 1142.76 L188.554 1142.76 L188.554 1145.96 L170.724 1145.96 L170.724 1142.76 Q172.887 1140.52 176.611 1136.76 Q180.353 1132.98 181.313 1131.89 Q183.137 1129.84 183.852 1128.43 Q184.585 1127 184.585 1125.63 Q184.585 1123.39 183.005 1121.98 Q181.444 1120.57 178.924 1120.57 Q177.137 1120.57 175.144 1121.19 Q173.169 1121.81 170.912 1123.07 L170.912 1119.23 Q173.206 1118.31 175.2 1117.84 Q177.194 1117.37 178.849 1117.37 Q183.212 1117.37 185.808 1119.55 Q188.403 1121.74 188.403 1125.38 Q188.403 1127.11 187.745 1128.68 Q187.105 1130.22 185.394 1132.32 Q184.924 1132.87 182.403 1135.48 Q179.883 1138.08 175.294 1142.76 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M81.0976 767.554 L88.7364 767.554 L88.7364 741.189 L80.4263 742.855 L80.4263 738.596 L88.6901 736.929 L93.366 736.929 L93.366 767.554 L101.005 767.554 L101.005 771.489 L81.0976 771.489 L81.0976 767.554 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M120.449 740.008 Q116.838 740.008 115.009 743.573 Q113.204 747.115 113.204 754.244 Q113.204 761.351 115.009 764.915 Q116.838 768.457 120.449 768.457 Q124.083 768.457 125.889 764.915 Q127.718 761.351 127.718 754.244 Q127.718 747.115 125.889 743.573 Q124.083 740.008 120.449 740.008 M120.449 736.305 Q126.259 736.305 129.315 740.911 Q132.394 745.494 132.394 754.244 Q132.394 762.971 129.315 767.577 Q126.259 772.161 120.449 772.161 Q114.639 772.161 111.56 767.577 Q108.505 762.971 108.505 754.244 Q108.505 745.494 111.56 740.911 Q114.639 736.305 120.449 736.305 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M142.098 718.501 Q139.164 718.501 137.679 721.397 Q136.212 724.275 136.212 730.067 Q136.212 735.841 137.679 738.738 Q139.164 741.615 142.098 741.615 Q145.051 741.615 146.518 738.738 Q148.004 735.841 148.004 730.067 Q148.004 724.275 146.518 721.397 Q145.051 718.501 142.098 718.501 M142.098 715.491 Q146.819 715.491 149.302 719.234 Q151.803 722.958 151.803 730.067 Q151.803 737.158 149.302 740.901 Q146.819 744.625 142.098 744.625 Q137.378 744.625 134.876 740.901 Q132.394 737.158 132.394 730.067 Q132.394 722.958 134.876 719.234 Q137.378 715.491 142.098 715.491 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M158.48 739.302 L162.448 739.302 L162.448 744.079 L158.48 744.079 L158.48 739.302 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M178.849 718.501 Q175.915 718.501 174.429 721.397 Q172.962 724.275 172.962 730.067 Q172.962 735.841 174.429 738.738 Q175.915 741.615 178.849 741.615 Q181.802 741.615 183.269 738.738 Q184.754 735.841 184.754 730.067 Q184.754 724.275 183.269 721.397 Q181.802 718.501 178.849 718.501 M178.849 715.491 Q183.57 715.491 186.052 719.234 Q188.554 722.958 188.554 730.067 Q188.554 737.158 186.052 740.901 Q183.57 744.625 178.849 744.625 Q174.128 744.625 171.627 740.901 Q169.144 737.158 169.144 730.067 Q169.144 722.958 171.627 719.234 Q174.128 715.491 178.849 715.491 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M82.3953 365.674 L90.0342 365.674 L90.0342 339.308 L81.724 340.975 L81.724 336.715 L89.9879 335.049 L94.6638 335.049 L94.6638 365.674 L102.303 365.674 L102.303 369.609 L82.3953 369.609 L82.3953 365.674 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M121.747 338.127 Q118.136 338.127 116.307 341.692 Q114.502 345.234 114.502 352.363 Q114.502 359.47 116.307 363.035 Q118.136 366.576 121.747 366.576 Q125.381 366.576 127.187 363.035 Q129.015 359.47 129.015 352.363 Q129.015 345.234 127.187 341.692 Q125.381 338.127 121.747 338.127 M121.747 334.424 Q127.557 334.424 130.613 339.03 Q133.691 343.614 133.691 352.363 Q133.691 361.09 130.613 365.697 Q127.557 370.28 121.747 370.28 Q115.937 370.28 112.858 365.697 Q109.803 361.09 109.803 352.363 Q109.803 343.614 112.858 339.03 Q115.937 334.424 121.747 334.424 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M143.396 316.62 Q140.462 316.62 138.976 319.516 Q137.509 322.394 137.509 328.187 Q137.509 333.961 138.976 336.857 Q140.462 339.735 143.396 339.735 Q146.349 339.735 147.816 336.857 Q149.302 333.961 149.302 328.187 Q149.302 322.394 147.816 319.516 Q146.349 316.62 143.396 316.62 M143.396 313.611 Q148.117 313.611 150.6 317.353 Q153.101 321.077 153.101 328.187 Q153.101 335.277 150.6 339.02 Q148.117 342.744 143.396 342.744 Q138.675 342.744 136.174 339.02 Q133.691 335.277 133.691 328.187 Q133.691 321.077 136.174 317.353 Q138.675 313.611 143.396 313.611 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M159.778 337.421 L163.746 337.421 L163.746 342.198 L159.778 342.198 L159.778 337.421 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M175.294 339.001 L188.554 339.001 L188.554 342.198 L170.724 342.198 L170.724 339.001 Q172.887 336.763 176.611 333.001 Q180.353 329.221 181.313 328.13 Q183.137 326.08 183.852 324.67 Q184.585 323.24 184.585 321.867 Q184.585 319.629 183.005 318.218 Q181.444 316.808 178.924 316.808 Q177.137 316.808 175.144 317.429 Q173.169 318.049 170.912 319.309 L170.912 315.473 Q173.206 314.551 175.2 314.081 Q177.194 313.611 178.849 313.611 Q183.212 313.611 185.808 315.792 Q188.403 317.974 188.403 321.623 Q188.403 323.353 187.745 324.914 Q187.105 326.456 185.394 328.563 Q184.924 329.108 182.403 331.722 Q179.883 334.318 175.294 339.001 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><polyline clip-path="url(#clip582)" style="stroke:#009af9;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="284.786,86.1857 507.868,396.457 730.95,664.701 954.032,816.775 1177.11,908.779 1400.2,972.056 1623.28,1021.19 1846.36,1063.71 2069.44,1100.81 2292.52,1134.93 "></polyline><polyline clip-path="url(#clip582)" style="stroke:#e26f46;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="284.786,217.379 507.868,552.313 730.95,745.17 954.032,855.747 1177.11,927.193 1400.2,978.777 1623.28,1021.45 1846.36,1061.38 2069.44,1095.68 2292.52,1124.57 "></polyline><polyline clip-path="url(#clip582)" style="stroke:#3da44d;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="284.786,1384.24 507.868,1172.63 730.95,1128.56 954.032,1094.81 1177.11,1066.11 1400.2,1048.13 1623.28,1023.24 1846.36,997.792 2069.44,981.043 2292.52,970.639 "></polyline><path clip-path="url(#clip580)" d="M1846.96 300.469 L2281.82 300.469 L2281.82 93.1086 L1846.96 93.1086  Z" fill="#ffffff" fill-rule="evenodd" fill-opacity="1"></path><polyline clip-path="url(#clip580)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="1846.96,300.469 2281.82,300.469 2281.82,93.1086 1846.96,93.1086 1846.96,300.469 "></polyline><polyline clip-path="url(#clip580)" style="stroke:#009af9;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="1870.61,144.949 2012.49,144.949 "></polyline><path clip-path="url(#clip580)" d="M2043.54 128.942 L2043.54 136.303 L2052.31 136.303 L2052.31 139.613 L2043.54 139.613 L2043.54 153.687 Q2043.54 156.858 2044.4 157.761 Q2045.28 158.664 2047.94 158.664 L2052.31 158.664 L2052.31 162.229 L2047.94 162.229 Q2043.01 162.229 2041.13 160.4 Q2039.26 158.548 2039.26 153.687 L2039.26 139.613 L2036.13 139.613 L2036.13 136.303 L2039.26 136.303 L2039.26 128.942 L2043.54 128.942 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M2072.94 140.284 Q2072.22 139.868 2071.36 139.682 Q2070.53 139.474 2069.51 139.474 Q2065.9 139.474 2063.96 141.835 Q2062.04 144.173 2062.04 148.571 L2062.04 162.229 L2057.75 162.229 L2057.75 136.303 L2062.04 136.303 L2062.04 140.331 Q2063.38 137.969 2065.53 136.835 Q2067.68 135.678 2070.76 135.678 Q2071.2 135.678 2071.73 135.747 Q2072.27 135.794 2072.92 135.909 L2072.94 140.284 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M2089.19 149.196 Q2084.03 149.196 2082.04 150.377 Q2080.05 151.557 2080.05 154.405 Q2080.05 156.673 2081.53 158.016 Q2083.03 159.335 2085.6 159.335 Q2089.14 159.335 2091.27 156.835 Q2093.42 154.312 2093.42 150.145 L2093.42 149.196 L2089.19 149.196 M2097.68 147.437 L2097.68 162.229 L2093.42 162.229 L2093.42 158.293 Q2091.97 160.655 2089.79 161.789 Q2087.61 162.9 2084.47 162.9 Q2080.48 162.9 2078.12 160.678 Q2075.79 158.432 2075.79 154.682 Q2075.79 150.307 2078.7 148.085 Q2081.64 145.863 2087.45 145.863 L2093.42 145.863 L2093.42 145.446 Q2093.42 142.507 2091.48 140.909 Q2089.56 139.289 2086.06 139.289 Q2083.84 139.289 2081.73 139.821 Q2079.63 140.354 2077.68 141.419 L2077.68 137.483 Q2080.02 136.581 2082.22 136.141 Q2084.42 135.678 2086.5 135.678 Q2092.13 135.678 2094.91 138.594 Q2097.68 141.511 2097.68 147.437 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M2106.46 136.303 L2110.72 136.303 L2110.72 162.229 L2106.46 162.229 L2106.46 136.303 M2106.46 126.21 L2110.72 126.21 L2110.72 131.604 L2106.46 131.604 L2106.46 126.21 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M2141.18 146.581 L2141.18 162.229 L2136.92 162.229 L2136.92 146.719 Q2136.92 143.039 2135.48 141.21 Q2134.05 139.382 2131.18 139.382 Q2127.73 139.382 2125.74 141.581 Q2123.75 143.78 2123.75 147.576 L2123.75 162.229 L2119.47 162.229 L2119.47 136.303 L2123.75 136.303 L2123.75 140.331 Q2125.28 137.993 2127.34 136.835 Q2129.42 135.678 2132.13 135.678 Q2136.6 135.678 2138.89 138.456 Q2141.18 141.21 2141.18 146.581 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M2169.37 170.099 L2169.37 173.409 L2144.74 173.409 L2144.74 170.099 L2169.37 170.099 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M2173.38 126.21 L2177.64 126.21 L2177.64 162.229 L2173.38 162.229 L2173.38 126.21 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M2196.6 139.289 Q2193.17 139.289 2191.18 141.974 Q2189.19 144.636 2189.19 149.289 Q2189.19 153.942 2191.16 156.627 Q2193.15 159.289 2196.6 159.289 Q2200 159.289 2201.99 156.604 Q2203.98 153.918 2203.98 149.289 Q2203.98 144.682 2201.99 141.997 Q2200 139.289 2196.6 139.289 M2196.6 135.678 Q2202.15 135.678 2205.32 139.289 Q2208.49 142.9 2208.49 149.289 Q2208.49 155.655 2205.32 159.289 Q2202.15 162.9 2196.6 162.9 Q2191.02 162.9 2187.85 159.289 Q2184.7 155.655 2184.7 149.289 Q2184.7 142.9 2187.85 139.289 Q2191.02 135.678 2196.6 135.678 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M2232.08 137.067 L2232.08 141.094 Q2230.28 140.169 2228.33 139.706 Q2226.39 139.243 2224.3 139.243 Q2221.13 139.243 2219.54 140.215 Q2217.96 141.187 2217.96 143.131 Q2217.96 144.613 2219.1 145.469 Q2220.23 146.303 2223.66 147.067 L2225.11 147.391 Q2229.65 148.363 2231.55 150.145 Q2233.47 151.905 2233.47 155.076 Q2233.47 158.687 2230.6 160.793 Q2227.75 162.9 2222.75 162.9 Q2220.67 162.9 2218.4 162.483 Q2216.16 162.09 2213.66 161.28 L2213.66 156.881 Q2216.02 158.108 2218.31 158.733 Q2220.6 159.335 2222.85 159.335 Q2225.85 159.335 2227.47 158.317 Q2229.1 157.275 2229.1 155.4 Q2229.1 153.664 2227.91 152.738 Q2226.76 151.812 2222.8 150.956 L2221.32 150.608 Q2217.36 149.775 2215.6 148.062 Q2213.84 146.326 2213.84 143.317 Q2213.84 139.659 2216.43 137.669 Q2219.03 135.678 2223.79 135.678 Q2226.16 135.678 2228.24 136.025 Q2230.32 136.372 2232.08 137.067 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M2256.78 137.067 L2256.78 141.094 Q2254.97 140.169 2253.03 139.706 Q2251.09 139.243 2249 139.243 Q2245.83 139.243 2244.23 140.215 Q2242.66 141.187 2242.66 143.131 Q2242.66 144.613 2243.79 145.469 Q2244.93 146.303 2248.35 147.067 L2249.81 147.391 Q2254.35 148.363 2256.25 150.145 Q2258.17 151.905 2258.17 155.076 Q2258.17 158.687 2255.3 160.793 Q2252.45 162.9 2247.45 162.9 Q2245.37 162.9 2243.1 162.483 Q2240.85 162.09 2238.35 161.28 L2238.35 156.881 Q2240.72 158.108 2243.01 158.733 Q2245.3 159.335 2247.54 159.335 Q2250.55 159.335 2252.17 158.317 Q2253.79 157.275 2253.79 155.4 Q2253.79 153.664 2252.61 152.738 Q2251.46 151.812 2247.5 150.956 L2246.02 150.608 Q2242.06 149.775 2240.3 148.062 Q2238.54 146.326 2238.54 143.317 Q2238.54 139.659 2241.13 137.669 Q2243.72 135.678 2248.49 135.678 Q2250.85 135.678 2252.94 136.025 Q2255.02 136.372 2256.78 137.067 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><polyline clip-path="url(#clip580)" style="stroke:#e26f46;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="1870.61,196.789 2012.49,196.789 "></polyline><path clip-path="url(#clip580)" d="M2036.13 188.143 L2040.65 188.143 L2048.75 209.902 L2056.85 188.143 L2061.36 188.143 L2051.64 214.069 L2045.86 214.069 L2036.13 188.143 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M2079.03 201.036 Q2073.86 201.036 2071.87 202.217 Q2069.88 203.397 2069.88 206.245 Q2069.88 208.513 2071.36 209.856 Q2072.87 211.175 2075.44 211.175 Q2078.98 211.175 2081.11 208.675 Q2083.26 206.152 2083.26 201.985 L2083.26 201.036 L2079.03 201.036 M2087.52 199.277 L2087.52 214.069 L2083.26 214.069 L2083.26 210.133 Q2081.8 212.495 2079.63 213.629 Q2077.45 214.74 2074.3 214.74 Q2070.32 214.74 2067.96 212.518 Q2065.62 210.272 2065.62 206.522 Q2065.62 202.147 2068.54 199.925 Q2071.48 197.703 2077.29 197.703 L2083.26 197.703 L2083.26 197.286 Q2083.26 194.347 2081.32 192.749 Q2079.4 191.129 2075.9 191.129 Q2073.68 191.129 2071.57 191.661 Q2069.47 192.194 2067.52 193.259 L2067.52 189.323 Q2069.86 188.421 2072.06 187.981 Q2074.26 187.518 2076.34 187.518 Q2081.97 187.518 2084.74 190.434 Q2087.52 193.351 2087.52 199.277 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M2096.3 178.05 L2100.55 178.05 L2100.55 214.069 L2096.3 214.069 L2096.3 178.05 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M2129.17 221.939 L2129.17 225.249 L2104.54 225.249 L2104.54 221.939 L2129.17 221.939 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M2133.17 178.05 L2137.43 178.05 L2137.43 214.069 L2133.17 214.069 L2133.17 178.05 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M2156.39 191.129 Q2152.96 191.129 2150.97 193.814 Q2148.98 196.476 2148.98 201.129 Q2148.98 205.782 2150.95 208.467 Q2152.94 211.129 2156.39 211.129 Q2159.79 211.129 2161.78 208.444 Q2163.77 205.758 2163.77 201.129 Q2163.77 196.522 2161.78 193.837 Q2159.79 191.129 2156.39 191.129 M2156.39 187.518 Q2161.94 187.518 2165.11 191.129 Q2168.29 194.74 2168.29 201.129 Q2168.29 207.495 2165.11 211.129 Q2161.94 214.74 2156.39 214.74 Q2150.81 214.74 2147.64 211.129 Q2144.49 207.495 2144.49 201.129 Q2144.49 194.74 2147.64 191.129 Q2150.81 187.518 2156.39 187.518 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M2191.87 188.907 L2191.87 192.934 Q2190.07 192.009 2188.12 191.546 Q2186.18 191.083 2184.1 191.083 Q2180.92 191.083 2179.33 192.055 Q2177.75 193.027 2177.75 194.971 Q2177.75 196.453 2178.89 197.309 Q2180.02 198.143 2183.45 198.907 L2184.91 199.231 Q2189.44 200.203 2191.34 201.985 Q2193.26 203.745 2193.26 206.916 Q2193.26 210.527 2190.39 212.633 Q2187.54 214.74 2182.54 214.74 Q2180.46 214.74 2178.19 214.323 Q2175.95 213.93 2173.45 213.12 L2173.45 208.721 Q2175.81 209.948 2178.1 210.573 Q2180.39 211.175 2182.64 211.175 Q2185.65 211.175 2187.27 210.157 Q2188.89 209.115 2188.89 207.24 Q2188.89 205.504 2187.71 204.578 Q2186.55 203.652 2182.59 202.796 L2181.11 202.448 Q2177.15 201.615 2175.39 199.902 Q2173.63 198.166 2173.63 195.157 Q2173.63 191.499 2176.23 189.509 Q2178.82 187.518 2183.59 187.518 Q2185.95 187.518 2188.03 187.865 Q2190.11 188.212 2191.87 188.907 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M2216.57 188.907 L2216.57 192.934 Q2214.77 192.009 2212.82 191.546 Q2210.88 191.083 2208.79 191.083 Q2205.62 191.083 2204.03 192.055 Q2202.45 193.027 2202.45 194.971 Q2202.45 196.453 2203.59 197.309 Q2204.72 198.143 2208.15 198.907 L2209.6 199.231 Q2214.14 200.203 2216.04 201.985 Q2217.96 203.745 2217.96 206.916 Q2217.96 210.527 2215.09 212.633 Q2212.24 214.74 2207.24 214.74 Q2205.16 214.74 2202.89 214.323 Q2200.65 213.93 2198.15 213.12 L2198.15 208.721 Q2200.51 209.948 2202.8 210.573 Q2205.09 211.175 2207.34 211.175 Q2210.35 211.175 2211.97 210.157 Q2213.59 209.115 2213.59 207.24 Q2213.59 205.504 2212.41 204.578 Q2211.25 203.652 2207.29 202.796 L2205.81 202.448 Q2201.85 201.615 2200.09 199.902 Q2198.33 198.166 2198.33 195.157 Q2198.33 191.499 2200.92 189.509 Q2203.52 187.518 2208.29 187.518 Q2210.65 187.518 2212.73 187.865 Q2214.81 188.212 2216.57 188.907 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><polyline clip-path="url(#clip580)" style="stroke:#3da44d;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="1870.61,248.629 2012.49,248.629 "></polyline><path clip-path="url(#clip580)" d="M2036.13 239.983 L2040.65 239.983 L2048.75 261.742 L2056.85 239.983 L2061.36 239.983 L2051.64 265.909 L2045.86 265.909 L2036.13 239.983 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M2079.03 252.876 Q2073.86 252.876 2071.87 254.057 Q2069.88 255.237 2069.88 258.085 Q2069.88 260.353 2071.36 261.696 Q2072.87 263.015 2075.44 263.015 Q2078.98 263.015 2081.11 260.515 Q2083.26 257.992 2083.26 253.825 L2083.26 252.876 L2079.03 252.876 M2087.52 251.117 L2087.52 265.909 L2083.26 265.909 L2083.26 261.973 Q2081.8 264.335 2079.63 265.469 Q2077.45 266.58 2074.3 266.58 Q2070.32 266.58 2067.96 264.358 Q2065.62 262.112 2065.62 258.362 Q2065.62 253.987 2068.54 251.765 Q2071.48 249.543 2077.29 249.543 L2083.26 249.543 L2083.26 249.126 Q2083.26 246.187 2081.32 244.589 Q2079.4 242.969 2075.9 242.969 Q2073.68 242.969 2071.57 243.501 Q2069.47 244.034 2067.52 245.099 L2067.52 241.163 Q2069.86 240.261 2072.06 239.821 Q2074.26 239.358 2076.34 239.358 Q2081.97 239.358 2084.74 242.274 Q2087.52 245.191 2087.52 251.117 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M2096.3 229.89 L2100.55 229.89 L2100.55 265.909 L2096.3 265.909 L2096.3 229.89 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M2129.17 273.779 L2129.17 277.089 L2104.54 277.089 L2104.54 273.779 L2129.17 273.779 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M2144.95 252.876 Q2139.79 252.876 2137.8 254.057 Q2135.81 255.237 2135.81 258.085 Q2135.81 260.353 2137.29 261.696 Q2138.79 263.015 2141.36 263.015 Q2144.91 263.015 2147.04 260.515 Q2149.19 257.992 2149.19 253.825 L2149.19 252.876 L2144.95 252.876 M2153.45 251.117 L2153.45 265.909 L2149.19 265.909 L2149.19 261.973 Q2147.73 264.335 2145.55 265.469 Q2143.38 266.58 2140.23 266.58 Q2136.25 266.58 2133.89 264.358 Q2131.55 262.112 2131.55 258.362 Q2131.55 253.987 2134.47 251.765 Q2137.41 249.543 2143.22 249.543 L2149.19 249.543 L2149.19 249.126 Q2149.19 246.187 2147.24 244.589 Q2145.32 242.969 2141.83 242.969 Q2139.6 242.969 2137.5 243.501 Q2135.39 244.034 2133.45 245.099 L2133.45 241.163 Q2135.79 240.261 2137.98 239.821 Q2140.18 239.358 2142.27 239.358 Q2147.89 239.358 2150.67 242.274 Q2153.45 245.191 2153.45 251.117 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M2180.88 240.978 L2180.88 244.96 Q2179.07 243.964 2177.24 243.478 Q2175.44 242.969 2173.59 242.969 Q2169.44 242.969 2167.15 245.608 Q2164.86 248.224 2164.86 252.969 Q2164.86 257.714 2167.15 260.353 Q2169.44 262.969 2173.59 262.969 Q2175.44 262.969 2177.24 262.483 Q2179.07 261.973 2180.88 260.978 L2180.88 264.913 Q2179.1 265.747 2177.17 266.163 Q2175.28 266.58 2173.12 266.58 Q2167.27 266.58 2163.82 262.899 Q2160.37 259.219 2160.37 252.969 Q2160.37 246.626 2163.84 242.992 Q2167.34 239.358 2173.4 239.358 Q2175.37 239.358 2177.24 239.775 Q2179.12 240.168 2180.88 240.978 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip580)" d="M2206.94 240.978 L2206.94 244.96 Q2205.14 243.964 2203.31 243.478 Q2201.5 242.969 2199.65 242.969 Q2195.51 242.969 2193.22 245.608 Q2190.92 248.224 2190.92 252.969 Q2190.92 257.714 2193.22 260.353 Q2195.51 262.969 2199.65 262.969 Q2201.5 262.969 2203.31 262.483 Q2205.14 261.973 2206.94 260.978 L2206.94 264.913 Q2205.16 265.747 2203.24 266.163 Q2201.34 266.58 2199.19 266.58 Q2193.33 266.58 2189.88 262.899 Q2186.43 259.219 2186.43 252.969 Q2186.43 246.626 2189.91 242.992 Q2193.4 239.358 2199.47 239.358 Q2201.43 239.358 2203.31 239.775 Q2205.18 240.168 2206.94 240.978 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path></svg><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>(MLP([0.0025907253012318 0.004434211742339771 â€¦ 0.005948848386828566 -0.004396632680610081; -0.01389325653004344 -0.0011132944731336177 â€¦ 0.001565572069784555 -0.011690286663672693; â€¦ ; -0.0030419971399973694 -0.009797153218174827 â€¦ 0.017208869386144 -0.0021644320780200683; 0.005653869642510044 0.00516614739146323 â€¦ -0.00930094933047343 0.00125522016678587], [-0.02261086552697285 0.12511211528987537 â€¦ 0.00770935608775288 -0.008336313757029881; 0.12241688893245524 0.06049709111587903 â€¦ 0.006157700732419801 0.004634774334394043; â€¦ ; -0.0032371654640280965 0.036300996101492164 â€¦ -0.004576708890541834 0.0032142054671962664; -0.03554650737048207 -0.12095986363824825 â€¦ 0.004313900447319184 0.002968760071406733], [0.003992542412849325; 0.00498983816799759; â€¦ ; -0.0007639085639713631; -0.0011848515594961512;;], [0.00885574653302873; 0.018424048539937087; â€¦ ; -0.16186837388373113; -0.2571295877214314;;], (num_inputs = 784, num_hiddens = 256, num_outputs = 10, lr = 0.01)), (val_loss = [0.6075688169558727, 0.5900464218227306, 0.7035459637079877, 0.6316132833104677, 0.7028046369944622, 0.6129771166217814, 0.589745203955325, 0.6413945676206254, 0.5793911786651581, 0.6014784633828493  â€¦  0.664900760190743, 0.7017198448903048, 0.6059283986378813, 0.593572766971733, 0.6947916744852096, 0.6572553180778933, 0.6345673023591967, 0.6922486000942907, 0.6389265185331557, 0.39833012812119917], val_acc = [0.76953125, 0.8125, 0.76171875, 0.78515625, 0.7421875, 0.78515625, 0.81640625, 0.76171875, 0.80859375, 0.78125  â€¦  0.765625, 0.75390625, 0.7890625, 0.80859375, 0.7421875, 0.76171875, 0.75, 0.7890625, 0.796875, 0.875]))</span></span></code></pre></div><h2 id="Concise-Implementation" tabindex="-1">Concise Implementation <a class="header-anchor" href="#Concise-Implementation" aria-label="Permalink to &quot;Concise Implementation {#Concise-Implementation}&quot;">â€‹</a></h2><p>As you might expect, by relying on the high-level APIs, we can implement MLPs even more concisely.</p><h3 id="Model-2" tabindex="-1">Model <a class="header-anchor" href="#Model-2" aria-label="Permalink to &quot;Model {#Model-2}&quot;">â€‹</a></h3><p>Compared with our concise implementation of softmax regression implementation (:numref:<code>sec_softmax_concise</code>), the only difference is that we add <em>two</em> fully connected layers where we previously added only <em>one</em>. The first is [<strong>the hidden layer</strong>], the second is the output layer.</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">struct</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> MLPConcise{N, A} </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> AbstractClassifier</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    net</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">N</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    args</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">A</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">end</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">function</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> MLPConcise</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(num_inputs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Int64</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, num_outputs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Int64</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, num_hiddens</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Int64</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, lr, sigma </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.01</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    args </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (num_inputs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> num_inputs, num_hiddens </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> num_hiddens, num_outputs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> num_outputs, lr </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> lr)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    net </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> Chain</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Dense</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(num_inputs, num_hiddens, relu), </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Dense</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(num_hiddens, num_outputs), Flux</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">softmax)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    MLPConcise</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(net, args)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">end</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">d2lai</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(m</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">MLPConcise</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, x) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> m</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">net</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">d2lai</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">loss</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(m</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">MLPConcise</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, y_pred, y) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Flux</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">crossentropy</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(y_pred, Flux</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">onehotbatch</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(y, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">9</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span></code></pre></div><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> MLPConcise</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">28</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">28</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.01</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">opt </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> Descent</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.01</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">data </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> d2lai</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">FashionMNISTData</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(; batchsize </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, flatten</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">true</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">trainer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> Trainer</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(model, data, opt; max_epochs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">d2lai</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">fit</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(trainer)</span></span></code></pre></div><div style="max-height:300px;overflow-y:auto;background:#111;color:#eee;padding:1em;border-radius:5px;"><pre>    [ Info: Train Loss: 1.032749, Val Loss: 0.7838099, Val Acc: 0.75
    [ Info: Train Loss: 0.6469836, Val Loss: 0.54223603, Val Acc: 0.8125
    [ Info: Train Loss: 0.7175854, Val Loss: 0.44240537, Val Acc: 0.8125
    [ Info: Train Loss: 0.5304204, Val Loss: 0.39751008, Val Acc: 0.8125
    [ Info: Train Loss: 0.5611671, Val Loss: 0.37504986, Val Acc: 0.75
    [ Info: Train Loss: 0.51782006, Val Loss: 0.35605115, Val Acc: 0.8125
    [ Info: Train Loss: 0.5623277, Val Loss: 0.33210504, Val Acc: 0.8125
    [ Info: Train Loss: 0.5539348, Val Loss: 0.32132548, Val Acc: 0.8125
    [ Info: Train Loss: 0.5783891, Val Loss: 0.32704777, Val Acc: 0.875
    [ Info: Train Loss: 0.46418503, Val Loss: 0.31624204, Val Acc: 0.875</pre></div><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="600" height="400" viewBox="0 0 2400 1600"><defs><clipPath id="clip970"><rect x="0" y="0" width="2400" height="1600"></rect></clipPath></defs><path clip-path="url(#clip970)" d="M0 1600 L2400 1600 L2400 0 L0 0  Z" fill="#ffffff" fill-rule="evenodd" fill-opacity="1"></path><defs><clipPath id="clip971"><rect x="480" y="0" width="1681" height="1600"></rect></clipPath></defs><path clip-path="url(#clip970)" d="M224.554 1423.18 L2352.76 1423.18 L2352.76 47.2441 L224.554 47.2441  Z" fill="#ffffff" fill-rule="evenodd" fill-opacity="1"></path><defs><clipPath id="clip972"><rect x="224" y="47" width="2129" height="1377"></rect></clipPath></defs><polyline clip-path="url(#clip972)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:2;stroke-opacity:0.1;fill:none;" points="507.868,1423.18 507.868,47.2441 "></polyline><polyline clip-path="url(#clip972)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:2;stroke-opacity:0.1;fill:none;" points="954.032,1423.18 954.032,47.2441 "></polyline><polyline clip-path="url(#clip972)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:2;stroke-opacity:0.1;fill:none;" points="1400.2,1423.18 1400.2,47.2441 "></polyline><polyline clip-path="url(#clip972)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:2;stroke-opacity:0.1;fill:none;" points="1846.36,1423.18 1846.36,47.2441 "></polyline><polyline clip-path="url(#clip972)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:2;stroke-opacity:0.1;fill:none;" points="2292.52,1423.18 2292.52,47.2441 "></polyline><polyline clip-path="url(#clip972)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:2;stroke-opacity:0.1;fill:none;" points="224.554,1072.98 2352.76,1072.98 "></polyline><polyline clip-path="url(#clip972)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:2;stroke-opacity:0.1;fill:none;" points="224.554,416.933 2352.76,416.933 "></polyline><polyline clip-path="url(#clip970)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="224.554,1423.18 2352.76,1423.18 "></polyline><polyline clip-path="url(#clip970)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="507.868,1423.18 507.868,1404.28 "></polyline><polyline clip-path="url(#clip970)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="954.032,1423.18 954.032,1404.28 "></polyline><polyline clip-path="url(#clip970)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="1400.2,1423.18 1400.2,1404.28 "></polyline><polyline clip-path="url(#clip970)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="1846.36,1423.18 1846.36,1404.28 "></polyline><polyline clip-path="url(#clip970)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="2292.52,1423.18 2292.52,1404.28 "></polyline><path clip-path="url(#clip970)" d="M502.521 1481.64 L518.84 1481.64 L518.84 1485.58 L496.896 1485.58 L496.896 1481.64 Q499.558 1478.89 504.141 1474.26 Q508.747 1469.61 509.928 1468.27 Q512.173 1465.74 513.053 1464.01 Q513.956 1462.25 513.956 1460.56 Q513.956 1457.8 512.011 1456.07 Q510.09 1454.33 506.988 1454.33 Q504.789 1454.33 502.335 1455.09 Q499.905 1455.86 497.127 1457.41 L497.127 1452.69 Q499.951 1451.55 502.405 1450.97 Q504.858 1450.39 506.896 1450.39 Q512.266 1450.39 515.46 1453.08 Q518.655 1455.77 518.655 1460.26 Q518.655 1462.39 517.845 1464.31 Q517.058 1466.2 514.951 1468.8 Q514.372 1469.47 511.271 1472.69 Q508.169 1475.88 502.521 1481.64 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M957.041 1455.09 L945.235 1473.54 L957.041 1473.54 L957.041 1455.09 M955.814 1451.02 L961.694 1451.02 L961.694 1473.54 L966.624 1473.54 L966.624 1477.43 L961.694 1477.43 L961.694 1485.58 L957.041 1485.58 L957.041 1477.43 L941.439 1477.43 L941.439 1472.92 L955.814 1451.02 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M1400.6 1466.44 Q1397.45 1466.44 1395.6 1468.59 Q1393.77 1470.74 1393.77 1474.49 Q1393.77 1478.22 1395.6 1480.39 Q1397.45 1482.55 1400.6 1482.55 Q1403.75 1482.55 1405.58 1480.39 Q1407.43 1478.22 1407.43 1474.49 Q1407.43 1470.74 1405.58 1468.59 Q1403.75 1466.44 1400.6 1466.44 M1409.88 1451.78 L1409.88 1456.04 Q1408.12 1455.21 1406.32 1454.77 Q1404.54 1454.33 1402.78 1454.33 Q1398.15 1454.33 1395.69 1457.45 Q1393.26 1460.58 1392.92 1466.9 Q1394.28 1464.89 1396.34 1463.82 Q1398.4 1462.73 1400.88 1462.73 Q1406.09 1462.73 1409.1 1465.9 Q1412.13 1469.05 1412.13 1474.49 Q1412.13 1479.82 1408.98 1483.03 Q1405.83 1486.25 1400.6 1486.25 Q1394.61 1486.25 1391.43 1481.67 Q1388.26 1477.06 1388.26 1468.33 Q1388.26 1460.14 1392.15 1455.28 Q1396.04 1450.39 1402.59 1450.39 Q1404.35 1450.39 1406.13 1450.74 Q1407.94 1451.09 1409.88 1451.78 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M1846.36 1469.17 Q1843.03 1469.17 1841.11 1470.95 Q1839.21 1472.73 1839.21 1475.86 Q1839.21 1478.98 1841.11 1480.77 Q1843.03 1482.55 1846.36 1482.55 Q1849.69 1482.55 1851.61 1480.77 Q1853.54 1478.96 1853.54 1475.86 Q1853.54 1472.73 1851.61 1470.95 Q1849.72 1469.17 1846.36 1469.17 M1841.68 1467.18 Q1838.67 1466.44 1836.98 1464.38 Q1835.32 1462.32 1835.32 1459.35 Q1835.32 1455.21 1838.26 1452.8 Q1841.22 1450.39 1846.36 1450.39 Q1851.52 1450.39 1854.46 1452.8 Q1857.4 1455.21 1857.4 1459.35 Q1857.4 1462.32 1855.71 1464.38 Q1854.04 1466.44 1851.06 1467.18 Q1854.44 1467.96 1856.31 1470.26 Q1858.21 1472.55 1858.21 1475.86 Q1858.21 1480.88 1855.13 1483.57 Q1852.08 1486.25 1846.36 1486.25 Q1840.64 1486.25 1837.56 1483.57 Q1834.51 1480.88 1834.51 1475.86 Q1834.51 1472.55 1836.41 1470.26 Q1838.3 1467.96 1841.68 1467.18 M1839.97 1459.79 Q1839.97 1462.48 1841.64 1463.98 Q1843.33 1465.49 1846.36 1465.49 Q1849.37 1465.49 1851.06 1463.98 Q1852.77 1462.48 1852.77 1459.79 Q1852.77 1457.11 1851.06 1455.6 Q1849.37 1454.1 1846.36 1454.1 Q1843.33 1454.1 1841.64 1455.6 Q1839.97 1457.11 1839.97 1459.79 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M2267.21 1481.64 L2274.85 1481.64 L2274.85 1455.28 L2266.54 1456.95 L2266.54 1452.69 L2274.8 1451.02 L2279.48 1451.02 L2279.48 1481.64 L2287.12 1481.64 L2287.12 1485.58 L2267.21 1485.58 L2267.21 1481.64 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M2306.56 1454.1 Q2302.95 1454.1 2301.12 1457.66 Q2299.32 1461.2 2299.32 1468.33 Q2299.32 1475.44 2301.12 1479.01 Q2302.95 1482.55 2306.56 1482.55 Q2310.2 1482.55 2312 1479.01 Q2313.83 1475.44 2313.83 1468.33 Q2313.83 1461.2 2312 1457.66 Q2310.2 1454.1 2306.56 1454.1 M2306.56 1450.39 Q2312.37 1450.39 2315.43 1455 Q2318.51 1459.58 2318.51 1468.33 Q2318.51 1477.06 2315.43 1481.67 Q2312.37 1486.25 2306.56 1486.25 Q2300.75 1486.25 2297.67 1481.67 Q2294.62 1477.06 2294.62 1468.33 Q2294.62 1459.58 2297.67 1455 Q2300.75 1450.39 2306.56 1450.39 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M1208.84 1548.76 L1208.84 1551.62 L1181.92 1551.62 Q1182.3 1557.67 1185.55 1560.85 Q1188.82 1564 1194.65 1564 Q1198.02 1564 1201.17 1563.17 Q1204.36 1562.35 1207.48 1560.69 L1207.48 1566.23 Q1204.33 1567.57 1201.01 1568.27 Q1197.7 1568.97 1194.3 1568.97 Q1185.77 1568.97 1180.77 1564 Q1175.81 1559.04 1175.81 1550.57 Q1175.81 1541.82 1180.52 1536.69 Q1185.26 1531.54 1193.28 1531.54 Q1200.47 1531.54 1204.64 1536.18 Q1208.84 1540.8 1208.84 1548.76 M1202.99 1547.04 Q1202.92 1542.23 1200.28 1539.37 Q1197.67 1536.5 1193.34 1536.5 Q1188.44 1536.5 1185.48 1539.27 Q1182.55 1542.04 1182.11 1547.07 L1202.99 1547.04 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M1224.12 1562.7 L1224.12 1581.6 L1218.23 1581.6 L1218.23 1532.4 L1224.12 1532.4 L1224.12 1537.81 Q1225.97 1534.62 1228.77 1533.1 Q1231.6 1531.54 1235.52 1531.54 Q1242.01 1531.54 1246.05 1536.69 Q1250.13 1541.85 1250.13 1550.25 Q1250.13 1558.65 1246.05 1563.81 Q1242.01 1568.97 1235.52 1568.97 Q1231.6 1568.97 1228.77 1567.44 Q1225.97 1565.88 1224.12 1562.7 M1244.05 1550.25 Q1244.05 1543.79 1241.37 1540.13 Q1238.73 1536.44 1234.08 1536.44 Q1229.44 1536.44 1226.76 1540.13 Q1224.12 1543.79 1224.12 1550.25 Q1224.12 1556.71 1226.76 1560.4 Q1229.44 1564.07 1234.08 1564.07 Q1238.73 1564.07 1241.37 1560.4 Q1244.05 1556.71 1244.05 1550.25 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M1273.65 1536.5 Q1268.94 1536.5 1266.2 1540.19 Q1263.46 1543.85 1263.46 1550.25 Q1263.46 1556.65 1266.17 1560.34 Q1268.91 1564 1273.65 1564 Q1278.33 1564 1281.06 1560.31 Q1283.8 1556.62 1283.8 1550.25 Q1283.8 1543.92 1281.06 1540.23 Q1278.33 1536.5 1273.65 1536.5 M1273.65 1531.54 Q1281.29 1531.54 1285.65 1536.5 Q1290.01 1541.47 1290.01 1550.25 Q1290.01 1559 1285.65 1564 Q1281.29 1568.97 1273.65 1568.97 Q1265.98 1568.97 1261.62 1564 Q1257.29 1559 1257.29 1550.25 Q1257.29 1541.47 1261.62 1536.5 Q1265.98 1531.54 1273.65 1531.54 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M1325.37 1533.76 L1325.37 1539.24 Q1322.89 1537.87 1320.37 1537.2 Q1317.89 1536.5 1315.34 1536.5 Q1309.65 1536.5 1306.49 1540.13 Q1303.34 1543.73 1303.34 1550.25 Q1303.34 1556.78 1306.49 1560.4 Q1309.65 1564 1315.34 1564 Q1317.89 1564 1320.37 1563.33 Q1322.89 1562.63 1325.37 1561.26 L1325.37 1566.68 Q1322.92 1567.82 1320.28 1568.39 Q1317.67 1568.97 1314.71 1568.97 Q1306.65 1568.97 1301.91 1563.91 Q1297.17 1558.85 1297.17 1550.25 Q1297.17 1541.53 1301.94 1536.53 Q1306.75 1531.54 1315.09 1531.54 Q1317.79 1531.54 1320.37 1532.11 Q1322.95 1532.65 1325.37 1533.76 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M1365.19 1546.53 L1365.19 1568.04 L1359.33 1568.04 L1359.33 1546.72 Q1359.33 1541.66 1357.36 1539.14 Q1355.38 1536.63 1351.44 1536.63 Q1346.69 1536.63 1343.96 1539.65 Q1341.22 1542.68 1341.22 1547.9 L1341.22 1568.04 L1335.33 1568.04 L1335.33 1518.52 L1341.22 1518.52 L1341.22 1537.93 Q1343.32 1534.72 1346.15 1533.13 Q1349.02 1531.54 1352.74 1531.54 Q1358.88 1531.54 1362.04 1535.36 Q1365.19 1539.14 1365.19 1546.53 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M1399.59 1533.45 L1399.59 1538.98 Q1397.11 1537.71 1394.44 1537.07 Q1391.76 1536.44 1388.9 1536.44 Q1384.54 1536.44 1382.34 1537.77 Q1380.18 1539.11 1380.18 1541.79 Q1380.18 1543.82 1381.74 1545 Q1383.3 1546.15 1388.01 1547.2 L1390.01 1547.64 Q1396.25 1548.98 1398.86 1551.43 Q1401.5 1553.85 1401.5 1558.21 Q1401.5 1563.17 1397.56 1566.07 Q1393.64 1568.97 1386.77 1568.97 Q1383.9 1568.97 1380.78 1568.39 Q1377.7 1567.85 1374.26 1566.74 L1374.26 1560.69 Q1377.5 1562.38 1380.66 1563.24 Q1383.81 1564.07 1386.89 1564.07 Q1391.03 1564.07 1393.26 1562.66 Q1395.49 1561.23 1395.49 1558.65 Q1395.49 1556.27 1393.86 1554.99 Q1392.27 1553.72 1386.83 1552.54 L1384.79 1552.07 Q1379.35 1550.92 1376.93 1548.56 Q1374.51 1546.18 1374.51 1542.04 Q1374.51 1537.01 1378.08 1534.27 Q1381.64 1531.54 1388.2 1531.54 Q1391.45 1531.54 1394.31 1532.01 Q1397.17 1532.49 1399.59 1533.45 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><polyline clip-path="url(#clip970)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="224.554,1423.18 224.554,47.2441 "></polyline><polyline clip-path="url(#clip970)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="224.554,1072.98 243.451,1072.98 "></polyline><polyline clip-path="url(#clip970)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="224.554,416.933 243.451,416.933 "></polyline><path clip-path="url(#clip970)" d="M51.6634 1092.77 L59.3023 1092.77 L59.3023 1066.41 L50.9921 1068.07 L50.9921 1063.81 L59.256 1062.15 L63.9319 1062.15 L63.9319 1092.77 L71.5707 1092.77 L71.5707 1096.71 L51.6634 1096.71 L51.6634 1092.77 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M91.0151 1065.23 Q87.404 1065.23 85.5753 1068.79 Q83.7697 1072.33 83.7697 1079.46 Q83.7697 1086.57 85.5753 1090.13 Q87.404 1093.68 91.0151 1093.68 Q94.6493 1093.68 96.4548 1090.13 Q98.2835 1086.57 98.2835 1079.46 Q98.2835 1072.33 96.4548 1068.79 Q94.6493 1065.23 91.0151 1065.23 M91.0151 1061.52 Q96.8252 1061.52 99.8808 1066.13 Q102.959 1070.71 102.959 1079.46 Q102.959 1088.19 99.8808 1092.8 Q96.8252 1097.38 91.0151 1097.38 Q85.2049 1097.38 82.1262 1092.8 Q79.0707 1088.19 79.0707 1079.46 Q79.0707 1070.71 82.1262 1066.13 Q85.2049 1061.52 91.0151 1061.52 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M102.959 1055.62 L127.071 1055.62 L127.071 1058.82 L102.959 1058.82 L102.959 1055.62 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M143.396 1043.72 Q140.462 1043.72 138.976 1046.62 Q137.509 1049.49 137.509 1055.29 Q137.509 1061.06 138.976 1063.96 Q140.462 1066.83 143.396 1066.83 Q146.349 1066.83 147.816 1063.96 Q149.302 1061.06 149.302 1055.29 Q149.302 1049.49 147.816 1046.62 Q146.349 1043.72 143.396 1043.72 M143.396 1040.71 Q148.117 1040.71 150.6 1044.45 Q153.101 1048.18 153.101 1055.29 Q153.101 1062.38 150.6 1066.12 Q148.117 1069.84 143.396 1069.84 Q138.675 1069.84 136.174 1066.12 Q133.691 1062.38 133.691 1055.29 Q133.691 1048.18 136.174 1044.45 Q138.675 1040.71 143.396 1040.71 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M159.778 1064.52 L163.746 1064.52 L163.746 1069.3 L159.778 1069.3 L159.778 1064.52 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M175.294 1066.1 L188.554 1066.1 L188.554 1069.3 L170.724 1069.3 L170.724 1066.1 Q172.887 1063.86 176.611 1060.1 Q180.353 1056.32 181.313 1055.23 Q183.137 1053.18 183.852 1051.77 Q184.585 1050.34 184.585 1048.97 Q184.585 1046.73 183.005 1045.32 Q181.444 1043.91 178.924 1043.91 Q177.137 1043.91 175.144 1044.53 Q173.169 1045.15 170.912 1046.41 L170.912 1042.57 Q173.206 1041.65 175.2 1041.18 Q177.194 1040.71 178.849 1040.71 Q183.212 1040.71 185.808 1042.89 Q188.403 1045.07 188.403 1048.72 Q188.403 1050.45 187.745 1052.01 Q187.105 1053.56 185.394 1055.66 Q184.924 1056.21 182.403 1058.82 Q179.883 1061.42 175.294 1066.1 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M81.0976 436.725 L88.7364 436.725 L88.7364 410.36 L80.4263 412.026 L80.4263 407.767 L88.6901 406.1 L93.366 406.1 L93.366 436.725 L101.005 436.725 L101.005 440.66 L81.0976 440.66 L81.0976 436.725 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M120.449 409.179 Q116.838 409.179 115.009 412.744 Q113.204 416.285 113.204 423.415 Q113.204 430.521 115.009 434.086 Q116.838 437.628 120.449 437.628 Q124.083 437.628 125.889 434.086 Q127.718 430.521 127.718 423.415 Q127.718 416.285 125.889 412.744 Q124.083 409.179 120.449 409.179 M120.449 405.475 Q126.259 405.475 129.315 410.082 Q132.394 414.665 132.394 423.415 Q132.394 432.142 129.315 436.748 Q126.259 441.332 120.449 441.332 Q114.639 441.332 111.56 436.748 Q108.505 432.142 108.505 423.415 Q108.505 414.665 111.56 410.082 Q114.639 405.475 120.449 405.475 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M142.098 387.671 Q139.164 387.671 137.679 390.568 Q136.212 393.445 136.212 399.238 Q136.212 405.012 137.679 407.908 Q139.164 410.786 142.098 410.786 Q145.051 410.786 146.518 407.908 Q148.004 405.012 148.004 399.238 Q148.004 393.445 146.518 390.568 Q145.051 387.671 142.098 387.671 M142.098 384.662 Q146.819 384.662 149.302 388.405 Q151.803 392.129 151.803 399.238 Q151.803 406.329 149.302 410.071 Q146.819 413.795 142.098 413.795 Q137.378 413.795 134.876 410.071 Q132.394 406.329 132.394 399.238 Q132.394 392.129 134.876 388.405 Q137.378 384.662 142.098 384.662 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M158.48 408.473 L162.448 408.473 L162.448 413.25 L158.48 413.25 L158.48 408.473 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M178.849 387.671 Q175.915 387.671 174.429 390.568 Q172.962 393.445 172.962 399.238 Q172.962 405.012 174.429 407.908 Q175.915 410.786 178.849 410.786 Q181.802 410.786 183.269 407.908 Q184.754 405.012 184.754 399.238 Q184.754 393.445 183.269 390.568 Q181.802 387.671 178.849 387.671 M178.849 384.662 Q183.57 384.662 186.052 388.405 Q188.554 392.129 188.554 399.238 Q188.554 406.329 186.052 410.071 Q183.57 413.795 178.849 413.795 Q174.128 413.795 171.627 410.071 Q169.144 406.329 169.144 399.238 Q169.144 392.129 171.627 388.405 Q174.128 384.662 178.849 384.662 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><polyline clip-path="url(#clip972)" style="stroke:#009af9;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="284.786,86.1857 507.868,736.674 730.95,939.262 954.032,1063.23 1177.11,1149.67 1400.2,1216.01 1623.28,1270.04 1846.36,1314.02 2069.44,1350.93 2292.52,1384.24 "></polyline><polyline clip-path="url(#clip972)" style="stroke:#e26f46;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="284.786,551.951 507.868,819.687 730.95,966.838 954.032,1063.88 1177.11,1128.14 1400.2,1186.46 1623.28,1223.75 1846.36,1241.64 2069.44,1294.06 2292.52,1323.18 "></polyline><polyline clip-path="url(#clip972)" style="stroke:#3da44d;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="284.786,899.638 507.868,826.947 730.95,792.671 954.032,759.2 1177.11,743.717 1400.2,731.347 1623.28,723.734 1846.36,722.182 2069.44,703.007 2292.52,698.762 "></polyline><path clip-path="url(#clip970)" d="M1846.96 300.469 L2281.82 300.469 L2281.82 93.1086 L1846.96 93.1086  Z" fill="#ffffff" fill-rule="evenodd" fill-opacity="1"></path><polyline clip-path="url(#clip970)" style="stroke:#000000;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="1846.96,300.469 2281.82,300.469 2281.82,93.1086 1846.96,93.1086 1846.96,300.469 "></polyline><polyline clip-path="url(#clip970)" style="stroke:#009af9;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="1870.61,144.949 2012.49,144.949 "></polyline><path clip-path="url(#clip970)" d="M2043.54 128.942 L2043.54 136.303 L2052.31 136.303 L2052.31 139.613 L2043.54 139.613 L2043.54 153.687 Q2043.54 156.858 2044.4 157.761 Q2045.28 158.664 2047.94 158.664 L2052.31 158.664 L2052.31 162.229 L2047.94 162.229 Q2043.01 162.229 2041.13 160.4 Q2039.26 158.548 2039.26 153.687 L2039.26 139.613 L2036.13 139.613 L2036.13 136.303 L2039.26 136.303 L2039.26 128.942 L2043.54 128.942 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M2072.94 140.284 Q2072.22 139.868 2071.36 139.682 Q2070.53 139.474 2069.51 139.474 Q2065.9 139.474 2063.96 141.835 Q2062.04 144.173 2062.04 148.571 L2062.04 162.229 L2057.75 162.229 L2057.75 136.303 L2062.04 136.303 L2062.04 140.331 Q2063.38 137.969 2065.53 136.835 Q2067.68 135.678 2070.76 135.678 Q2071.2 135.678 2071.73 135.747 Q2072.27 135.794 2072.92 135.909 L2072.94 140.284 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M2089.19 149.196 Q2084.03 149.196 2082.04 150.377 Q2080.05 151.557 2080.05 154.405 Q2080.05 156.673 2081.53 158.016 Q2083.03 159.335 2085.6 159.335 Q2089.14 159.335 2091.27 156.835 Q2093.42 154.312 2093.42 150.145 L2093.42 149.196 L2089.19 149.196 M2097.68 147.437 L2097.68 162.229 L2093.42 162.229 L2093.42 158.293 Q2091.97 160.655 2089.79 161.789 Q2087.61 162.9 2084.47 162.9 Q2080.48 162.9 2078.12 160.678 Q2075.79 158.432 2075.79 154.682 Q2075.79 150.307 2078.7 148.085 Q2081.64 145.863 2087.45 145.863 L2093.42 145.863 L2093.42 145.446 Q2093.42 142.507 2091.48 140.909 Q2089.56 139.289 2086.06 139.289 Q2083.84 139.289 2081.73 139.821 Q2079.63 140.354 2077.68 141.419 L2077.68 137.483 Q2080.02 136.581 2082.22 136.141 Q2084.42 135.678 2086.5 135.678 Q2092.13 135.678 2094.91 138.594 Q2097.68 141.511 2097.68 147.437 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M2106.46 136.303 L2110.72 136.303 L2110.72 162.229 L2106.46 162.229 L2106.46 136.303 M2106.46 126.21 L2110.72 126.21 L2110.72 131.604 L2106.46 131.604 L2106.46 126.21 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M2141.18 146.581 L2141.18 162.229 L2136.92 162.229 L2136.92 146.719 Q2136.92 143.039 2135.48 141.21 Q2134.05 139.382 2131.18 139.382 Q2127.73 139.382 2125.74 141.581 Q2123.75 143.78 2123.75 147.576 L2123.75 162.229 L2119.47 162.229 L2119.47 136.303 L2123.75 136.303 L2123.75 140.331 Q2125.28 137.993 2127.34 136.835 Q2129.42 135.678 2132.13 135.678 Q2136.6 135.678 2138.89 138.456 Q2141.18 141.21 2141.18 146.581 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M2169.37 170.099 L2169.37 173.409 L2144.74 173.409 L2144.74 170.099 L2169.37 170.099 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M2173.38 126.21 L2177.64 126.21 L2177.64 162.229 L2173.38 162.229 L2173.38 126.21 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M2196.6 139.289 Q2193.17 139.289 2191.18 141.974 Q2189.19 144.636 2189.19 149.289 Q2189.19 153.942 2191.16 156.627 Q2193.15 159.289 2196.6 159.289 Q2200 159.289 2201.99 156.604 Q2203.98 153.918 2203.98 149.289 Q2203.98 144.682 2201.99 141.997 Q2200 139.289 2196.6 139.289 M2196.6 135.678 Q2202.15 135.678 2205.32 139.289 Q2208.49 142.9 2208.49 149.289 Q2208.49 155.655 2205.32 159.289 Q2202.15 162.9 2196.6 162.9 Q2191.02 162.9 2187.85 159.289 Q2184.7 155.655 2184.7 149.289 Q2184.7 142.9 2187.85 139.289 Q2191.02 135.678 2196.6 135.678 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M2232.08 137.067 L2232.08 141.094 Q2230.28 140.169 2228.33 139.706 Q2226.39 139.243 2224.3 139.243 Q2221.13 139.243 2219.54 140.215 Q2217.96 141.187 2217.96 143.131 Q2217.96 144.613 2219.1 145.469 Q2220.23 146.303 2223.66 147.067 L2225.11 147.391 Q2229.65 148.363 2231.55 150.145 Q2233.47 151.905 2233.47 155.076 Q2233.47 158.687 2230.6 160.793 Q2227.75 162.9 2222.75 162.9 Q2220.67 162.9 2218.4 162.483 Q2216.16 162.09 2213.66 161.28 L2213.66 156.881 Q2216.02 158.108 2218.31 158.733 Q2220.6 159.335 2222.85 159.335 Q2225.85 159.335 2227.47 158.317 Q2229.1 157.275 2229.1 155.4 Q2229.1 153.664 2227.91 152.738 Q2226.76 151.812 2222.8 150.956 L2221.32 150.608 Q2217.36 149.775 2215.6 148.062 Q2213.84 146.326 2213.84 143.317 Q2213.84 139.659 2216.43 137.669 Q2219.03 135.678 2223.79 135.678 Q2226.16 135.678 2228.24 136.025 Q2230.32 136.372 2232.08 137.067 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M2256.78 137.067 L2256.78 141.094 Q2254.97 140.169 2253.03 139.706 Q2251.09 139.243 2249 139.243 Q2245.83 139.243 2244.23 140.215 Q2242.66 141.187 2242.66 143.131 Q2242.66 144.613 2243.79 145.469 Q2244.93 146.303 2248.35 147.067 L2249.81 147.391 Q2254.35 148.363 2256.25 150.145 Q2258.17 151.905 2258.17 155.076 Q2258.17 158.687 2255.3 160.793 Q2252.45 162.9 2247.45 162.9 Q2245.37 162.9 2243.1 162.483 Q2240.85 162.09 2238.35 161.28 L2238.35 156.881 Q2240.72 158.108 2243.01 158.733 Q2245.3 159.335 2247.54 159.335 Q2250.55 159.335 2252.17 158.317 Q2253.79 157.275 2253.79 155.4 Q2253.79 153.664 2252.61 152.738 Q2251.46 151.812 2247.5 150.956 L2246.02 150.608 Q2242.06 149.775 2240.3 148.062 Q2238.54 146.326 2238.54 143.317 Q2238.54 139.659 2241.13 137.669 Q2243.72 135.678 2248.49 135.678 Q2250.85 135.678 2252.94 136.025 Q2255.02 136.372 2256.78 137.067 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><polyline clip-path="url(#clip970)" style="stroke:#e26f46;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="1870.61,196.789 2012.49,196.789 "></polyline><path clip-path="url(#clip970)" d="M2036.13 188.143 L2040.65 188.143 L2048.75 209.902 L2056.85 188.143 L2061.36 188.143 L2051.64 214.069 L2045.86 214.069 L2036.13 188.143 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M2079.03 201.036 Q2073.86 201.036 2071.87 202.217 Q2069.88 203.397 2069.88 206.245 Q2069.88 208.513 2071.36 209.856 Q2072.87 211.175 2075.44 211.175 Q2078.98 211.175 2081.11 208.675 Q2083.26 206.152 2083.26 201.985 L2083.26 201.036 L2079.03 201.036 M2087.52 199.277 L2087.52 214.069 L2083.26 214.069 L2083.26 210.133 Q2081.8 212.495 2079.63 213.629 Q2077.45 214.74 2074.3 214.74 Q2070.32 214.74 2067.96 212.518 Q2065.62 210.272 2065.62 206.522 Q2065.62 202.147 2068.54 199.925 Q2071.48 197.703 2077.29 197.703 L2083.26 197.703 L2083.26 197.286 Q2083.26 194.347 2081.32 192.749 Q2079.4 191.129 2075.9 191.129 Q2073.68 191.129 2071.57 191.661 Q2069.47 192.194 2067.52 193.259 L2067.52 189.323 Q2069.86 188.421 2072.06 187.981 Q2074.26 187.518 2076.34 187.518 Q2081.97 187.518 2084.74 190.434 Q2087.52 193.351 2087.52 199.277 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M2096.3 178.05 L2100.55 178.05 L2100.55 214.069 L2096.3 214.069 L2096.3 178.05 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M2129.17 221.939 L2129.17 225.249 L2104.54 225.249 L2104.54 221.939 L2129.17 221.939 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M2133.17 178.05 L2137.43 178.05 L2137.43 214.069 L2133.17 214.069 L2133.17 178.05 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M2156.39 191.129 Q2152.96 191.129 2150.97 193.814 Q2148.98 196.476 2148.98 201.129 Q2148.98 205.782 2150.95 208.467 Q2152.94 211.129 2156.39 211.129 Q2159.79 211.129 2161.78 208.444 Q2163.77 205.758 2163.77 201.129 Q2163.77 196.522 2161.78 193.837 Q2159.79 191.129 2156.39 191.129 M2156.39 187.518 Q2161.94 187.518 2165.11 191.129 Q2168.29 194.74 2168.29 201.129 Q2168.29 207.495 2165.11 211.129 Q2161.94 214.74 2156.39 214.74 Q2150.81 214.74 2147.64 211.129 Q2144.49 207.495 2144.49 201.129 Q2144.49 194.74 2147.64 191.129 Q2150.81 187.518 2156.39 187.518 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M2191.87 188.907 L2191.87 192.934 Q2190.07 192.009 2188.12 191.546 Q2186.18 191.083 2184.1 191.083 Q2180.92 191.083 2179.33 192.055 Q2177.75 193.027 2177.75 194.971 Q2177.75 196.453 2178.89 197.309 Q2180.02 198.143 2183.45 198.907 L2184.91 199.231 Q2189.44 200.203 2191.34 201.985 Q2193.26 203.745 2193.26 206.916 Q2193.26 210.527 2190.39 212.633 Q2187.54 214.74 2182.54 214.74 Q2180.46 214.74 2178.19 214.323 Q2175.95 213.93 2173.45 213.12 L2173.45 208.721 Q2175.81 209.948 2178.1 210.573 Q2180.39 211.175 2182.64 211.175 Q2185.65 211.175 2187.27 210.157 Q2188.89 209.115 2188.89 207.24 Q2188.89 205.504 2187.71 204.578 Q2186.55 203.652 2182.59 202.796 L2181.11 202.448 Q2177.15 201.615 2175.39 199.902 Q2173.63 198.166 2173.63 195.157 Q2173.63 191.499 2176.23 189.509 Q2178.82 187.518 2183.59 187.518 Q2185.95 187.518 2188.03 187.865 Q2190.11 188.212 2191.87 188.907 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M2216.57 188.907 L2216.57 192.934 Q2214.77 192.009 2212.82 191.546 Q2210.88 191.083 2208.79 191.083 Q2205.62 191.083 2204.03 192.055 Q2202.45 193.027 2202.45 194.971 Q2202.45 196.453 2203.59 197.309 Q2204.72 198.143 2208.15 198.907 L2209.6 199.231 Q2214.14 200.203 2216.04 201.985 Q2217.96 203.745 2217.96 206.916 Q2217.96 210.527 2215.09 212.633 Q2212.24 214.74 2207.24 214.74 Q2205.16 214.74 2202.89 214.323 Q2200.65 213.93 2198.15 213.12 L2198.15 208.721 Q2200.51 209.948 2202.8 210.573 Q2205.09 211.175 2207.34 211.175 Q2210.35 211.175 2211.97 210.157 Q2213.59 209.115 2213.59 207.24 Q2213.59 205.504 2212.41 204.578 Q2211.25 203.652 2207.29 202.796 L2205.81 202.448 Q2201.85 201.615 2200.09 199.902 Q2198.33 198.166 2198.33 195.157 Q2198.33 191.499 2200.92 189.509 Q2203.52 187.518 2208.29 187.518 Q2210.65 187.518 2212.73 187.865 Q2214.81 188.212 2216.57 188.907 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><polyline clip-path="url(#clip970)" style="stroke:#3da44d;stroke-linecap:round;stroke-linejoin:round;stroke-width:4;stroke-opacity:1;fill:none;" points="1870.61,248.629 2012.49,248.629 "></polyline><path clip-path="url(#clip970)" d="M2036.13 239.983 L2040.65 239.983 L2048.75 261.742 L2056.85 239.983 L2061.36 239.983 L2051.64 265.909 L2045.86 265.909 L2036.13 239.983 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M2079.03 252.876 Q2073.86 252.876 2071.87 254.057 Q2069.88 255.237 2069.88 258.085 Q2069.88 260.353 2071.36 261.696 Q2072.87 263.015 2075.44 263.015 Q2078.98 263.015 2081.11 260.515 Q2083.26 257.992 2083.26 253.825 L2083.26 252.876 L2079.03 252.876 M2087.52 251.117 L2087.52 265.909 L2083.26 265.909 L2083.26 261.973 Q2081.8 264.335 2079.63 265.469 Q2077.45 266.58 2074.3 266.58 Q2070.32 266.58 2067.96 264.358 Q2065.62 262.112 2065.62 258.362 Q2065.62 253.987 2068.54 251.765 Q2071.48 249.543 2077.29 249.543 L2083.26 249.543 L2083.26 249.126 Q2083.26 246.187 2081.32 244.589 Q2079.4 242.969 2075.9 242.969 Q2073.68 242.969 2071.57 243.501 Q2069.47 244.034 2067.52 245.099 L2067.52 241.163 Q2069.86 240.261 2072.06 239.821 Q2074.26 239.358 2076.34 239.358 Q2081.97 239.358 2084.74 242.274 Q2087.52 245.191 2087.52 251.117 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M2096.3 229.89 L2100.55 229.89 L2100.55 265.909 L2096.3 265.909 L2096.3 229.89 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M2129.17 273.779 L2129.17 277.089 L2104.54 277.089 L2104.54 273.779 L2129.17 273.779 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M2144.95 252.876 Q2139.79 252.876 2137.8 254.057 Q2135.81 255.237 2135.81 258.085 Q2135.81 260.353 2137.29 261.696 Q2138.79 263.015 2141.36 263.015 Q2144.91 263.015 2147.04 260.515 Q2149.19 257.992 2149.19 253.825 L2149.19 252.876 L2144.95 252.876 M2153.45 251.117 L2153.45 265.909 L2149.19 265.909 L2149.19 261.973 Q2147.73 264.335 2145.55 265.469 Q2143.38 266.58 2140.23 266.58 Q2136.25 266.58 2133.89 264.358 Q2131.55 262.112 2131.55 258.362 Q2131.55 253.987 2134.47 251.765 Q2137.41 249.543 2143.22 249.543 L2149.19 249.543 L2149.19 249.126 Q2149.19 246.187 2147.24 244.589 Q2145.32 242.969 2141.83 242.969 Q2139.6 242.969 2137.5 243.501 Q2135.39 244.034 2133.45 245.099 L2133.45 241.163 Q2135.79 240.261 2137.98 239.821 Q2140.18 239.358 2142.27 239.358 Q2147.89 239.358 2150.67 242.274 Q2153.45 245.191 2153.45 251.117 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M2180.88 240.978 L2180.88 244.96 Q2179.07 243.964 2177.24 243.478 Q2175.44 242.969 2173.59 242.969 Q2169.44 242.969 2167.15 245.608 Q2164.86 248.224 2164.86 252.969 Q2164.86 257.714 2167.15 260.353 Q2169.44 262.969 2173.59 262.969 Q2175.44 262.969 2177.24 262.483 Q2179.07 261.973 2180.88 260.978 L2180.88 264.913 Q2179.1 265.747 2177.17 266.163 Q2175.28 266.58 2173.12 266.58 Q2167.27 266.58 2163.82 262.899 Q2160.37 259.219 2160.37 252.969 Q2160.37 246.626 2163.84 242.992 Q2167.34 239.358 2173.4 239.358 Q2175.37 239.358 2177.24 239.775 Q2179.12 240.168 2180.88 240.978 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip970)" d="M2206.94 240.978 L2206.94 244.96 Q2205.14 243.964 2203.31 243.478 Q2201.5 242.969 2199.65 242.969 Q2195.51 242.969 2193.22 245.608 Q2190.92 248.224 2190.92 252.969 Q2190.92 257.714 2193.22 260.353 Q2195.51 262.969 2199.65 262.969 Q2201.5 262.969 2203.31 262.483 Q2205.14 261.973 2206.94 260.978 L2206.94 264.913 Q2205.16 265.747 2203.24 266.163 Q2201.34 266.58 2199.19 266.58 Q2193.33 266.58 2189.88 262.899 Q2186.43 259.219 2186.43 252.969 Q2186.43 246.626 2189.91 242.992 Q2193.4 239.358 2199.47 239.358 Q2201.43 239.358 2203.31 239.775 Q2205.18 240.168 2206.94 240.978 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path></svg><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>(MLPConcise{Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, typeof(softmax)}}, @NamedTuple{num_inputs::Int64, num_hiddens::Int64, num_outputs::Int64, lr::Float64}}(Chain(Dense(784 =&gt; 256, relu), Dense(256 =&gt; 10), softmax), (num_inputs = 784, num_hiddens = 256, num_outputs = 10, lr = 0.01)), (val_loss = Float32[0.47921216, 0.48217854, 0.5917104, 0.49460533, 0.54532135, 0.48910785, 0.46038538, 0.5588525, 0.44173148, 0.51100296  â€¦  0.51876605, 0.5761145, 0.48369744, 0.5024649, 0.5960579, 0.54009736, 0.4811007, 0.5494064, 0.49265826, 0.31624204], val_acc = [0.828125, 0.85546875, 0.8046875, 0.828125, 0.81640625, 0.8359375, 0.86328125, 0.8359375, 0.84765625, 0.828125  â€¦  0.8359375, 0.78515625, 0.8203125, 0.81640625, 0.7890625, 0.80859375, 0.80078125, 0.82421875, 0.84765625, 0.875]))</span></span></code></pre></div><h2 id="Summary" tabindex="-1">Summary <a class="header-anchor" href="#Summary" aria-label="Permalink to &quot;Summary {#Summary}&quot;">â€‹</a></h2><p>Now that we have more practice in designing deep networks, the step from a single to multiple layers of deep networks does not pose such a significant challenge any longer. In particular, we can reuse the training algorithm and data loader. Note, though, that implementing MLPs from scratch is nonetheless messy: naming and keeping track of the model parameters makes it difficult to extend models. For instance, imagine wanting to insert another layer between layers 42 and 43. This might now be layer 42b, unless we are willing to perform sequential renaming. Moreover, if we implement the network from scratch, it is much more difficult for the framework to perform meaningful performance optimizations.</p><p>Nonetheless, you have now reached the state of the art of the late 1980s when fully connected deep networks were the method of choice for neural network modeling. Our next conceptual step will be to consider images. Before we do so, we need to review a number of statistical basics and details on how to compute models efficiently.</p><h2 id="Exercises" tabindex="-1">Exercises <a class="header-anchor" href="#Exercises" aria-label="Permalink to &quot;Exercises {#Exercises}&quot;">â€‹</a></h2><ol><li><p>Change the number of hidden units <code>num_hiddens</code> and plot how its number affects the accuracy of the model. What is the best value of this hyperparameter?</p></li><li><p>Try adding a hidden layer to see how it affects the results.</p></li><li><p>Why is it a bad idea to insert a hidden layer with a single neuron? What could go wrong?</p></li><li><p>How does changing the learning rate alter your results? With all other parameters fixed, which learning rate gives you the best results? How does this relate to the number of epochs?</p></li><li><p>Let&#39;s optimize over all hyperparameters jointly, i.e., learning rate, number of epochs, number of hidden layers, and number of hidden units per layer.</p></li><li><p>What is the best result you can get by optimizing over all of them?</p></li><li><p>Why it is much more challenging to deal with multiple hyperparameters?</p></li><li><p>Describe an efficient strategy for optimizing over multiple parameters jointly.</p></li><li><p>Compare the speed of the framework and the from-scratch implementation for a challenging problem. How does it change with the complexity of the network?</p></li><li><p>Measure the speed of tensorâ€“matrix multiplications for well-aligned and misaligned matrices. For instance, test for matrices with dimension 1024, 1025, 1026, 1028, and 1032.</p></li><li><p>How does this change between GPUs and CPUs?</p></li><li><p>Determine the memory bus width of your CPU and GPU.</p></li><li><p>Try out different activation functions. Which one works best?</p></li><li><p>Is there a difference between weight initializations of the network? Does it matter?</p></li></ol><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"></span></code></pre></div></div></div></main><footer class="VPDocFooter" data-v-83890dd9 data-v-4f9813fa><!--[--><!--]--><div class="edit-info" data-v-4f9813fa><div class="edit-link" data-v-4f9813fa><a class="VPLink link vp-external-link-icon no-icon edit-link-button" href="https://https://github.com/ashutosh-b-b/d2l-julia/edit/master/docs/src/CH5.MLP/MLP_2.md" target="_blank" rel="noreferrer" data-v-4f9813fa><!--[--><span class="vpi-square-pen edit-link-icon" data-v-4f9813fa></span> Edit this page<!--]--></a></div><!----></div><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-4f9813fa><span class="visually-hidden" id="doc-footer-aria-label" data-v-4f9813fa>Pager</span><div class="pager" data-v-4f9813fa><a class="VPLink link pager-link prev" href="/d2l-julia/previews/PR1/CH5.MLP/MLP_1" data-v-4f9813fa><!--[--><span class="desc" data-v-4f9813fa>Previous page</span><span class="title" data-v-4f9813fa>Multilayer Perceptrons</span><!--]--></a></div><div class="pager" data-v-4f9813fa><a class="VPLink link pager-link next" href="/d2l-julia/previews/PR1/CH5.MLP/MLP_3" data-v-4f9813fa><!--[--><span class="desc" data-v-4f9813fa>Next page</span><span class="title" data-v-4f9813fa>Forward Propagation, Backward Propagation, and Computational Graphs</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-a9a9e638 data-v-c970a860><div class="container" data-v-c970a860><p class="message" data-v-c970a860>Made with <a href="https://luxdl.github.io/DocumenterVitepress.jl/dev/" target="_blank"><strong>DocumenterVitepress.jl</strong></a><br></p><p class="copyright" data-v-c970a860>Â© Copyright 2025.</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"ch10.attention_mechanisms_and_transformers_attn_1.md\":\"BPTHOId7\",\"ch10.attention_mechanisms_and_transformers_attn_2.md\":\"CSvHAO07\",\"ch10.attention_mechanisms_and_transformers_attn_3.md\":\"B6P-XMmW\",\"ch10.attention_mechanisms_and_transformers_attn_4.md\":\"CB5DEaB1\",\"ch10.attention_mechanisms_and_transformers_attn_5.md\":\"DQHNoxkK\",\"ch10.attention_mechanisms_and_transformers_attn_6.md\":\"DJp_Cd3H\",\"ch10.attention_mechanisms_and_transformers_untitled.md\":\"AZxRWAaB\",\"ch3.linear_regression_lnn_1.md\":\"DTK1fX6I\",\"ch3.linear_regression_lnn_2.md\":\"BD8w6uR8\",\"ch3.linear_regression_lnn_3.md\":\"C4MB6zPT\",\"ch3.linear_regression_lnn_4.md\":\"B7J5MW04\",\"ch3.linear_regression_lnn_5.md\":\"CfF2CfNK\",\"ch3.linear_regression_lnn_6.md\":\"uj6xm8fY\",\"ch3.linear_regression_lnn_7.md\":\"B_zpSpiN\",\"ch4.linear_classification_lcn_1.md\":\"Boi1cDsh\",\"ch4.linear_classification_lcn_2.md\":\"CkOR2Iia\",\"ch4.linear_classification_lcn_3.md\":\"V-0rtib8\",\"ch4.linear_classification_lcn_4.md\":\"BX5UP2HZ\",\"ch4.linear_classification_lcn_5.md\":\"C-7KZE9h\",\"ch4.linear_classification_lcn_6.md\":\"DNDvKaZ3\",\"ch5.mlp_mlp_1.md\":\"DNcZmrDZ\",\"ch5.mlp_mlp_2.md\":\"MI21_tyz\",\"ch5.mlp_mlp_3.md\":\"DVB63m8H\",\"ch5.mlp_mlp_4.md\":\"BYjKXVG9\",\"ch5.mlp_mlp_5.md\":\"CxEzVy5G\",\"ch5.mlp_mlp_6.md\":\"CpygNHoD\",\"ch6.convolutional_neural_networks_cnn_2.md\":\"pAndzyT8\",\"ch6.convolutional_neural_networks_cnn_3.md\":\"CyHC0BXV\",\"ch6.convolutional_neural_networks_cnn_4.md\":\"-fYwA9iM\",\"ch6.convolutional_neural_networks_cnn_5.md\":\"DKCH7I6h\",\"ch6.convolutional_neural_networks_cnn_6.md\":\"BxTNLj1_\",\"ch7.modernconvolutionalneuralnetworks_mcnn_0.md\":\"Do42Pcb-\",\"ch7.modernconvolutionalneuralnetworks_mcnn_1.md\":\"DyrfEGE0\",\"ch7.modernconvolutionalneuralnetworks_mcnn_2.md\":\"BdK6e3J7\",\"ch7.modernconvolutionalneuralnetworks_mcnn_3.md\":\"CvJU8raL\",\"ch7.modernconvolutionalneuralnetworks_mcnn_4.md\":\"DfMUvHOO\",\"ch7.modernconvolutionalneuralnetworks_mcnn_5.md\":\"CVkY2ACS\",\"ch7.modernconvolutionalneuralnetworks_mcnn_6.md\":\"Cin-j3ht\",\"ch7.modernconvolutionalneuralnetworks_mcnn_7.md\":\"BY0qhW6e\",\"ch7.modernconvolutionalneuralnetworks_mcnn_8.md\":\"CfFt59lS\",\"ch8.recurrent_neural_networks_rnn_0.md\":\"CIW34d_V\",\"ch8.recurrent_neural_networks_rnn_1.md\":\"Dqwc86d0\",\"ch8.recurrent_neural_networks_rnn_2.md\":\"DVOnaLjw\",\"ch8.recurrent_neural_networks_rnn_3.md\":\"BzfHLTyo\",\"ch8.recurrent_neural_networks_rnn_4.md\":\"DnQjCEE3\",\"ch8.recurrent_neural_networks_rnn_5.md\":\"6IPEYW7M\",\"ch8.recurrent_neural_networks_rnn_6.md\":\"GS6Ynndo\",\"ch8.recurrent_neural_networks_rnn_7.md\":\"B3soXDbW\",\"ch9.modern_recurrent_neural_networks_mrnn_1.md\":\"zGzQsIzl\",\"ch9.modern_recurrent_neural_networks_mrnn_2.md\":\"CV4lwlnE\",\"ch9.modern_recurrent_neural_networks_mrnn_3.md\":\"DI9bj1mT\",\"ch9.modern_recurrent_neural_networks_mrnn_4.md\":\"CvMg8EjP\",\"ch9.modern_recurrent_neural_networks_mrnn_5.md\":\"CuOfLj02\",\"ch9.modern_recurrent_neural_networks_mrnn_6.md\":\"BrLASjSi\",\"ch9.modern_recurrent_neural_networks_mrnn_7.md\":\"D5R7Lv49\",\"chapters.md\":\"BCfSINH3\",\"index.md\":\"C9fKtYo7\",\"references.md\":\"Dwf5fRK0\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"d2l Julia\",\"description\":\"Documentation for d2l-julia\",\"base\":\"/d2l-julia/previews/PR1/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"outline\":\"deep\",\"logo\":{\"src\":\"/logo.png\",\"width\":24,\"height\":24},\"search\":{\"provider\":\"local\",\"options\":{\"detailedView\":true}},\"nav\":[{\"text\":\"Home\",\"link\":\"/index\"},{\"text\":\"Chapters\",\"collapsed\":false,\"items\":[{\"text\":\"ðŸ“˜ Chapters Overview\",\"link\":\"/chapters\"},{\"text\":\"Linear Neural Networks for Regression\",\"collapsed\":false,\"items\":[{\"text\":\"Linear Regression\",\"link\":\"/CH3.Linear_Regression/LNN_1\"},{\"text\":\"Multiple Dispatch Design for Implementation\",\"link\":\"/CH3.Linear_Regression/LNN_2\"},{\"text\":\"Synthetic Regression Data\",\"link\":\"/CH3.Linear_Regression/LNN_3\"},{\"text\":\"Linear Regression Implementation from Scratch\",\"link\":\"/CH3.Linear_Regression/LNN_4\"},{\"text\":\"Concise Implementation of Linear Regression\",\"link\":\"/CH3.Linear_Regression/LNN_5\"},{\"text\":\"Generalization\",\"link\":\"/CH3.Linear_Regression/LNN_6\"},{\"text\":\"Weight Decay\",\"link\":\"/CH3.Linear_Regression/LNN_7\"}]},{\"text\":\"Linear Neural Networks for Classification\",\"collapsed\":false,\"items\":[{\"text\":\"Softmax Regression\",\"link\":\"/CH4.Linear_Classification/LCN_1\"},{\"text\":\"The Image Classification Dataset\",\"link\":\"/CH4.Linear_Classification/LCN_2\"},{\"text\":\"Softmax Regression Implementation from Scratch\",\"link\":\"/CH4.Linear_Classification/LCN_3\"},{\"text\":\"Concise Implementation of Softmax Regression\",\"link\":\"/CH4.Linear_Classification/LCN_4\"},{\"text\":\"Generalization in Classification\",\"link\":\"/CH4.Linear_Classification/LCN_5\"},{\"text\":\"Environment and Distribution Shift\",\"link\":\"/CH4.Linear_Classification/LCN_6\"}]},{\"text\":\"Multilayer Perceptron\",\"collapsed\":false,\"items\":[{\"text\":\"Multilayer Perceptrons\",\"link\":\"/CH5.MLP/MLP_1\"},{\"text\":\"Implementation of Multilayer Perceptrons\",\"link\":\"/CH5.MLP/MLP_2\"},{\"text\":\"Forward Propagation, Backward Propagation, and Computational Graphs\",\"link\":\"/CH5.MLP/MLP_3\"},{\"text\":\"Numerical Stability and Initialization\",\"link\":\"/CH5.MLP/MLP_4\"},{\"text\":\"Generalization in Deep Learning\",\"link\":\"/CH5.MLP/MLP_5\"},{\"text\":\"Dropout\",\"link\":\"/CH5.MLP/MLP_6\"}]},{\"text\":\"Convolutional Neural Networks\",\"collapsed\":false,\"items\":[{\"text\":\"Convolutions for Images\",\"link\":\"/CH6.Convolutional_Neural_Networks/CNN_2\"},{\"text\":\"Padding and Stride\",\"link\":\"/CH6.Convolutional_Neural_Networks/CNN_3\"},{\"text\":\"Multiple Input and Multiple Output Channels\",\"link\":\"/CH6.Convolutional_Neural_Networks/CNN_4\"},{\"text\":\"Pooling\",\"link\":\"/CH6.Convolutional_Neural_Networks/CNN_5\"},{\"text\":\"Convolutional Neural Networks (LeNet)\",\"link\":\"/CH6.Convolutional_Neural_Networks/CNN_6\"}]},{\"text\":\"Modern Convolutional Neural Networks\",\"collapsed\":false,\"items\":[{\"text\":\"Modern Convolutional Neural Networks\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_0\"},{\"text\":\"Deep Convolutional Neural Networks (AlexNet)\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_1\"},{\"text\":\"Networks Using Blocks (VGG)\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_2\"},{\"text\":\"Network in Network (NiN)\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_3\"},{\"text\":\"Multi-Branch Networks  (GoogLeNet)\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_4\"},{\"text\":\"Batch Normalization\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_5\"},{\"text\":\"Residual Networks (ResNet) and ResNeXt\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_6\"},{\"text\":\"Densely Connected Networks (DenseNet)\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_7\"},{\"text\":\"Designing Convolution Network Architectures\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_8\"}]},{\"text\":\"Recurrent Neural Networks\",\"collapsed\":false,\"items\":[{\"text\":\"Recurrent Neural Networks\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_0\"},{\"text\":\"Working with Sequences\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_1\"},{\"text\":\"Converting Raw Text into Sequence Data\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_2\"},{\"text\":\"Language Models\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_3\"},{\"text\":\"Recurrent Neural Networks\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_4\"},{\"text\":\"Recurrent Neural Network Implementation from Scratch\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_5\"},{\"text\":\"Concise Implementation of Recurrent Neural Networks\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_6\"},{\"text\":\"Backpropagation Through Time\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_7\"}]},{\"text\":\"Modern Recurrent Neural Networks\",\"collapsed\":false,\"items\":[{\"text\":\"Long Short-Term Memory (LSTM)\",\"link\":\"/CH9.Modern_Recurrent_Neural_Networks/MRNN_1\"},{\"text\":\"Gated Recurrent Units (GRU)\",\"link\":\"/CH9.Modern_Recurrent_Neural_Networks/MRNN_2\"},{\"text\":\"Deep Recurrent Neural Networks\",\"link\":\"/CH9.Modern_Recurrent_Neural_Networks/MRNN_3\"},{\"text\":\"Bidirectional Recurrent Neural Networks\",\"link\":\"/CH9.Modern_Recurrent_Neural_Networks/MRNN_4\"},{\"text\":\"Machine Translation and the Dataset\",\"link\":\"/CH9.Modern_Recurrent_Neural_Networks/MRNN_5\"},{\"text\":\"The Encoderâ€“Decoder Architecture\",\"link\":\"/CH9.Modern_Recurrent_Neural_Networks/MRNN_6\"},{\"text\":\"Sequence-to-Sequence Learning for Machine Translation\",\"link\":\"/CH9.Modern_Recurrent_Neural_Networks/MRNN_7\"}]},{\"text\":\"Attention Mechanisms and Transformers\",\"collapsed\":false,\"items\":[{\"text\":\"Queries, Keys, and Values\",\"link\":\"/CH10.Attention_Mechanisms_and_Transformers/ATTN_1\"},{\"text\":\"Attention Pooling by Similarity\",\"link\":\"/CH10.Attention_Mechanisms_and_Transformers/ATTN_2\"},{\"text\":\"Attention Scoring Functions\",\"link\":\"/CH10.Attention_Mechanisms_and_Transformers/ATTN_3\"},{\"text\":\"The Bahdanau Attention Mechanism\",\"link\":\"/CH10.Attention_Mechanisms_and_Transformers/ATTN_4\"},{\"text\":\"Multi-Head Attention\",\"link\":\"/CH10.Attention_Mechanisms_and_Transformers/ATTN_5\"},{\"text\":\"Self-Attention and Positional Encoding\",\"link\":\"/CH10.Attention_Mechanisms_and_Transformers/ATTN_6\"},{\"text\":\"CH10.Attention_Mechanisms_and_Transformers/Untitled\",\"link\":\"/CH10.Attention_Mechanisms_and_Transformers/Untitled\"}]}]},{\"text\":\"References\",\"link\":\"/references\"},{\"component\":\"VersionPicker\"}],\"sidebar\":[{\"text\":\"Home\",\"link\":\"/index\"},{\"text\":\"Chapters\",\"collapsed\":false,\"items\":[{\"text\":\"ðŸ“˜ Chapters Overview\",\"link\":\"/chapters\"},{\"text\":\"Linear Neural Networks for Regression\",\"collapsed\":false,\"items\":[{\"text\":\"Linear Regression\",\"link\":\"/CH3.Linear_Regression/LNN_1\"},{\"text\":\"Multiple Dispatch Design for Implementation\",\"link\":\"/CH3.Linear_Regression/LNN_2\"},{\"text\":\"Synthetic Regression Data\",\"link\":\"/CH3.Linear_Regression/LNN_3\"},{\"text\":\"Linear Regression Implementation from Scratch\",\"link\":\"/CH3.Linear_Regression/LNN_4\"},{\"text\":\"Concise Implementation of Linear Regression\",\"link\":\"/CH3.Linear_Regression/LNN_5\"},{\"text\":\"Generalization\",\"link\":\"/CH3.Linear_Regression/LNN_6\"},{\"text\":\"Weight Decay\",\"link\":\"/CH3.Linear_Regression/LNN_7\"}]},{\"text\":\"Linear Neural Networks for Classification\",\"collapsed\":false,\"items\":[{\"text\":\"Softmax Regression\",\"link\":\"/CH4.Linear_Classification/LCN_1\"},{\"text\":\"The Image Classification Dataset\",\"link\":\"/CH4.Linear_Classification/LCN_2\"},{\"text\":\"Softmax Regression Implementation from Scratch\",\"link\":\"/CH4.Linear_Classification/LCN_3\"},{\"text\":\"Concise Implementation of Softmax Regression\",\"link\":\"/CH4.Linear_Classification/LCN_4\"},{\"text\":\"Generalization in Classification\",\"link\":\"/CH4.Linear_Classification/LCN_5\"},{\"text\":\"Environment and Distribution Shift\",\"link\":\"/CH4.Linear_Classification/LCN_6\"}]},{\"text\":\"Multilayer Perceptron\",\"collapsed\":false,\"items\":[{\"text\":\"Multilayer Perceptrons\",\"link\":\"/CH5.MLP/MLP_1\"},{\"text\":\"Implementation of Multilayer Perceptrons\",\"link\":\"/CH5.MLP/MLP_2\"},{\"text\":\"Forward Propagation, Backward Propagation, and Computational Graphs\",\"link\":\"/CH5.MLP/MLP_3\"},{\"text\":\"Numerical Stability and Initialization\",\"link\":\"/CH5.MLP/MLP_4\"},{\"text\":\"Generalization in Deep Learning\",\"link\":\"/CH5.MLP/MLP_5\"},{\"text\":\"Dropout\",\"link\":\"/CH5.MLP/MLP_6\"}]},{\"text\":\"Convolutional Neural Networks\",\"collapsed\":false,\"items\":[{\"text\":\"Convolutions for Images\",\"link\":\"/CH6.Convolutional_Neural_Networks/CNN_2\"},{\"text\":\"Padding and Stride\",\"link\":\"/CH6.Convolutional_Neural_Networks/CNN_3\"},{\"text\":\"Multiple Input and Multiple Output Channels\",\"link\":\"/CH6.Convolutional_Neural_Networks/CNN_4\"},{\"text\":\"Pooling\",\"link\":\"/CH6.Convolutional_Neural_Networks/CNN_5\"},{\"text\":\"Convolutional Neural Networks (LeNet)\",\"link\":\"/CH6.Convolutional_Neural_Networks/CNN_6\"}]},{\"text\":\"Modern Convolutional Neural Networks\",\"collapsed\":false,\"items\":[{\"text\":\"Modern Convolutional Neural Networks\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_0\"},{\"text\":\"Deep Convolutional Neural Networks (AlexNet)\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_1\"},{\"text\":\"Networks Using Blocks (VGG)\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_2\"},{\"text\":\"Network in Network (NiN)\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_3\"},{\"text\":\"Multi-Branch Networks  (GoogLeNet)\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_4\"},{\"text\":\"Batch Normalization\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_5\"},{\"text\":\"Residual Networks (ResNet) and ResNeXt\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_6\"},{\"text\":\"Densely Connected Networks (DenseNet)\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_7\"},{\"text\":\"Designing Convolution Network Architectures\",\"link\":\"/CH7.ModernConvolutionalNeuralNetworks/MCNN_8\"}]},{\"text\":\"Recurrent Neural Networks\",\"collapsed\":false,\"items\":[{\"text\":\"Recurrent Neural Networks\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_0\"},{\"text\":\"Working with Sequences\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_1\"},{\"text\":\"Converting Raw Text into Sequence Data\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_2\"},{\"text\":\"Language Models\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_3\"},{\"text\":\"Recurrent Neural Networks\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_4\"},{\"text\":\"Recurrent Neural Network Implementation from Scratch\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_5\"},{\"text\":\"Concise Implementation of Recurrent Neural Networks\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_6\"},{\"text\":\"Backpropagation Through Time\",\"link\":\"/CH8.Recurrent_Neural_Networks/RNN_7\"}]},{\"text\":\"Modern Recurrent Neural Networks\",\"collapsed\":false,\"items\":[{\"text\":\"Long Short-Term Memory (LSTM)\",\"link\":\"/CH9.Modern_Recurrent_Neural_Networks/MRNN_1\"},{\"text\":\"Gated Recurrent Units (GRU)\",\"link\":\"/CH9.Modern_Recurrent_Neural_Networks/MRNN_2\"},{\"text\":\"Deep Recurrent Neural Networks\",\"link\":\"/CH9.Modern_Recurrent_Neural_Networks/MRNN_3\"},{\"text\":\"Bidirectional Recurrent Neural Networks\",\"link\":\"/CH9.Modern_Recurrent_Neural_Networks/MRNN_4\"},{\"text\":\"Machine Translation and the Dataset\",\"link\":\"/CH9.Modern_Recurrent_Neural_Networks/MRNN_5\"},{\"text\":\"The Encoderâ€“Decoder Architecture\",\"link\":\"/CH9.Modern_Recurrent_Neural_Networks/MRNN_6\"},{\"text\":\"Sequence-to-Sequence Learning for Machine Translation\",\"link\":\"/CH9.Modern_Recurrent_Neural_Networks/MRNN_7\"}]},{\"text\":\"Attention Mechanisms and Transformers\",\"collapsed\":false,\"items\":[{\"text\":\"Queries, Keys, and Values\",\"link\":\"/CH10.Attention_Mechanisms_and_Transformers/ATTN_1\"},{\"text\":\"Attention Pooling by Similarity\",\"link\":\"/CH10.Attention_Mechanisms_and_Transformers/ATTN_2\"},{\"text\":\"Attention Scoring Functions\",\"link\":\"/CH10.Attention_Mechanisms_and_Transformers/ATTN_3\"},{\"text\":\"The Bahdanau Attention Mechanism\",\"link\":\"/CH10.Attention_Mechanisms_and_Transformers/ATTN_4\"},{\"text\":\"Multi-Head Attention\",\"link\":\"/CH10.Attention_Mechanisms_and_Transformers/ATTN_5\"},{\"text\":\"Self-Attention and Positional Encoding\",\"link\":\"/CH10.Attention_Mechanisms_and_Transformers/ATTN_6\"},{\"text\":\"CH10.Attention_Mechanisms_and_Transformers/Untitled\",\"link\":\"/CH10.Attention_Mechanisms_and_Transformers/Untitled\"}]}]},{\"text\":\"References\",\"link\":\"/references\"}],\"editLink\":{\"pattern\":\"https://https://github.com/ashutosh-b-b/d2l-julia/edit/master/docs/src/:path\"},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/ashutosh-b-b/d2l-julia\"}],\"footer\":{\"message\":\"Made with <a href=\\\"https://luxdl.github.io/DocumenterVitepress.jl/dev/\\\" target=\\\"_blank\\\"><strong>DocumenterVitepress.jl</strong></a><br>\",\"copyright\":\"Â© Copyright 2025.\"}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":true}");</script>
    
  </body>
</html>