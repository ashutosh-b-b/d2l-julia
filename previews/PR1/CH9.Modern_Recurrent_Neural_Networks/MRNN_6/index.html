<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>The Encoder–Decoder Architecture · d2l Julia</title><meta name="title" content="The Encoder–Decoder Architecture · d2l Julia"/><meta property="og:title" content="The Encoder–Decoder Architecture · d2l Julia"/><meta property="twitter:title" content="The Encoder–Decoder Architecture · d2l Julia"/><meta name="description" content="Documentation for d2l Julia."/><meta property="og:description" content="Documentation for d2l Julia."/><meta property="twitter:description" content="Documentation for d2l Julia."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../CH3.Linear_Regression/LNN_1/">d2l Julia</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><span class="tocitem">Linear Neural Networks for Regression</span><ul><li><a class="tocitem" href="../../CH3.Linear_Regression/LNN_1/">Linear Regression</a></li><li><a class="tocitem" href="../../CH3.Linear_Regression/LNN_2/">Multiple Dispatch Design for Implementation</a></li><li><a class="tocitem" href="../../CH3.Linear_Regression/LNN_3/">Synthetic Regression Data</a></li><li><a class="tocitem" href="../../CH3.Linear_Regression/LNN_4/">Linear Regression Implementation from Scratch</a></li><li><a class="tocitem" href="../../CH3.Linear_Regression/LNN_5/">Concise Implementation of Linear Regression</a></li><li><a class="tocitem" href="../../CH3.Linear_Regression/LNN_6/">Generalization</a></li><li><a class="tocitem" href="../../CH3.Linear_Regression/LNN_7/">Weight Decay</a></li></ul></li><li><span class="tocitem">Linear Neural Networks for Classification</span><ul><li><a class="tocitem" href="../../CH4.Linear_Classification/LCN_1/">Softmax Regression</a></li><li><a class="tocitem" href="../../CH4.Linear_Classification/LCN_2/">The Image Classification Dataset</a></li><li><a class="tocitem" href="../../CH4.Linear_Classification/LCN_3/">Softmax Regression Implementation from Scratch</a></li><li><a class="tocitem" href="../../CH4.Linear_Classification/LCN_4/">Concise Implementation of Softmax Regression</a></li><li><a class="tocitem" href="../../CH4.Linear_Classification/LCN_5/">Generalization in Classification</a></li><li><a class="tocitem" href="../../CH4.Linear_Classification/LCN_6/">Environment and Distribution Shift</a></li></ul></li><li><span class="tocitem">Multilayer Perceptron</span><ul><li><a class="tocitem" href="../../CH5.MLP/MLP_1/">Multilayer Perceptrons</a></li><li><a class="tocitem" href="../../CH5.MLP/MLP_2/">Implementation of Multilayer Perceptrons</a></li><li><a class="tocitem" href="../../CH5.MLP/MLP_3/">Forward Propagation, Backward Propagation, and Computational Graphs</a></li><li><a class="tocitem" href="../../CH5.MLP/MLP_4/">Numerical Stability and Initialization</a></li><li><a class="tocitem" href="../../CH5.MLP/MLP_5/">Generalization in Deep Learning</a></li><li><a class="tocitem" href="../../CH5.MLP/MLP_6/">Dropout</a></li></ul></li><li><span class="tocitem">Convolutional Neural Networks</span><ul><li><a class="tocitem" href="../../CH6.Convolutional_Neural_Networks/CNN_2/">Convolutions for Images</a></li><li><a class="tocitem" href="../../CH6.Convolutional_Neural_Networks/CNN_3/">Padding and Stride</a></li><li><a class="tocitem" href="../../CH6.Convolutional_Neural_Networks/CNN_4/">Multiple Input and Multiple Output Channels</a></li><li><a class="tocitem" href="../../CH6.Convolutional_Neural_Networks/CNN_5/">Pooling</a></li><li><a class="tocitem" href="../../CH6.Convolutional_Neural_Networks/CNN_6/">Convolutional Neural Networks (LeNet)</a></li></ul></li><li><span class="tocitem">Modern Convolutional Neural Networks</span><ul><li><a class="tocitem" href="../../CH7.ModernConvolutionalNeuralNetworks/MCNN_0/">Modern Convolutional Neural Networks</a></li><li><a class="tocitem" href="../../CH7.ModernConvolutionalNeuralNetworks/MCNN_1/">Deep Convolutional Neural Networks (AlexNet)</a></li><li><a class="tocitem" href="../../CH7.ModernConvolutionalNeuralNetworks/MCNN_2/">Networks Using Blocks (VGG)</a></li><li><a class="tocitem" href="../../CH7.ModernConvolutionalNeuralNetworks/MCNN_3/">-</a></li><li><a class="tocitem" href="../../CH7.ModernConvolutionalNeuralNetworks/MCNN_4/">Multi-Branch Networks  (GoogLeNet)</a></li><li><a class="tocitem" href="../../CH7.ModernConvolutionalNeuralNetworks/MCNN_5/">-</a></li><li><a class="tocitem" href="../../CH7.ModernConvolutionalNeuralNetworks/MCNN_6/">Residual Networks (ResNet) and ResNeXt</a></li><li><a class="tocitem" href="../../CH7.ModernConvolutionalNeuralNetworks/MCNN_7/">Densely Connected Networks (DenseNet)</a></li><li><a class="tocitem" href="../../CH7.ModernConvolutionalNeuralNetworks/MCNN_8/">Designing Convolution Network Architectures</a></li></ul></li><li><span class="tocitem">Recurrent Neural Networks</span><ul><li><a class="tocitem" href="../../CH8.Recurrent_Neural_Networks/RNN_0/">Recurrent Neural Networks</a></li><li><a class="tocitem" href="../../CH8.Recurrent_Neural_Networks/RNN_1/">Working with Sequences</a></li><li><a class="tocitem" href="../../CH8.Recurrent_Neural_Networks/RNN_2/">Converting Raw Text into Sequence Data</a></li><li><a class="tocitem" href="../../CH8.Recurrent_Neural_Networks/RNN_3/">Language Models</a></li><li><a class="tocitem" href="../../CH8.Recurrent_Neural_Networks/RNN_4/">Recurrent Neural Networks</a></li><li><a class="tocitem" href="../../CH8.Recurrent_Neural_Networks/RNN_5/">Recurrent Neural Network Implementation from Scratch</a></li><li><a class="tocitem" href="../../CH8.Recurrent_Neural_Networks/RNN_6/">Concise Implementation of Recurrent Neural Networks</a></li><li><a class="tocitem" href="../../CH8.Recurrent_Neural_Networks/RNN_7/">Backpropagation Through Time</a></li></ul></li><li><span class="tocitem">Modern Recurrent Neural Networks</span><ul><li><a class="tocitem" href="../MRNN7/">Sequence-to-Sequence Learning for Machine Translation</a></li><li><a class="tocitem" href="../MRNN_1/">Long Short-Term Memory (LSTM)</a></li><li><a class="tocitem" href="../MRNN_2/">Gated Recurrent Units (GRU)</a></li><li><a class="tocitem" href="../MRNN_3/">-</a></li><li><a class="tocitem" href="../MRNN_4/">Bidirectional Recurrent Neural Networks</a></li><li><a class="tocitem" href="../MRNN_5/">Machine Translation and the Dataset</a></li><li class="is-active"><a class="tocitem" href>The Encoder–Decoder Architecture</a><ul class="internal"><li><a class="tocitem" href="#Encoder"><span>Encoder</span></a></li><li><a class="tocitem" href="#Decoder"><span>Decoder</span></a></li><li><a class="tocitem" href="#Putting-the-Encoder-and-Decoder-Together"><span>Putting the Encoder and Decoder Together</span></a></li><li><a class="tocitem" href="#Summary"><span>Summary</span></a></li><li><a class="tocitem" href="#Exercises"><span>Exercises</span></a></li></ul></li></ul></li><li><span class="tocitem">Attention Mechanisms and Transformers</span><ul><li><a class="tocitem" href="../../CH10.Attention_Mechanisms_and_Transformers/ATTN_1/">Queries, Keys, and Values</a></li><li><a class="tocitem" href="../../CH10.Attention_Mechanisms_and_Transformers/ATTN_2/">Attention Pooling by Similarity</a></li><li><a class="tocitem" href="../../CH10.Attention_Mechanisms_and_Transformers/ATTN_3/">Attention Scoring Functions</a></li><li><a class="tocitem" href="../../CH10.Attention_Mechanisms_and_Transformers/ATTN_4/">The Bahdanau Attention Mechanism</a></li><li><a class="tocitem" href="../../CH10.Attention_Mechanisms_and_Transformers/ATTN_5/">Multi-Head Attention</a></li><li><a class="tocitem" href="../../CH10.Attention_Mechanisms_and_Transformers/ATTN_6/">Self-Attention and Positional Encoding</a></li><li><a class="tocitem" href="../../CH10.Attention_Mechanisms_and_Transformers/Untitled/">-</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Modern Recurrent Neural Networks</a></li><li class="is-active"><a href>The Encoder–Decoder Architecture</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>The Encoder–Decoder Architecture</a></li></ul></nav><div class="docs-right"><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="The-Encoder–Decoder-Architecture"><a class="docs-heading-anchor" href="#The-Encoder–Decoder-Architecture">The Encoder–Decoder Architecture</a><a id="The-Encoder–Decoder-Architecture-1"></a><a class="docs-heading-anchor-permalink" href="#The-Encoder–Decoder-Architecture" title="Permalink"></a></h1><p>In general sequence-to-sequence problems like machine translation (:numref:<code>sec_machine_translation</code>), inputs and outputs are of varying lengths that are unaligned. The standard approach to handling this sort of data is to design an <em>encoder–decoder</em> architecture (:numref:<code>fig_encoder_decoder</code>) consisting of two major components: an <em>encoder</em> that takes a variable-length sequence as input, and a <em>decoder</em> that acts as a conditional language model, taking in the encoded input and the leftwards context of the target sequence and predicting the subsequent token in the target sequence.</p><p><img src="../../img/encoder-decoder.svg" alt="The encoder--decoder architecture."/> :label:<code>fig_encoder_decoder</code></p><p>Let&#39;s take machine translation from English to French as an example. Given an input sequence in English: &quot;They&quot;, &quot;are&quot;, &quot;watching&quot;, &quot;.&quot;, this encoder–decoder architecture first encodes the variable-length input into a state, then decodes the state to generate the translated sequence, token by token, as output: &quot;Ils&quot;, &quot;regardent&quot;, &quot;.&quot;. Since the encoder–decoder architecture forms the basis of different sequence-to-sequence models in subsequent sections, this section will convert this architecture into an interface that will be implemented later.</p><pre><code class="language-julia hljs">using Pkg; Pkg.activate(&quot;../../d2lai&quot;)
using d2lai
using Flux 
using Downloads
using StatsBase
using Plots
using CUDA, cuDNN
import d2lai: RNNScratch</code></pre><pre><code class="nohighlight hljs">  Activating project at `/workspace/d2l-julia/d2lai`</code></pre><h2 id="Encoder"><a class="docs-heading-anchor" href="#Encoder">Encoder</a><a id="Encoder-1"></a><a class="docs-heading-anchor-permalink" href="#Encoder" title="Permalink"></a></h2><p>In the encoder interface, we just specify that the encoder takes variable-length sequences as input <code>X</code>. The implementation will be provided by any model that subtypes this base <code>AbstractEncoder</code></p><pre><code class="language-julia hljs">abstract type AbstractEncoder &lt;: AbstractModel end</code></pre><h2 id="Decoder"><a class="docs-heading-anchor" href="#Decoder">Decoder</a><a id="Decoder-1"></a><a class="docs-heading-anchor-permalink" href="#Decoder" title="Permalink"></a></h2><p>In the following decoder interface, we add an additional <code>init_state</code> method to convert the encoder output (<code>enc_all_outputs</code>) into the encoded state. Note that this step may require extra inputs, such as the valid length of the input, which was explained in :numref:<code>sec_machine_translation</code>. To generate a variable-length sequence token by token, every time the decoder may map an input (e.g., the generated token at the previous time step) and the encoded state into an output token at the current time step. However this is handled in the next section and we currently only define the abstract class and the <code>init_state</code> method</p><pre><code class="language-julia hljs">abstract type AbstractDecoder &lt;: AbstractModel end

function init_state(decoder::AbstractDecoder, args...) end</code></pre><pre><code class="nohighlight hljs">init_state (generic function with 1 method)</code></pre><h2 id="Putting-the-Encoder-and-Decoder-Together"><a class="docs-heading-anchor" href="#Putting-the-Encoder-and-Decoder-Together">Putting the Encoder and Decoder Together</a><a id="Putting-the-Encoder-and-Decoder-Together-1"></a><a class="docs-heading-anchor-permalink" href="#Putting-the-Encoder-and-Decoder-Together" title="Permalink"></a></h2><p>In the forward propagation, the output of the encoder is used to produce the encoded state, and this state will be further used by the decoder as one of its input.</p><pre><code class="language-julia hljs">abstract type AbstractEncoderDecoder &lt;: AbstractClassifier end 

function (model::AbstractEncoderDecoder)(enc_X, dec_X, args...)
    enc_all_outputs = model.encoder(enc_X, args...)
    dec_state = init_state(model.decoder, enc_all_outputs, args...)
    return model.decoder(dec_X, dec_state)[1]
end</code></pre><p>In the next section, we will see how to apply RNNs to design sequence-to-sequence models based on this encoder–decoder architecture.</p><h2 id="Summary"><a class="docs-heading-anchor" href="#Summary">Summary</a><a id="Summary-1"></a><a class="docs-heading-anchor-permalink" href="#Summary" title="Permalink"></a></h2><p>Encoder-decoder architectures can handle inputs and outputs that both consist of variable-length sequences and thus are suitable for sequence-to-sequence problems such as machine translation. The encoder takes a variable-length sequence as input and transforms it into a state with a fixed shape. The decoder maps the encoded state of a fixed shape to a variable-length sequence.</p><h2 id="Exercises"><a class="docs-heading-anchor" href="#Exercises">Exercises</a><a id="Exercises-1"></a><a class="docs-heading-anchor-permalink" href="#Exercises" title="Permalink"></a></h2><ol><li>Suppose that we use neural networks to implement the encoder–decoder architecture. Do the encoder and the decoder have to be the same type of neural network?</li><li>Besides machine translation, can you think of another application where the encoder–decoder architecture can be applied?</li></ol><pre><code class="language-julia hljs"></code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../MRNN_5/">« Machine Translation and the Dataset</a><a class="docs-footer-nextpage" href="../../CH10.Attention_Mechanisms_and_Transformers/ATTN_1/">Queries, Keys, and Values »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.12.0 on <span class="colophon-date" title="Sunday 15 June 2025 19:32">Sunday 15 June 2025</span>. Using Julia version 1.11.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
